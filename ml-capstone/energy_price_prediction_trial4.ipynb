{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "***\n",
    "## Capstone Project\n",
    "Monish Ananthu<br>\n",
    "October 3rd, 2018<br>\n",
    "***\n",
    "## Energy Price Prediction\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import source_data_helper as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "import visuals as vs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV Data\n",
    "\n",
    "We start by reading data which have a frequency of 15 mins:\n",
    "\n",
    "1. Actual generation\n",
    "2. Actual consumption\n",
    "3. Balancing energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 70271 samples with 14 features each.\n",
      "dataset has 70271 samples with 3 features each.\n",
      "dataset has 70271 samples with 4 features each.\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "# source_path = os.path.join(cwd, 'datasets', '2015')\n",
    "source_path = os.path.join(cwd, 'datasets', '2015-2017')\n",
    "\n",
    "# Read all csv data with a time series frequency of 15 mins. data_freq_15min is a list of dataframes\n",
    "#data_freq_15min = sc.read_multiple_csv(source_path, ['DE_Actual generation.csv', 'DE_Actual consumption.csv', 'DE_Balancing energy.csv'])\n",
    "data_freq_15min = sc.read_multiple_csv(source_path, ['DE_Actual generation_2015-2017.csv', 'DE_Actual consumption_2015-2017.csv','DE_Balancing energy_2015-2017.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual generation** (Frequency = 15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>Biomass[MWh]</th>\n",
       "      <th>Hydropower[MWh]</th>\n",
       "      <th>Wind offshore[MWh]</th>\n",
       "      <th>Wind onshore[MWh]</th>\n",
       "      <th>Photovoltaics[MWh]</th>\n",
       "      <th>Other renewable[MWh]</th>\n",
       "      <th>Nuclear[MWh]</th>\n",
       "      <th>Fossil brown coal[MWh]</th>\n",
       "      <th>Fossil hard coal[MWh]</th>\n",
       "      <th>Fossil gas[MWh]</th>\n",
       "      <th>Hydro pumped storage[MWh]</th>\n",
       "      <th>Other conventional[MWh]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>1005.50</td>\n",
       "      <td>288.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>2028.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2685.50</td>\n",
       "      <td>3976.25</td>\n",
       "      <td>686.00</td>\n",
       "      <td>263.00</td>\n",
       "      <td>192.50</td>\n",
       "      <td>1521.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:15 AM</td>\n",
       "      <td>1007.00</td>\n",
       "      <td>287.75</td>\n",
       "      <td>129.25</td>\n",
       "      <td>2023.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2646.25</td>\n",
       "      <td>3963.25</td>\n",
       "      <td>721.25</td>\n",
       "      <td>261.75</td>\n",
       "      <td>149.75</td>\n",
       "      <td>1498.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:30 AM</td>\n",
       "      <td>1006.50</td>\n",
       "      <td>292.75</td>\n",
       "      <td>128.50</td>\n",
       "      <td>2040.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2660.75</td>\n",
       "      <td>3924.75</td>\n",
       "      <td>695.75</td>\n",
       "      <td>260.50</td>\n",
       "      <td>173.25</td>\n",
       "      <td>1503.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:45 AM</td>\n",
       "      <td>1005.25</td>\n",
       "      <td>289.50</td>\n",
       "      <td>128.75</td>\n",
       "      <td>2036.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2718.00</td>\n",
       "      <td>3871.75</td>\n",
       "      <td>664.75</td>\n",
       "      <td>241.50</td>\n",
       "      <td>95.00</td>\n",
       "      <td>1518.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1:00 AM</td>\n",
       "      <td>998.75</td>\n",
       "      <td>295.25</td>\n",
       "      <td>128.75</td>\n",
       "      <td>2045.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2772.25</td>\n",
       "      <td>3899.00</td>\n",
       "      <td>520.50</td>\n",
       "      <td>202.25</td>\n",
       "      <td>67.50</td>\n",
       "      <td>1491.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Time of day  Biomass[MWh]  Hydropower[MWh]  Wind offshore[MWh]  \\\n",
       "0 2015-01-01    12:00 AM       1005.50           288.25              130.00   \n",
       "1 2015-01-01    12:15 AM       1007.00           287.75              129.25   \n",
       "2 2015-01-01    12:30 AM       1006.50           292.75              128.50   \n",
       "3 2015-01-01    12:45 AM       1005.25           289.50              128.75   \n",
       "4 2015-01-01     1:00 AM        998.75           295.25              128.75   \n",
       "\n",
       "   Wind onshore[MWh]  Photovoltaics[MWh]  Other renewable[MWh]  Nuclear[MWh]  \\\n",
       "0            2028.25                 0.0                  14.5       2685.50   \n",
       "1            2023.00                 0.0                  14.5       2646.25   \n",
       "2            2040.25                 0.0                  14.5       2660.75   \n",
       "3            2036.50                 0.0                  14.5       2718.00   \n",
       "4            2045.75                 0.0                  14.5       2772.25   \n",
       "\n",
       "   Fossil brown coal[MWh]  Fossil hard coal[MWh]  Fossil gas[MWh]  \\\n",
       "0                 3976.25                 686.00           263.00   \n",
       "1                 3963.25                 721.25           261.75   \n",
       "2                 3924.75                 695.75           260.50   \n",
       "3                 3871.75                 664.75           241.50   \n",
       "4                 3899.00                 520.50           202.25   \n",
       "\n",
       "   Hydro pumped storage[MWh]  Other conventional[MWh]  \n",
       "0                     192.50                  1521.75  \n",
       "1                     149.75                  1498.00  \n",
       "2                     173.25                  1503.25  \n",
       "3                      95.00                  1518.75  \n",
       "4                      67.50                  1491.75  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_freq_15min[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of energy in MWh(Megawatt hour) from different energy sources for each time period is listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>biomass_mwh</th>\n",
       "      <th>hydropower_mwh</th>\n",
       "      <th>wind_offshore_mwh</th>\n",
       "      <th>wind_onshore_mwh</th>\n",
       "      <th>photovoltaics_mwh</th>\n",
       "      <th>other_renewable_mwh</th>\n",
       "      <th>nuclear_mwh</th>\n",
       "      <th>fossil_brown_coal_mwh</th>\n",
       "      <th>fossil_hard_coal_mwh</th>\n",
       "      <th>fossil_gas_mwh</th>\n",
       "      <th>hydro_pumped_storage_mwh</th>\n",
       "      <th>other_conventional_mwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>1005.50</td>\n",
       "      <td>288.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>2028.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2685.50</td>\n",
       "      <td>3976.25</td>\n",
       "      <td>686.00</td>\n",
       "      <td>263.00</td>\n",
       "      <td>192.50</td>\n",
       "      <td>1521.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:15 AM</td>\n",
       "      <td>1007.00</td>\n",
       "      <td>287.75</td>\n",
       "      <td>129.25</td>\n",
       "      <td>2023.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2646.25</td>\n",
       "      <td>3963.25</td>\n",
       "      <td>721.25</td>\n",
       "      <td>261.75</td>\n",
       "      <td>149.75</td>\n",
       "      <td>1498.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:30 AM</td>\n",
       "      <td>1006.50</td>\n",
       "      <td>292.75</td>\n",
       "      <td>128.50</td>\n",
       "      <td>2040.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2660.75</td>\n",
       "      <td>3924.75</td>\n",
       "      <td>695.75</td>\n",
       "      <td>260.50</td>\n",
       "      <td>173.25</td>\n",
       "      <td>1503.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:45 AM</td>\n",
       "      <td>1005.25</td>\n",
       "      <td>289.50</td>\n",
       "      <td>128.75</td>\n",
       "      <td>2036.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2718.00</td>\n",
       "      <td>3871.75</td>\n",
       "      <td>664.75</td>\n",
       "      <td>241.50</td>\n",
       "      <td>95.00</td>\n",
       "      <td>1518.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1:00 AM</td>\n",
       "      <td>998.75</td>\n",
       "      <td>295.25</td>\n",
       "      <td>128.75</td>\n",
       "      <td>2045.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2772.25</td>\n",
       "      <td>3899.00</td>\n",
       "      <td>520.50</td>\n",
       "      <td>202.25</td>\n",
       "      <td>67.50</td>\n",
       "      <td>1491.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date time_of_day  biomass_mwh  hydropower_mwh  wind_offshore_mwh  \\\n",
       "0 2015-01-01    12:00 AM      1005.50          288.25             130.00   \n",
       "1 2015-01-01    12:15 AM      1007.00          287.75             129.25   \n",
       "2 2015-01-01    12:30 AM      1006.50          292.75             128.50   \n",
       "3 2015-01-01    12:45 AM      1005.25          289.50             128.75   \n",
       "4 2015-01-01     1:00 AM       998.75          295.25             128.75   \n",
       "\n",
       "   wind_onshore_mwh  photovoltaics_mwh  other_renewable_mwh  nuclear_mwh  \\\n",
       "0           2028.25                0.0                 14.5      2685.50   \n",
       "1           2023.00                0.0                 14.5      2646.25   \n",
       "2           2040.25                0.0                 14.5      2660.75   \n",
       "3           2036.50                0.0                 14.5      2718.00   \n",
       "4           2045.75                0.0                 14.5      2772.25   \n",
       "\n",
       "   fossil_brown_coal_mwh  fossil_hard_coal_mwh  fossil_gas_mwh  \\\n",
       "0                3976.25                686.00          263.00   \n",
       "1                3963.25                721.25          261.75   \n",
       "2                3924.75                695.75          260.50   \n",
       "3                3871.75                664.75          241.50   \n",
       "4                3899.00                520.50          202.25   \n",
       "\n",
       "   hydro_pumped_storage_mwh  other_conventional_mwh  \n",
       "0                    192.50                 1521.75  \n",
       "1                    149.75                 1498.00  \n",
       "2                    173.25                 1503.25  \n",
       "3                     95.00                 1518.75  \n",
       "4                     67.50                 1491.75  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix column names with Whitespaces and Uppercases\n",
    "#data_freq_15min[0].columns = data_freq_15min[0].columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "data_freq_15min[0].columns = data_freq_15min[0].columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('[', '_').str.replace(']', '')\n",
    "data_freq_15min[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Actual consumption** (Frequency = 15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>Total[MWh]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>10606.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:15 AM</td>\n",
       "      <td>10505.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:30 AM</td>\n",
       "      <td>10517.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:45 AM</td>\n",
       "      <td>10468.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1:00 AM</td>\n",
       "      <td>10307.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Time of day  Total[MWh]\n",
       "0 2015-01-01    12:00 AM    10606.25\n",
       "1 2015-01-01    12:15 AM    10505.25\n",
       "2 2015-01-01    12:30 AM    10517.00\n",
       "3 2015-01-01    12:45 AM    10468.50\n",
       "4 2015-01-01     1:00 AM    10307.50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_freq_15min[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of energy consumed in MWh(Megawatt hour) for each time period is listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix column names with Whitespaces and Uppercases\n",
    "#data_freq_15min[1].columns = data_freq_15min[1].columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "data_freq_15min[1].columns = data_freq_15min[1].columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('[', '_').str.replace(']', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balancing energy** (Frequency = 15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>Balancing energy volume[MWh]</th>\n",
       "      <th>Balancing energy price[Euro/MWh]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>-475.0</td>\n",
       "      <td>-49.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:15 AM</td>\n",
       "      <td>-181.0</td>\n",
       "      <td>-19.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:30 AM</td>\n",
       "      <td>154.0</td>\n",
       "      <td>74.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:45 AM</td>\n",
       "      <td>137.0</td>\n",
       "      <td>62.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1:00 AM</td>\n",
       "      <td>463.0</td>\n",
       "      <td>63.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Time of day  Balancing energy volume[MWh]  \\\n",
       "0 2015-01-01    12:00 AM                        -475.0   \n",
       "1 2015-01-01    12:15 AM                        -181.0   \n",
       "2 2015-01-01    12:30 AM                         154.0   \n",
       "3 2015-01-01    12:45 AM                         137.0   \n",
       "4 2015-01-01     1:00 AM                         463.0   \n",
       "\n",
       "   Balancing energy price[Euro/MWh]  \n",
       "0                            -49.41  \n",
       "1                            -19.69  \n",
       "2                             74.70  \n",
       "3                             62.28  \n",
       "4                             63.71  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_freq_15min[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix column names with Whitespaces and Uppercases\n",
    "#data_freq_15min[2].columns = data_freq_15min[2].columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "data_freq_15min[2].columns = data_freq_15min[2].columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('[', '_').str.replace(']', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wholesale market price** (Frequency = 60 mins)\n",
    "\n",
    "Wholesale market price/Day ahead price has a frequency of 60 mins. Therfore, we will read this data separately to merge them later with the 15 min data set, which will be reduced to a frequency of 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 17568 samples with 14 features each.\n"
     ]
    }
   ],
   "source": [
    "#prices_freq_60min = sc.read_csv(os.path.join(source_path,\"DE_Day-ahead prices.csv\"))\n",
    "prices_freq_60min = sc.read_csv(os.path.join(source_path,\"DE_Day-ahead prices_2015-2017.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time of day</th>\n",
       "      <th>Germany/Austria/Luxembourg[Euro/MWh]</th>\n",
       "      <th>Denmark 1[Euro/MWh]</th>\n",
       "      <th>Denmark 2[Euro/MWh]</th>\n",
       "      <th>France[Euro/MWh]</th>\n",
       "      <th>Northern Italy[Euro/MWh]</th>\n",
       "      <th>Netherlands[Euro/MWh]</th>\n",
       "      <th>Poland[Euro/MWh]</th>\n",
       "      <th>Sweden 4[Euro/MWh]</th>\n",
       "      <th>Switzerland[Euro/MWh]</th>\n",
       "      <th>Slovenia[Euro/MWh]</th>\n",
       "      <th>Czech Republic[Euro/MWh]</th>\n",
       "      <th>Hungary[Euro/MWh]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.02</td>\n",
       "      <td>27.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.38</td>\n",
       "      <td>44.94</td>\n",
       "      <td>27.30</td>\n",
       "      <td>26.48</td>\n",
       "      <td>45.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.29</td>\n",
       "      <td>18.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.37</td>\n",
       "      <td>43.43</td>\n",
       "      <td>23.25</td>\n",
       "      <td>24.20</td>\n",
       "      <td>44.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.04</td>\n",
       "      <td>16.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.33</td>\n",
       "      <td>38.08</td>\n",
       "      <td>22.20</td>\n",
       "      <td>22.06</td>\n",
       "      <td>39.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.60</td>\n",
       "      <td>14.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.66</td>\n",
       "      <td>35.47</td>\n",
       "      <td>19.56</td>\n",
       "      <td>20.27</td>\n",
       "      <td>26.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.53</td>\n",
       "      <td>30.83</td>\n",
       "      <td>18.88</td>\n",
       "      <td>19.17</td>\n",
       "      <td>20.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Time of day  Germany/Austria/Luxembourg[Euro/MWh]  \\\n",
       "0 2015-01-01    12:00 AM                                   NaN   \n",
       "1 2015-01-01     1:00 AM                                   NaN   \n",
       "2 2015-01-01     2:00 AM                                   NaN   \n",
       "3 2015-01-01     3:00 AM                                   NaN   \n",
       "4 2015-01-01     4:00 AM                                   NaN   \n",
       "\n",
       "   Denmark 1[Euro/MWh]  Denmark 2[Euro/MWh]  France[Euro/MWh]  \\\n",
       "0                25.02                27.38               NaN   \n",
       "1                18.29                18.29               NaN   \n",
       "2                16.04                16.04               NaN   \n",
       "3                14.60                14.60               NaN   \n",
       "4                14.95                14.95               NaN   \n",
       "\n",
       "   Northern Italy[Euro/MWh]  Netherlands[Euro/MWh]  Poland[Euro/MWh]  \\\n",
       "0                       NaN                    NaN               NaN   \n",
       "1                       NaN                    NaN               NaN   \n",
       "2                       NaN                    NaN               NaN   \n",
       "3                       NaN                    NaN               NaN   \n",
       "4                       NaN                    NaN               NaN   \n",
       "\n",
       "   Sweden 4[Euro/MWh]  Switzerland[Euro/MWh]  Slovenia[Euro/MWh]  \\\n",
       "0               27.38                  44.94               27.30   \n",
       "1               23.37                  43.43               23.25   \n",
       "2               19.33                  38.08               22.20   \n",
       "3               17.66                  35.47               19.56   \n",
       "4               17.53                  30.83               18.88   \n",
       "\n",
       "   Czech Republic[Euro/MWh]  Hungary[Euro/MWh]  \n",
       "0                     26.48              45.07  \n",
       "1                     24.20              44.16  \n",
       "2                     22.06              39.17  \n",
       "3                     20.27              26.93  \n",
       "4                     19.17              20.94  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_freq_60min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix column names with Whitespaces and Uppercases\n",
    "#prices_freq_60min.columns = prices_freq_60min.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "prices_freq_60min.columns = prices_freq_60min.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('[', '_').str.replace(']', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce frequency of all features to 60 minutes and merge to a single data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified dataset has 17568 samples with 14 features each.\n",
      "Modified dataset has 17568 samples with 3 features each.\n",
      "Modified dataset has 17568 samples with 4 features each.\n"
     ]
    }
   ],
   "source": [
    "data_freq_60min = sc.convert_multiple_to_hourly(data_freq_15min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>biomass_mwh</th>\n",
       "      <th>hydropower_mwh</th>\n",
       "      <th>wind_offshore_mwh</th>\n",
       "      <th>wind_onshore_mwh</th>\n",
       "      <th>photovoltaics_mwh</th>\n",
       "      <th>other_renewable_mwh</th>\n",
       "      <th>nuclear_mwh</th>\n",
       "      <th>fossil_brown_coal_mwh</th>\n",
       "      <th>fossil_hard_coal_mwh</th>\n",
       "      <th>fossil_gas_mwh</th>\n",
       "      <th>hydro_pumped_storage_mwh</th>\n",
       "      <th>other_conventional_mwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>1005.50</td>\n",
       "      <td>288.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>2028.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2685.50</td>\n",
       "      <td>3976.25</td>\n",
       "      <td>686.00</td>\n",
       "      <td>263.00</td>\n",
       "      <td>192.50</td>\n",
       "      <td>1521.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1:00 AM</td>\n",
       "      <td>998.75</td>\n",
       "      <td>295.25</td>\n",
       "      <td>128.75</td>\n",
       "      <td>2045.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2772.25</td>\n",
       "      <td>3899.00</td>\n",
       "      <td>520.50</td>\n",
       "      <td>202.25</td>\n",
       "      <td>67.50</td>\n",
       "      <td>1491.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2:00 AM</td>\n",
       "      <td>1001.00</td>\n",
       "      <td>293.25</td>\n",
       "      <td>129.00</td>\n",
       "      <td>2134.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2774.00</td>\n",
       "      <td>3774.50</td>\n",
       "      <td>449.25</td>\n",
       "      <td>101.00</td>\n",
       "      <td>167.00</td>\n",
       "      <td>1480.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>3:00 AM</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>284.25</td>\n",
       "      <td>128.50</td>\n",
       "      <td>2149.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2759.25</td>\n",
       "      <td>3574.00</td>\n",
       "      <td>483.50</td>\n",
       "      <td>101.00</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1537.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>4:00 AM</td>\n",
       "      <td>1008.75</td>\n",
       "      <td>279.25</td>\n",
       "      <td>129.75</td>\n",
       "      <td>2184.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2766.50</td>\n",
       "      <td>3540.25</td>\n",
       "      <td>469.50</td>\n",
       "      <td>101.25</td>\n",
       "      <td>142.25</td>\n",
       "      <td>1476.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date time_of_day  biomass_mwh  hydropower_mwh  wind_offshore_mwh  \\\n",
       "0 2015-01-01    12:00 AM      1005.50          288.25             130.00   \n",
       "1 2015-01-01     1:00 AM       998.75          295.25             128.75   \n",
       "2 2015-01-01     2:00 AM      1001.00          293.25             129.00   \n",
       "3 2015-01-01     3:00 AM      1008.00          284.25             128.50   \n",
       "4 2015-01-01     4:00 AM      1008.75          279.25             129.75   \n",
       "\n",
       "   wind_onshore_mwh  photovoltaics_mwh  other_renewable_mwh  nuclear_mwh  \\\n",
       "0           2028.25                0.0                 14.5      2685.50   \n",
       "1           2045.75                0.0                 14.5      2772.25   \n",
       "2           2134.50                0.0                 14.5      2774.00   \n",
       "3           2149.50                0.0                 14.5      2759.25   \n",
       "4           2184.00                0.0                 14.5      2766.50   \n",
       "\n",
       "   fossil_brown_coal_mwh  fossil_hard_coal_mwh  fossil_gas_mwh  \\\n",
       "0                3976.25                686.00          263.00   \n",
       "1                3899.00                520.50          202.25   \n",
       "2                3774.50                449.25          101.00   \n",
       "3                3574.00                483.50          101.00   \n",
       "4                3540.25                469.50          101.25   \n",
       "\n",
       "   hydro_pumped_storage_mwh  other_conventional_mwh  \n",
       "0                    192.50                 1521.75  \n",
       "1                     67.50                 1491.75  \n",
       "2                    167.00                 1480.25  \n",
       "3                    136.50                 1537.00  \n",
       "4                    142.25                 1476.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view reduced data for actual generation\n",
    "data_freq_60min[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join new dataframes list with the previous join to get master dataframe\n",
    "data_freq_60min.extend([prices_freq_60min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all dataframes in the list iteratively with keys= date, time_of_day\n",
    "master_data = sc.join(data_freq_60min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unrelevant columns\n",
    "master_data.drop(['denmark_1_euro/mwh','denmark_2_euro/mwh', 'france_euro/mwh', 'northern_italy_euro/mwh',\n",
    " 'netherlands_euro/mwh', 'poland_euro/mwh', 'sweden_4_euro/mwh', 'switzerland_euro/mwh',\n",
    " 'slovenia_euro/mwh', 'czech_republic_euro/mwh', 'hungary_euro/mwh'], 1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in dataset = 17596\n",
      "Total number of columns = 18\n",
      "Column wise count of null values:-\n",
      "date                                  0\n",
      "time_of_day                           0\n",
      "biomass_mwh                         203\n",
      "hydropower_mwh                      135\n",
      "wind_offshore_mwh                   113\n",
      "wind_onshore_mwh                    117\n",
      "photovoltaics_mwh                   146\n",
      "other_renewable_mwh                 212\n",
      "nuclear_mwh                          96\n",
      "fossil_brown_coal_mwh               196\n",
      "fossil_hard_coal_mwh                168\n",
      "fossil_gas_mwh                      150\n",
      "hydro_pumped_storage_mwh            121\n",
      "other_conventional_mwh             1017\n",
      "total_consumption_mwh                 0\n",
      "balancing_energy_volume_mwh           0\n",
      "balancing_energy_price_euro/mwh       0\n",
      "price_germany_euro/mwh              120\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "master_data.rename(columns={'total_mwh': 'total_consumption_mwh', 'germany/austria/luxembourg_euro/mwh': 'price_germany_euro/mwh'}, inplace=True)\n",
    "#master_data.rename(columns={'germany/austria/luxembourg[euro/mwh]': 'price_germany[euro/mwh]'}, inplace=True)\n",
    "# Dataset characteristics\n",
    "print(\"Number of instances in dataset = {}\".format(master_data.shape[0]))\n",
    "print(\"Total number of columns = {}\".format(master_data.columns.shape[0]))\n",
    "print(\"Column wise count of null values:-\")\n",
    "print(master_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, 12 features contain missing or NaN values. Let us explore the data in detail to determine how to deal with NaNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4 types of data and we have to explore them separately.\n",
    "\n",
    "a. Actual generation<br>\n",
    "b. Realized Consumption<br>\n",
    "c. Balancing energy<br>\n",
    "d. Wholesale energy price<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for actual generation\n",
    "actual_generation = ['biomass_mwh','hydropower_mwh','wind_offshore_mwh','wind_onshore_mwh','photovoltaics_mwh',\n",
    "                     'other_renewable_mwh','nuclear_mwh','fossil_brown_coal_mwh','fossil_hard_coal_mwh',\n",
    "                     'fossil_gas_mwh','hydro_pumped_storage_mwh', 'other_conventional_mwh']\n",
    "\n",
    "#actual_consumption = ['50hz_consumption','amprion_consumption','tennet_consumption','transnetbw_consumption']\n",
    "actual_consumption = ['total_consumption_mwh']\n",
    "\n",
    "balancing_energy = ['balancing_energy_volume_mwh','balancing_energy_price_euro/mwh']\n",
    "\n",
    "target = ['price_germany_euro/mwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biomass_mwh</th>\n",
       "      <th>hydropower_mwh</th>\n",
       "      <th>wind_offshore_mwh</th>\n",
       "      <th>wind_onshore_mwh</th>\n",
       "      <th>photovoltaics_mwh</th>\n",
       "      <th>other_renewable_mwh</th>\n",
       "      <th>nuclear_mwh</th>\n",
       "      <th>fossil_brown_coal_mwh</th>\n",
       "      <th>fossil_hard_coal_mwh</th>\n",
       "      <th>fossil_gas_mwh</th>\n",
       "      <th>hydro_pumped_storage_mwh</th>\n",
       "      <th>other_conventional_mwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17393.000000</td>\n",
       "      <td>17461.000000</td>\n",
       "      <td>17483.000000</td>\n",
       "      <td>17479.000000</td>\n",
       "      <td>17450.000000</td>\n",
       "      <td>17384.000000</td>\n",
       "      <td>17500.000000</td>\n",
       "      <td>17400.000000</td>\n",
       "      <td>17428.000000</td>\n",
       "      <td>17446.000000</td>\n",
       "      <td>17475.000000</td>\n",
       "      <td>16579.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1059.656126</td>\n",
       "      <td>453.039030</td>\n",
       "      <td>285.107447</td>\n",
       "      <td>1907.624707</td>\n",
       "      <td>985.667722</td>\n",
       "      <td>23.507248</td>\n",
       "      <td>2345.017114</td>\n",
       "      <td>3762.063707</td>\n",
       "      <td>2337.405899</td>\n",
       "      <td>362.094334</td>\n",
       "      <td>175.073462</td>\n",
       "      <td>1437.941764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89.666552</td>\n",
       "      <td>128.472593</td>\n",
       "      <td>231.897884</td>\n",
       "      <td>1606.903028</td>\n",
       "      <td>1511.748379</td>\n",
       "      <td>15.589565</td>\n",
       "      <td>360.398637</td>\n",
       "      <td>576.352412</td>\n",
       "      <td>1231.525012</td>\n",
       "      <td>311.543847</td>\n",
       "      <td>226.936886</td>\n",
       "      <td>609.139779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>660.500000</td>\n",
       "      <td>202.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1130.500000</td>\n",
       "      <td>1332.500000</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>174.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>986.250000</td>\n",
       "      <td>354.250000</td>\n",
       "      <td>85.750000</td>\n",
       "      <td>726.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>2156.250000</td>\n",
       "      <td>3453.000000</td>\n",
       "      <td>1250.062500</td>\n",
       "      <td>153.312500</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1021.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1080.250000</td>\n",
       "      <td>423.750000</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>1412.250000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2457.000000</td>\n",
       "      <td>3836.750000</td>\n",
       "      <td>2393.125000</td>\n",
       "      <td>235.125000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>1334.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1147.000000</td>\n",
       "      <td>530.750000</td>\n",
       "      <td>481.750000</td>\n",
       "      <td>2616.250000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>2630.250000</td>\n",
       "      <td>4186.500000</td>\n",
       "      <td>3350.562500</td>\n",
       "      <td>455.187500</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>1716.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1206.000000</td>\n",
       "      <td>785.250000</td>\n",
       "      <td>915.500000</td>\n",
       "      <td>7738.250000</td>\n",
       "      <td>6563.000000</td>\n",
       "      <td>518.250000</td>\n",
       "      <td>2868.500000</td>\n",
       "      <td>4807.500000</td>\n",
       "      <td>5169.500000</td>\n",
       "      <td>2364.750000</td>\n",
       "      <td>1598.250000</td>\n",
       "      <td>8127.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        biomass_mwh  hydropower_mwh  wind_offshore_mwh  wind_onshore_mwh  \\\n",
       "count  17393.000000    17461.000000       17483.000000      17479.000000   \n",
       "mean    1059.656126      453.039030         285.107447       1907.624707   \n",
       "std       89.666552      128.472593         231.897884       1606.903028   \n",
       "min      660.500000      202.250000           0.000000         28.000000   \n",
       "25%      986.250000      354.250000          85.750000        726.250000   \n",
       "50%     1080.250000      423.750000         210.250000       1412.250000   \n",
       "75%     1147.000000      530.750000         481.750000       2616.250000   \n",
       "max     1206.000000      785.250000         915.500000       7738.250000   \n",
       "\n",
       "       photovoltaics_mwh  other_renewable_mwh   nuclear_mwh  \\\n",
       "count       17450.000000         17384.000000  17500.000000   \n",
       "mean          985.667722            23.507248   2345.017114   \n",
       "std          1511.748379            15.589565    360.398637   \n",
       "min             0.000000             6.500000   1130.500000   \n",
       "25%             0.000000            16.250000   2156.250000   \n",
       "50%            17.250000            25.000000   2457.000000   \n",
       "75%          1579.000000            27.750000   2630.250000   \n",
       "max          6563.000000           518.250000   2868.500000   \n",
       "\n",
       "       fossil_brown_coal_mwh  fossil_hard_coal_mwh  fossil_gas_mwh  \\\n",
       "count           17400.000000          17428.000000    17446.000000   \n",
       "mean             3762.063707           2337.405899      362.094334   \n",
       "std               576.352412           1231.525012      311.543847   \n",
       "min              1332.500000            103.750000        7.250000   \n",
       "25%              3453.000000           1250.062500      153.312500   \n",
       "50%              3836.750000           2393.125000      235.125000   \n",
       "75%              4186.500000           3350.562500      455.187500   \n",
       "max              4807.500000           5169.500000     2364.750000   \n",
       "\n",
       "       hydro_pumped_storage_mwh  other_conventional_mwh  \n",
       "count              17475.000000            16579.000000  \n",
       "mean                 175.073462             1437.941764  \n",
       "std                  226.936886              609.139779  \n",
       "min                    0.000000              174.750000  \n",
       "25%                    1.250000             1021.750000  \n",
       "50%                   74.500000             1334.500000  \n",
       "75%                  275.000000             1716.750000  \n",
       "max                 1598.250000             8127.500000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data[actual_generation].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual generation depicts real time energy generation data. If we have missing values here, it implies that the particular energy source did not produce energy for the time period. We can replace the missing values with 0s.\n",
    "\n",
    "We also notice that the mean and median values of the different features vary to a large extent. Hence, in a later stage we should scale our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with zeroes\n",
    "master_data['biomass_mwh'].fillna(0,inplace=True)\n",
    "master_data['hydropower_mwh'].fillna(0,inplace=True)\n",
    "master_data['wind_offshore_mwh'].fillna(0,inplace=True)\n",
    "master_data['wind_onshore_mwh'].fillna(0,inplace=True)\n",
    "master_data['photovoltaics_mwh'].fillna(0,inplace=True)\n",
    "master_data['other_renewable_mwh'].fillna(0,inplace=True)\n",
    "master_data['nuclear_mwh'].fillna(0,inplace=True)\n",
    "master_data['fossil_brown_coal_mwh'].fillna(0,inplace=True)\n",
    "master_data['fossil_hard_coal_mwh'].fillna(0,inplace=True)\n",
    "master_data['fossil_gas_mwh'].fillna(0,inplace=True)\n",
    "master_data['hydro_pumped_storage_mwh'].fillna(0,inplace=True)\n",
    "master_data['other_conventional_mwh'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d3fe94ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distr = master_data['biomass_mwh'].plot(kind='hist', alpha=1.0, bins=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'other_conventional_mwh')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d382b60dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot actual generation\n",
    "fig = plt.figure(figsize=(13,8))\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "\n",
    "plt.subplot(4,4,1)\n",
    "master_data['biomass_mwh'].plot()\n",
    "plt.title('biomass_mwh')\n",
    "\n",
    "plt.subplot(4,4,2)\n",
    "master_data['hydropower_mwh'].plot()\n",
    "plt.title('hydropower_mwh')\n",
    "\n",
    "plt.subplot(4,4,3)\n",
    "master_data['wind_offshore_mwh'].plot()\n",
    "plt.title('wind_offshore_mwh')\n",
    "\n",
    "plt.subplot(4,4,4)\n",
    "master_data['wind_onshore_mwh'].plot()\n",
    "plt.title('wind_onshore_mwh')\n",
    "\n",
    "plt.subplot(4,4,5)\n",
    "master_data['photovoltaics_mwh'].plot()\n",
    "plt.title('photovoltaics_mwh')\n",
    "\n",
    "plt.subplot(4,4,6)\n",
    "master_data['other_renewable_mwh'].plot()\n",
    "plt.title('other_renewable_mwh')\n",
    "\n",
    "plt.subplot(4,4,7)\n",
    "master_data['nuclear_mwh'].plot()\n",
    "plt.title('nuclear_mwh')\n",
    "\n",
    "plt.subplot(4,4,8)\n",
    "master_data['fossil_brown_coal_mwh'].plot()\n",
    "plt.title('fossil_brown_coal_mwh')\n",
    "\n",
    "plt.subplot(4,4,9)\n",
    "master_data['fossil_hard_coal_mwh'].plot()\n",
    "plt.title('fossil_hard_coal_mwh')\n",
    "\n",
    "plt.subplot(4,4,10)\n",
    "master_data['fossil_gas_mwh'].plot()\n",
    "plt.title('fossil_gas_mwh')\n",
    "\n",
    "plt.subplot(4,4,11)\n",
    "master_data['hydro_pumped_storage_mwh'].plot()\n",
    "plt.title('hydro_pumped_storage_mwh')\n",
    "\n",
    "plt.subplot(4,4,12)\n",
    "master_data['other_conventional_mwh'].plot()\n",
    "plt.title('other_conventional_mwh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We currently have 17596 hourly dataset rows over a persiod of 2 years 2015-2016 and 2016-2017 i.e. 8798 per year. \n",
    "\n",
    "Looking at the above data we can observe that non-renewable sources of energy have a pattern which can be predicted if we were to divide the graphs right in the middle. This is true for nuclear, fossil brown coal, fossil hard coal, fossil gas, hydro pumped storage and other conventional energy sources.\n",
    "\n",
    "The same is not consistent for renewable sources. Wind energy is weather dependent which does not have set patterns. If we observe biomass and hydropower, they reflect similar patterns but in varying sizes. This could be a result of increasing yearly investments in these energy sources. Photovoltaics appears to be consistent with a predictable pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_consumption_mwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13663.896255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2477.577389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7856.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11586.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13582.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15906.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18975.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_consumption_mwh\n",
       "count           17596.000000\n",
       "mean            13663.896255\n",
       "std              2477.577389\n",
       "min              7856.750000\n",
       "25%             11586.750000\n",
       "50%             13582.500000\n",
       "75%             15906.437500\n",
       "max             18975.250000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data[actual_consumption].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and median of 'total_consumption_mwh' varies to a large extent when compared to features grouped under 'actual_generation'. Scaling is therefore necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d3868c5eb8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d383903588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_data['total_consumption_mwh'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The consumption data for the second year seems to follow a similar pattern as the first year. This implies that the energy consumption for a certain time of year is consistent to the previous year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balancing_energy_volume_mwh</th>\n",
       "      <th>balancing_energy_price_euro/mwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17596.000000</td>\n",
       "      <td>17596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>165.372471</td>\n",
       "      <td>31.917856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>464.695247</td>\n",
       "      <td>150.874693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3210.000000</td>\n",
       "      <td>-5997.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-102.250000</td>\n",
       "      <td>1.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>39.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>437.000000</td>\n",
       "      <td>60.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3271.000000</td>\n",
       "      <td>5824.630000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       balancing_energy_volume_mwh  balancing_energy_price_euro/mwh\n",
       "count                 17596.000000                     17596.000000\n",
       "mean                    165.372471                        31.917856\n",
       "std                     464.695247                       150.874693\n",
       "min                   -3210.000000                     -5997.420000\n",
       "25%                    -102.250000                         1.890000\n",
       "50%                     160.000000                        39.940000\n",
       "75%                     437.000000                        60.882500\n",
       "max                    3271.000000                      5824.630000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data[balancing_energy].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to 'total_consumption_mwh', Data Scaling is also required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'balancing_energy_price_euro/mwh')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d382558358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(13,8))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "master_data['balancing_energy_volume_mwh'].plot()\n",
    "plt.title('balancing_energy_volume_mwh')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "master_data['balancing_energy_price_euro/mwh'].plot()\n",
    "plt.title('balancing_energy_price_euro/mwh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balancing energy volume contains a consistent yearly pattern. This does not apply to the balancing energy price which appears more random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_germany_euro/mwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.386641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.551637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-130.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price_germany_euro/mwh\n",
       "count            17476.000000\n",
       "mean                30.386641\n",
       "std                 12.551637\n",
       "min               -130.090000\n",
       "25%                 23.460000\n",
       "50%                 29.660000\n",
       "75%                 37.060000\n",
       "max                104.960000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data[target].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 120 missing values for **price_germany**. The reason for missing values could be an error in the logging system. In the energy market, there is always supply and demand and hence, a price for each time period. Earlier for energy generation we replaced all missing values with zeroes. The case here is different and a price of zero has a false implication and would have a negative influence on the prediction.\n",
    "\n",
    "The best strategy here would be to either use the Median or the mean.\n",
    "\n",
    "<font color='blue'>Median = 29.66</font> <br>\n",
    "<font color='blue'>Mean = 30.386641</font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there isn't a large difference between Median and Mean, let us consider the Mean value to fill the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data['price_germany_euro/mwh'].fillna(master_data['price_germany_euro/mwh'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d38259c748>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d38390dcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_data['price_germany_euro/mwh'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figure we can observe a pattern with a lot of activity at start and end of the year. As the year proceeds, it appears more constant. The pattern cannot be reproduced the next year 100% but the tendency and value ranges remain the same. Moreover, pricing is a complex issue which not only depends on demand and supply but other factors which we haven't considered in our case. One factor could be the increase of investment every year in renewable energies increasing output but also at the same time making renewable energy expensive in the initial phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d3828d72e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distr = master_data[target].plot(kind='hist', alpha=0.5, bins=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date and time \n",
    "master_data.drop(['date','time_of_day'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biomass_mwh',\n",
       " 'hydropower_mwh',\n",
       " 'wind_offshore_mwh',\n",
       " 'wind_onshore_mwh',\n",
       " 'photovoltaics_mwh',\n",
       " 'other_renewable_mwh',\n",
       " 'nuclear_mwh',\n",
       " 'fossil_brown_coal_mwh',\n",
       " 'fossil_hard_coal_mwh',\n",
       " 'fossil_gas_mwh',\n",
       " 'hydro_pumped_storage_mwh',\n",
       " 'other_conventional_mwh',\n",
       " 'total_consumption_mwh',\n",
       " 'balancing_energy_volume_mwh',\n",
       " 'balancing_energy_price_euro/mwh',\n",
       " 'price_germany_euro/mwh']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(master_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_frame = master_data.copy()\n",
    "# get only source features for scaling\n",
    "x_features = ['biomass_mwh','hydropower_mwh','wind_offshore_mwh','wind_onshore_mwh','photovoltaics_mwh','other_renewable_mwh','nuclear_mwh','fossil_brown_coal_mwh','fossil_hard_coal_mwh','fossil_gas_mwh','hydro_pumped_storage_mwh','other_conventional_mwh','total_consumption_mwh','balancing_energy_volume_mwh']\n",
    "#temp_frame.drop(['balancing_energy_price_euro/mwh', 'price_germany_euro/mwh'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6812\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "out_counter = Counter()\n",
    "\n",
    "\n",
    "# For each feature find the data points with extreme high or low values\n",
    "for index,feature in temp_frame[x_features].T.iterrows():\n",
    "    \n",
    "    # TODO: Calculate Q1 (25th percentile of the data) for the given feature\n",
    "    Q1 = np.percentile(feature,25)\n",
    "\n",
    "    # TODO: Calculate Q3 (75th percentile of the data) for the given feature\n",
    "    Q3 = np.percentile(feature,75)\n",
    "    \n",
    "    # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "    step = (Q3 - Q1)*1.5\n",
    "    \n",
    "    # Display the outliers\n",
    "    #print(\"Data points considered outliers for the feature '{}':\".format(feature))\n",
    "    new_data = temp_frame[~((temp_frame[index] >= Q1 - step) & (temp_frame[index] <= Q3 + step))]\n",
    "    #new_data = feature[~((feature >= Q1 - step) & (feature <= Q3 + step))]\n",
    "    \n",
    "    #savr indices\n",
    "    #print(new_data)\n",
    "    for index in new_data.index.get_values():\n",
    "        #print(index)\n",
    "        out_counter[index] += 1\n",
    "        \n",
    "# OPTIONAL: Select the indices for data points you wish to remove\n",
    "outliers  = [list(out_counter.elements())]\n",
    "\n",
    "print (len(list(out_counter.elements())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:1754: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "source": [
    "# Remove the outliers, if any were specified\n",
    "#scaled_data = np.delete(scaled_data, ([outliers]), axis=0)\n",
    "temp_frame.drop(temp_frame.index[outliers], axis=0, inplace=True)\n",
    "print(len(temp_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biomass_mwh',\n",
       " 'hydropower_mwh',\n",
       " 'wind_offshore_mwh',\n",
       " 'wind_onshore_mwh',\n",
       " 'photovoltaics_mwh',\n",
       " 'other_renewable_mwh',\n",
       " 'nuclear_mwh',\n",
       " 'fossil_brown_coal_mwh',\n",
       " 'fossil_hard_coal_mwh',\n",
       " 'fossil_gas_mwh',\n",
       " 'hydro_pumped_storage_mwh',\n",
       " 'other_conventional_mwh',\n",
       " 'total_consumption_mwh',\n",
       " 'balancing_energy_volume_mwh',\n",
       " 'balancing_energy_price_euro/mwh',\n",
       " 'price_germany_euro/mwh']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(temp_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = master_data['price_germany_euro/mwh']\n",
    "#X = master_data.drop(['price_germany_euro/mwh','balancing_energy_price_euro/mwh'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"scaled_data[['biomass_mwh','hydropower_mwh','wind_offshore_mwh','wind_onshore_mwh','photovoltaics_mwh','other_renewable_mwh','nuclear_mwh','fossil_brown_coal_mwh','fossil_hard_coal_mwh','fossil_gas_mwh','hydro_pumped_storage_mwh','other_conventional_mwh','total_consumption_mwh','balancing_energy_volume_mwh','price_germany_euro/mwh']] = to_scale_data[['biomass_mwh','hydropower_mwh','wind_offshore_mwh','wind_onshore_mwh','photovoltaics_mwh','other_renewable_mwh','nuclear_mwh','fossil_brown_coal_mwh','fossil_hard_coal_mwh','fossil_gas_mwh','hydro_pumped_storage_mwh','other_conventional_mwh','total_consumption_mwh','balancing_energy_volume_mwh']].apply(\\n                           lambda x: scaler.fit_transform(x))\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'balancing_energy_price_euro/mwh' based on domain knowledge as this feature is not required\n",
    "\n",
    "y = temp_frame['price_germany_euro/mwh']\n",
    "X = temp_frame.drop(['price_germany_euro/mwh','balancing_energy_price_euro/mwh'], axis=1)\n",
    "\n",
    "# Use MinMaxScaler to scale\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=['biomass_mwh','hydropower_mwh','wind_offshore_mwh','wind_onshore_mwh','photovoltaics_mwh','other_renewable_mwh','nuclear_mwh','fossil_brown_coal_mwh','fossil_hard_coal_mwh','fossil_gas_mwh','hydro_pumped_storage_mwh','other_conventional_mwh','total_consumption_mwh','balancing_energy_volume_mwh'])\n",
    "#scaled_data = pd.DataFrame(scaled_data, columns=['biomass_mwh','hydropower_mwh','wind_offshore_mwh','wind_onshore_mwh','photovoltaics_mwh','other_renewable_mwh','nuclear_mwh','fossil_brown_coal_mwh','fossil_hard_coal_mwh','fossil_gas_mwh','hydro_pumped_storage_mwh','other_conventional_mwh','total_consumption_mwh','balancing_energy_volume_mwh','price_germany_euro/mwh','month','day'])\n",
    "\"\"\"scaled_data[['biomass_mwh','hydropower_mwh','wind_offshore_mwh','wind_onshore_mwh','photovoltaics_mwh','other_renewable_mwh','nuclear_mwh','fossil_brown_coal_mwh','fossil_hard_coal_mwh','fossil_gas_mwh','hydro_pumped_storage_mwh','other_conventional_mwh','total_consumption_mwh','balancing_energy_volume_mwh','price_germany_euro/mwh']] = to_scale_data[['biomass_mwh','hydropower_mwh','wind_offshore_mwh','wind_onshore_mwh','photovoltaics_mwh','other_renewable_mwh','nuclear_mwh','fossil_brown_coal_mwh','fossil_hard_coal_mwh','fossil_gas_mwh','hydro_pumped_storage_mwh','other_conventional_mwh','total_consumption_mwh','balancing_energy_volume_mwh']].apply(\n",
    "                           lambda x: scaler.fit_transform(x))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE Score =  4.953005879681329\n",
      "Average Prediction Accuracy = 0.424348335993258\n",
      "Execution time:  0.7210352420806885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# Perform Linear Regression using TimeSeriesSplit\n",
    "l_tscv = TimeSeriesSplit(n_splits=200)\n",
    "l_cv = l_tscv.split(X)\n",
    "\n",
    "l_reg = LinearRegression()\n",
    "rmse_list = []\n",
    "score_list = []\n",
    "\n",
    "# set start time\n",
    "start = time.time()\n",
    "\n",
    "for train_index, test_index in l_cv:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    l_reg.fit(X_train,y_train)\n",
    "    y_pred = l_reg.predict(X_test)\n",
    "    score = l_reg.score(X_test,y_test)\n",
    "    score_list.append(score)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# set end time\n",
    "end = time.time()\n",
    "\n",
    "print(\"Average RMSE Score = \",np.mean(rmse_list))\n",
    "print(\"Average Prediction Accuracy =\",np.mean(score_list))\n",
    "print(\"Execution time: \",end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result lists\n",
    "\n",
    "def run_pipeline(estimators, splits, X, y):\n",
    "    perf_summary = []\n",
    "    for est in estimators:\n",
    "        tscv = TimeSeriesSplit(n_splits = splits)\n",
    "        cv = tscv.split(X)\n",
    "        # Initialize regressor\n",
    "        perf = execute_regressor(est,X,y,cv)\n",
    "        #print(perf)\n",
    "        perf_summary.append(perf)\n",
    "    return perf_summary\n",
    "    \n",
    "def execute_regressor(reg, X, y, cv, **kwargs):\n",
    "    reg_perf = {}\n",
    "    rmse_list = []\n",
    "    score_list = []\n",
    "        \n",
    "    # record start\n",
    "    start = time.time()\n",
    "    \n",
    "    regressor = reg(**kwargs)\n",
    "        \n",
    "    for train_index, test_index in cv:\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        regressor.fit(X_train,y_train)\n",
    "        y_pred = regressor.predict(X_test)\n",
    "        score = regressor.score(X_test,y_test)\n",
    "        score_list.append(score)\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "        rmse_list.append(rmse) \n",
    "    \n",
    "    #record end time\n",
    "    end = time.time()\n",
    "    \n",
    "    reg_perf[\"name\"] = reg.__name__\n",
    "    reg_perf[\"train_time\"] = end - start\n",
    "    #reg_props[\"train_score\"] = regressor.score(X_train, y_train)\n",
    "    reg_perf[\"test_score\"] = np.mean(score_list)\n",
    "    reg_perf[\"rmse\"] = np.mean(rmse_list)\n",
    "    return reg_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "estimators = [Ridge, Lasso, RandomForestRegressor, SVR, GradientBoostingRegressor, LGBMRegressor, XGBRegressor]\n",
    "\n",
    "perf_list = run_pipeline(estimators, 70, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Ridge',\n",
       "  'rmse': 5.044569784392069,\n",
       "  'test_score': 0.5117790339269815,\n",
       "  'train_time': 0.23337531089782715},\n",
       " {'name': 'Lasso',\n",
       "  'rmse': 7.6638172655410175,\n",
       "  'test_score': -0.008370316949799683,\n",
       "  'train_time': 0.22240591049194336},\n",
       " {'name': 'RandomForestRegressor',\n",
       "  'rmse': 4.777211035587882,\n",
       "  'test_score': 0.6010472797967422,\n",
       "  'train_time': 32.0055456161499},\n",
       " {'name': 'SVR',\n",
       "  'rmse': 5.3033759032934285,\n",
       "  'test_score': 0.4863931237391187,\n",
       "  'train_time': 135.92159748077393},\n",
       " {'name': 'GradientBoostingRegressor',\n",
       "  'rmse': 4.3937678578547485,\n",
       "  'test_score': 0.6497670632302275,\n",
       "  'train_time': 32.711554288864136},\n",
       " {'name': 'LGBMRegressor',\n",
       "  'rmse': 4.282955064463353,\n",
       "  'test_score': 0.6791830685524011,\n",
       "  'train_time': 14.575279235839844},\n",
       " {'name': 'XGBRegressor',\n",
       "  'rmse': 4.3631840982237815,\n",
       "  'test_score': 0.6552920568004902,\n",
       "  'train_time': 23.95296883583069}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 70 folds for each of 27 candidates, totalling 1890 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1890 out of 1890 | elapsed: 23.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LGBM Parameters : {'boosting': 'dart', 'max_depth': 10, 'min_data': 1, 'min_data_in_bin': 1, 'min_data_in_leaf': 60, 'num_leaves': 100}\n",
      "LGB Score =  0.46676657243836983\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(min_data=1)\n",
    "#lgbm_param = {'num_leaves': [10, 100, 1000],'min_data_in_leaf': [100, 500, 1000],'max_depth': [5, 50, 100]}\n",
    "lgbm_param = {'min_data': [1],'min_data_in_bin':[1],'num_leaves': [100, 200, 300],'min_data_in_leaf': [60,70,100],'max_depth': [10,30,40]}\n",
    "tscv = TimeSeriesSplit(n_splits=70)\n",
    "cv = tscv.split(X)\n",
    "lgbm_cv = GridSearchCV(lgbm, lgbm_param, cv=cv, verbose=1)\n",
    "lgbm_cv.fit(X,y)\n",
    "lgbm_cv.best_params_\n",
    "lgbm_result = lgbm_cv.cv_results_\n",
    "print(\"Best LGBM Parameters :\",lgbm_cv.best_params_)\n",
    "print(\"LGB Score = \",lgbm_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=8, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=8, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "230/230 [==============================] - 0s 850us/step - loss: 918.3263 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 916.2060 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 912.5035 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "230/230 [==============================] - 0s 87us/step - loss: 905.7415 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 894.1220 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 876.0097 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 849.3820 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "230/230 [==============================] - 0s 78us/step - loss: 813.0908 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 766.4065 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "230/230 [==============================] - 0s 78us/step - loss: 708.3526 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 641.2784 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "230/230 [==============================] - 0s 82us/step - loss: 565.4678 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 484.7119 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 401.5810 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 320.8333 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "230/230 [==============================] - 0s 117us/step - loss: 248.1167 - acc: 0.0043\n",
      "Epoch 17/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 183.0448 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 132.7426 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 94.4388 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 69.2547 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 53.4024 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "230/230 [==============================] - 0s 126us/step - loss: 44.6045 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 40.7190 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "230/230 [==============================] - 0s 126us/step - loss: 38.4976 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "230/230 [==============================] - ETA: 0s - loss: 72.1125 - acc: 0.0000e+ - 0s 87us/step - loss: 37.6330 - acc: 0.0043\n",
      "Epoch 26/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 37.2902 - acc: 0.0087\n",
      "Epoch 27/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 37.1742 - acc: 0.0087\n",
      "Epoch 28/100\n",
      "230/230 [==============================] - 0s 82us/step - loss: 36.9805 - acc: 0.0087\n",
      "Epoch 29/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 36.9109 - acc: 0.0087\n",
      "Epoch 30/100\n",
      "230/230 [==============================] - 0s 82us/step - loss: 36.8080 - acc: 0.0087\n",
      "Epoch 31/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 36.7314 - acc: 0.0087\n",
      "Epoch 32/100\n",
      "230/230 [==============================] - 0s 117us/step - loss: 36.7315 - acc: 0.0087\n",
      "Epoch 33/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 36.5721 - acc: 0.0087\n",
      "Epoch 34/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 36.5123 - acc: 0.0087\n",
      "Epoch 35/100\n",
      "230/230 [==============================] - 0s 82us/step - loss: 36.3901 - acc: 0.0087\n",
      "Epoch 36/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 36.3362 - acc: 0.0087\n",
      "Epoch 37/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 36.2323 - acc: 0.0087\n",
      "Epoch 38/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 36.1479 - acc: 0.0087\n",
      "Epoch 39/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 36.0801 - acc: 0.0087\n",
      "Epoch 40/100\n",
      "230/230 [==============================] - 0s 91us/step - loss: 35.9815 - acc: 0.0087\n",
      "Epoch 41/100\n",
      "230/230 [==============================] - 0s 121us/step - loss: 35.8943 - acc: 0.0087\n",
      "Epoch 42/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 35.8174 - acc: 0.0087\n",
      "Epoch 43/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 35.7176 - acc: 0.0087\n",
      "Epoch 44/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 35.7219 - acc: 0.0087\n",
      "Epoch 45/100\n",
      "230/230 [==============================] - 0s 87us/step - loss: 35.5688 - acc: 0.0087\n",
      "Epoch 46/100\n",
      "230/230 [==============================] - 0s 143us/step - loss: 35.4524 - acc: 0.0087\n",
      "Epoch 47/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 35.4040 - acc: 0.0087\n",
      "Epoch 48/100\n",
      "230/230 [==============================] - 0s 126us/step - loss: 35.3143 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 35.2123 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 35.1108 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "230/230 [==============================] - 0s 87us/step - loss: 35.0942 - acc: 0.0043\n",
      "Epoch 52/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 34.9641 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "230/230 [==============================] - 0s 87us/step - loss: 34.8686 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "230/230 [==============================] - 0s 121us/step - loss: 34.9657 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 34.7974 - acc: 0.0043\n",
      "Epoch 56/100\n",
      "230/230 [==============================] - 0s 117us/step - loss: 34.7252 - acc: 0.0043\n",
      "Epoch 57/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 34.5028 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "230/230 [==============================] - 0s 87us/step - loss: 34.4229 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 34.3795 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "230/230 [==============================] - 0s 82us/step - loss: 34.2636 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 34.1949 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "230/230 [==============================] - 0s 87us/step - loss: 34.1765 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "230/230 [==============================] - 0s 139us/step - loss: 34.0076 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "230/230 [==============================] - 0s 87us/step - loss: 34.0023 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "230/230 [==============================] - 0s 91us/step - loss: 33.8562 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 33.8391 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 33.6950 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 33.6171 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "230/230 [==============================] - 0s 121us/step - loss: 33.5273 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 33.6235 - acc: 0.0043\n",
      "Epoch 71/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 33.3600 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "230/230 [==============================] - 0s 82us/step - loss: 33.2801 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 33.2445 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "230/230 [==============================] - 0s 91us/step - loss: 33.1814 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 33.0819 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "230/230 [==============================] - 0s 87us/step - loss: 32.9963 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "230/230 [==============================] - 0s 82us/step - loss: 32.9003 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 32.9967 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "230/230 [==============================] - 0s 117us/step - loss: 32.7142 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "230/230 [==============================] - 0s 91us/step - loss: 32.6648 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "230/230 [==============================] - 0s 139us/step - loss: 32.5691 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 32.5469 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 32.4943 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 32.3507 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "230/230 [==============================] - 0s 100us/step - loss: 32.2623 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 32.1992 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 32.1377 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "230/230 [==============================] - 0s 117us/step - loss: 32.1906 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "230/230 [==============================] - 0s 82us/step - loss: 31.9794 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 31.9395 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "230/230 [==============================] - 0s 95us/step - loss: 31.8631 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 31.8001 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 31.7281 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "230/230 [==============================] - 0s 104us/step - loss: 31.6275 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "230/230 [==============================] - 0s 130us/step - loss: 31.6177 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 31.5213 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 31.4131 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "230/230 [==============================] - 0s 113us/step - loss: 31.4607 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "230/230 [==============================] - 0s 108us/step - loss: 31.3628 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "230/230 [==============================] - 0s 117us/step - loss: 31.2467 - acc: 0.0000e+00\n",
      "172/172 [==============================] - 0s 278us/step\n",
      "Epoch 1/100\n",
      "402/402 [==============================] - 0s 79us/step - loss: 28.4241 - acc: 0.0025\n",
      "Epoch 2/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 28.0248 - acc: 0.0025\n",
      "Epoch 3/100\n",
      "402/402 [==============================] - 0s 82us/step - loss: 27.9832 - acc: 0.0025\n",
      "Epoch 4/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 27.7815 - acc: 0.0025\n",
      "Epoch 5/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 27.6614 - acc: 0.0025\n",
      "Epoch 6/100\n",
      " 10/402 [..............................] - ETA: 0s - loss: 1.5781 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 94us/step - loss: 27.5380 - acc: 0.0025\n",
      "Epoch 7/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 27.4443 - acc: 0.0025\n",
      "Epoch 8/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 27.2884 - acc: 0.0025\n",
      "Epoch 9/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 27.2095 - acc: 0.0025\n",
      "Epoch 10/100\n",
      "402/402 [==============================] - 0s 109us/step - loss: 27.0766 - acc: 0.0025\n",
      "Epoch 11/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 26.9610 - acc: 0.0025\n",
      "Epoch 12/100\n",
      "402/402 [==============================] - 0s 77us/step - loss: 26.8655 - acc: 0.0025\n",
      "Epoch 13/100\n",
      "402/402 [==============================] - 0s 104us/step - loss: 26.8673 - acc: 0.0025\n",
      "Epoch 14/100\n",
      "402/402 [==============================] - 0s 82us/step - loss: 26.6680 - acc: 0.0025\n",
      "Epoch 15/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 26.4982 - acc: 0.0025\n",
      "Epoch 16/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 26.3962 - acc: 0.0025\n",
      "Epoch 17/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 26.3588 - acc: 0.0025\n",
      "Epoch 18/100\n",
      "402/402 [==============================] - 0s 82us/step - loss: 26.1934 - acc: 0.0025\n",
      "Epoch 19/100\n",
      "402/402 [==============================] - 0s 99us/step - loss: 26.1214 - acc: 0.0025\n",
      "Epoch 20/100\n",
      "402/402 [==============================] - 0s 99us/step - loss: 26.0201 - acc: 0.0025\n",
      "Epoch 21/100\n",
      "402/402 [==============================] - 0s 127us/step - loss: 25.9293 - acc: 0.0025\n",
      "Epoch 22/100\n",
      "402/402 [==============================] - 0s 112us/step - loss: 25.8254 - acc: 0.0025\n",
      "Epoch 23/100\n",
      "402/402 [==============================] - 0s 122us/step - loss: 25.7564 - acc: 0.0025\n",
      "Epoch 24/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 25.7102 - acc: 0.0025\n",
      "Epoch 25/100\n",
      "402/402 [==============================] - 0s 117us/step - loss: 25.5043 - acc: 0.0025\n",
      "Epoch 26/100\n",
      "402/402 [==============================] - 0s 122us/step - loss: 25.4166 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 25.3839 - acc: 0.0025\n",
      "Epoch 28/100\n",
      "402/402 [==============================] - 0s 119us/step - loss: 25.2985 - acc: 0.0025\n",
      "Epoch 29/100\n",
      "402/402 [==============================] - 0s 104us/step - loss: 25.1905 - acc: 0.0025\n",
      "Epoch 30/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 25.2242 - acc: 0.0025\n",
      "Epoch 31/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 25.0275 - acc: 0.0025\n",
      "Epoch 32/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 24.9939 - acc: 0.0025\n",
      "Epoch 33/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 24.8225 - acc: 0.0025\n",
      "Epoch 34/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 24.7689 - acc: 0.0025\n",
      "Epoch 35/100\n",
      "402/402 [==============================] - 0s 102us/step - loss: 24.7158 - acc: 0.0025\n",
      "Epoch 36/100\n",
      "402/402 [==============================] - 0s 82us/step - loss: 24.6919 - acc: 0.0025\n",
      "Epoch 37/100\n",
      "402/402 [==============================] - 0s 102us/step - loss: 24.5426 - acc: 0.0050\n",
      "Epoch 38/100\n",
      "402/402 [==============================] - 0s 107us/step - loss: 24.5181 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 24.4210 - acc: 0.0050\n",
      "Epoch 40/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 24.3722 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "402/402 [==============================] - 0s 74us/step - loss: 24.3115 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 24.2736 - acc: 0.0050\n",
      "Epoch 43/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 24.2828 - acc: 0.0025\n",
      "Epoch 44/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 24.0874 - acc: 0.0050\n",
      "Epoch 45/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 24.0618 - acc: 0.0050\n",
      "Epoch 46/100\n",
      "402/402 [==============================] - 0s 104us/step - loss: 23.9967 - acc: 0.0050\n",
      "Epoch 47/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 23.9087 - acc: 0.0050\n",
      "Epoch 48/100\n",
      "402/402 [==============================] - 0s 102us/step - loss: 23.9279 - acc: 0.0025\n",
      "Epoch 49/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 23.8155 - acc: 0.0025\n",
      "Epoch 50/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 23.7187 - acc: 0.0050\n",
      "Epoch 51/100\n",
      "402/402 [==============================] - 0s 107us/step - loss: 23.6480 - acc: 0.0025\n",
      "Epoch 52/100\n",
      "402/402 [==============================] - 0s 109us/step - loss: 23.5949 - acc: 0.0050\n",
      "Epoch 53/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 23.5633 - acc: 0.0050\n",
      "Epoch 54/100\n",
      "402/402 [==============================] - 0s 112us/step - loss: 23.5030 - acc: 0.0025\n",
      "Epoch 55/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 23.4887 - acc: 0.0050\n",
      "Epoch 56/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 23.3372 - acc: 0.0050\n",
      "Epoch 57/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 23.2799 - acc: 0.0025\n",
      "Epoch 58/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 23.2478 - acc: 0.0050\n",
      "Epoch 59/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 23.2149 - acc: 0.0050\n",
      "Epoch 60/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 23.1877 - acc: 0.0050\n",
      "Epoch 61/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 23.1392 - acc: 0.0050\n",
      "Epoch 62/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 23.0747 - acc: 0.0025\n",
      "Epoch 63/100\n",
      "402/402 [==============================] - 0s 99us/step - loss: 23.0269 - acc: 0.0050\n",
      "Epoch 64/100\n",
      "402/402 [==============================] - 0s 104us/step - loss: 23.0377 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 23.0102 - acc: 0.0025\n",
      "Epoch 66/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 22.8907 - acc: 0.0025\n",
      "Epoch 67/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 22.9273 - acc: 0.0025\n",
      "Epoch 68/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 22.8816 - acc: 0.0050\n",
      "Epoch 69/100\n",
      "402/402 [==============================] - 0s 99us/step - loss: 22.7527 - acc: 0.0050\n",
      "Epoch 70/100\n",
      "402/402 [==============================] - 0s 82us/step - loss: 22.7639 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 22.6984 - acc: 0.0050\n",
      "Epoch 72/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 22.6420 - acc: 0.0025\n",
      "Epoch 73/100\n",
      "402/402 [==============================] - 0s 82us/step - loss: 22.6312 - acc: 0.0025\n",
      "Epoch 74/100\n",
      "402/402 [==============================] - 0s 82us/step - loss: 22.5608 - acc: 0.0025\n",
      "Epoch 75/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 22.4891 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 22.5203 - acc: 0.0025\n",
      "Epoch 77/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 22.4323 - acc: 0.0025\n",
      "Epoch 78/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 22.3949 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 22.3423 - acc: 0.0025\n",
      "Epoch 80/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 22.3674 - acc: 0.0025\n",
      "Epoch 81/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 22.2488 - acc: 0.0025\n",
      "Epoch 82/100\n",
      "402/402 [==============================] - 0s 97us/step - loss: 22.2918 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 22.2092 - acc: 0.0025\n",
      "Epoch 84/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 22.2144 - acc: 0.0025\n",
      "Epoch 85/100\n",
      "402/402 [==============================] - 0s 79us/step - loss: 22.2078 - acc: 0.0050\n",
      "Epoch 86/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 22.1495 - acc: 0.0025\n",
      "Epoch 87/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 22.0712 - acc: 0.0025\n",
      "Epoch 88/100\n",
      "402/402 [==============================] - 0s 92us/step - loss: 22.1408 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 22.0944 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "402/402 [==============================] - 0s 87us/step - loss: 21.9694 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 21.9497 - acc: 0.0025\n",
      "Epoch 92/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 21.9532 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "402/402 [==============================] - 0s 82us/step - loss: 21.8300 - acc: 0.0025\n",
      "Epoch 94/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 21.7969 - acc: 0.0025\n",
      "Epoch 95/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 22.0256 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "402/402 [==============================] - 0s 84us/step - loss: 21.7465 - acc: 0.0025\n",
      "Epoch 97/100\n",
      "402/402 [==============================] - 0s 94us/step - loss: 21.7239 - acc: 0.0025\n",
      "Epoch 98/100\n",
      "402/402 [==============================] - 0s 79us/step - loss: 21.6771 - acc: 0.0025\n",
      "Epoch 99/100\n",
      "402/402 [==============================] - 0s 89us/step - loss: 21.6428 - acc: 0.0025\n",
      "Epoch 100/100\n",
      "402/402 [==============================] - 0s 102us/step - loss: 21.6922 - acc: 0.0025\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "574/574 [==============================] - 0s 85us/step - loss: 26.3307 - acc: 0.0017\n",
      "Epoch 2/100\n",
      "574/574 [==============================] - 0s 90us/step - loss: 26.2586 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 25.9616 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " 10/574 [..............................] - ETA: 0s - loss: 30.0778 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 99us/step - loss: 25.8009 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 25.6940 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "574/574 [==============================] - 0s 70us/step - loss: 25.6196 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 25.4319 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "574/574 [==============================] - 0s 75us/step - loss: 25.3924 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "574/574 [==============================] - 0s 73us/step - loss: 25.2715 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "574/574 [==============================] - 0s 71us/step - loss: 25.2019 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 25.0211 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "574/574 [==============================] - 0s 75us/step - loss: 24.9572 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 24.9240 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "574/574 [==============================] - 0s 73us/step - loss: 24.7899 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "574/574 [==============================] - 0s 89us/step - loss: 24.8011 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "574/574 [==============================] - 0s 89us/step - loss: 24.7359 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 24.6223 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "574/574 [==============================] - 0s 76us/step - loss: 24.6165 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "574/574 [==============================] - 0s 92us/step - loss: 24.5753 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "574/574 [==============================] - 0s 97us/step - loss: 24.5263 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 24.4191 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 24.4275 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "574/574 [==============================] - 0s 89us/step - loss: 24.4137 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 24.3831 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "574/574 [==============================] - 0s 85us/step - loss: 24.3262 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 24.4052 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 24.1758 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "574/574 [==============================] - 0s 89us/step - loss: 24.1458 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 24.2859 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "574/574 [==============================] - 0s 76us/step - loss: 24.1163 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 24.1043 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 24.1108 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 24.1826 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 24.0103 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "574/574 [==============================] - 0s 85us/step - loss: 23.9759 - acc: 0.0017\n",
      "Epoch 36/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 24.1157 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 23.9638 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 24.0765 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "574/574 [==============================] - 0s 75us/step - loss: 23.8619 - acc: 0.0017\n",
      "Epoch 40/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 23.8768 - acc: 0.0017\n",
      "Epoch 41/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 23.8472 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 23.8320 - acc: 0.0017\n",
      "Epoch 43/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 23.8477 - acc: 0.0017\n",
      "Epoch 44/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 23.8217 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 23.7175 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 23.8784 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 23.6862 - acc: 0.0017\n",
      "Epoch 48/100\n",
      "574/574 [==============================] - 0s 76us/step - loss: 23.6921 - acc: 0.0017\n",
      "Epoch 49/100\n",
      "574/574 [==============================] - 0s 76us/step - loss: 23.6750 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 23.6853 - acc: 0.0017\n",
      "Epoch 51/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 23.6178 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 23.5742 - acc: 0.0017\n",
      "Epoch 53/100\n",
      "574/574 [==============================] - 0s 90us/step - loss: 23.5509 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "574/574 [==============================] - 0s 75us/step - loss: 23.5546 - acc: 0.0017\n",
      "Epoch 55/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 23.7326 - acc: 0.0017\n",
      "Epoch 56/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 23.6077 - acc: 0.0035\n",
      "Epoch 57/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 23.5668 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "574/574 [==============================] - 0s 76us/step - loss: 23.4968 - acc: 0.0017\n",
      "Epoch 59/100\n",
      "574/574 [==============================] - 0s 85us/step - loss: 23.5538 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "574/574 [==============================] - 0s 75us/step - loss: 23.5356 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 23.3893 - acc: 0.0017\n",
      "Epoch 62/100\n",
      "574/574 [==============================] - 0s 85us/step - loss: 23.5256 - acc: 0.0017\n",
      "Epoch 63/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 23.6114 - acc: 0.0017\n",
      "Epoch 64/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 23.4155 - acc: 0.0017\n",
      "Epoch 65/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 23.4065 - acc: 0.0017\n",
      "Epoch 66/100\n",
      "574/574 [==============================] - 0s 76us/step - loss: 23.4761 - acc: 0.0017\n",
      "Epoch 67/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 23.3378 - acc: 0.0017\n",
      "Epoch 68/100\n",
      "574/574 [==============================] - 0s 90us/step - loss: 23.3396 - acc: 0.0017\n",
      "Epoch 69/100\n",
      "574/574 [==============================] - 0s 85us/step - loss: 23.3158 - acc: 0.0017\n",
      "Epoch 70/100\n",
      "574/574 [==============================] - 0s 89us/step - loss: 23.2485 - acc: 0.0017\n",
      "Epoch 71/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 23.2267 - acc: 0.0017\n",
      "Epoch 72/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 23.2394 - acc: 0.0017\n",
      "Epoch 73/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 23.2221 - acc: 0.0017\n",
      "Epoch 74/100\n",
      "574/574 [==============================] - 0s 90us/step - loss: 23.1854 - acc: 0.0017\n",
      "Epoch 75/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 23.2217 - acc: 0.0017\n",
      "Epoch 76/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 23.1970 - acc: 0.0017\n",
      "Epoch 77/100\n",
      "574/574 [==============================] - 0s 90us/step - loss: 23.2045 - acc: 0.0035\n",
      "Epoch 78/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 23.1782 - acc: 0.0017\n",
      "Epoch 79/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 23.0973 - acc: 0.0035\n",
      "Epoch 80/100\n",
      "574/574 [==============================] - 0s 82us/step - loss: 23.1987 - acc: 0.0017\n",
      "Epoch 81/100\n",
      "574/574 [==============================] - 0s 92us/step - loss: 23.0820 - acc: 0.0017\n",
      "Epoch 82/100\n",
      "574/574 [==============================] - 0s 90us/step - loss: 23.1322 - acc: 0.0017\n",
      "Epoch 83/100\n",
      "574/574 [==============================] - 0s 101us/step - loss: 22.9945 - acc: 0.0035\n",
      "Epoch 84/100\n",
      "574/574 [==============================] - 0s 89us/step - loss: 23.1217 - acc: 0.0017\n",
      "Epoch 85/100\n",
      "574/574 [==============================] - 0s 90us/step - loss: 23.0365 - acc: 0.0017\n",
      "Epoch 86/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 23.1980 - acc: 0.0017\n",
      "Epoch 87/100\n",
      "574/574 [==============================] - 0s 97us/step - loss: 23.0194 - acc: 0.0035\n",
      "Epoch 88/100\n",
      "574/574 [==============================] - 0s 87us/step - loss: 22.9262 - acc: 0.0017\n",
      "Epoch 89/100\n",
      "574/574 [==============================] - 0s 89us/step - loss: 22.9509 - acc: 0.0035\n",
      "Epoch 90/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 22.9628 - acc: 0.0017\n",
      "Epoch 91/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 22.8963 - acc: 0.0017\n",
      "Epoch 92/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 22.9008 - acc: 0.0035\n",
      "Epoch 93/100\n",
      "574/574 [==============================] - 0s 75us/step - loss: 22.8862 - acc: 0.0035\n",
      "Epoch 94/100\n",
      "574/574 [==============================] - 0s 76us/step - loss: 22.8690 - acc: 0.0035\n",
      "Epoch 95/100\n",
      "574/574 [==============================] - 0s 78us/step - loss: 22.8995 - acc: 0.0017\n",
      "Epoch 96/100\n",
      "574/574 [==============================] - 0s 75us/step - loss: 22.9847 - acc: 0.0017\n",
      "Epoch 97/100\n",
      "574/574 [==============================] - 0s 76us/step - loss: 22.8264 - acc: 0.0017\n",
      "Epoch 98/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 22.8787 - acc: 0.0017\n",
      "Epoch 99/100\n",
      "574/574 [==============================] - 0s 83us/step - loss: 22.8436 - acc: 0.0017\n",
      "Epoch 100/100\n",
      "574/574 [==============================] - 0s 80us/step - loss: 22.7502 - acc: 0.0035\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.8257 - acc: 0.0027\n",
      "Epoch 2/100\n",
      "746/746 [==============================] - 0s 76us/step - loss: 23.7978 - acc: 0.0027\n",
      "Epoch 3/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.7517 - acc: 0.0013\n",
      "Epoch 4/100\n",
      " 10/746 [..............................] - ETA: 0s - loss: 63.0959 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 0s 98us/step - loss: 23.7031 - acc: 0.0027\n",
      "Epoch 5/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 23.9153 - acc: 0.0013\n",
      "Epoch 6/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 23.7544 - acc: 0.0027\n",
      "Epoch 7/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 23.7353 - acc: 0.0027\n",
      "Epoch 8/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 23.6370 - acc: 0.0013\n",
      "Epoch 9/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.6126 - acc: 0.0027\n",
      "Epoch 10/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.5983 - acc: 0.0027\n",
      "Epoch 11/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 23.5947 - acc: 0.0027\n",
      "Epoch 12/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 23.5508 - acc: 0.0027\n",
      "Epoch 13/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 23.6409 - acc: 0.0027\n",
      "Epoch 14/100\n",
      "746/746 [==============================] - 0s 87us/step - loss: 23.5045 - acc: 0.0027\n",
      "Epoch 15/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 23.4205 - acc: 0.0013\n",
      "Epoch 16/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 23.5264 - acc: 0.0027\n",
      "Epoch 17/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 23.4579 - acc: 0.0027\n",
      "Epoch 18/100\n",
      "746/746 [==============================] - 0s 88us/step - loss: 23.4811 - acc: 0.0027\n",
      "Epoch 19/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 23.4596 - acc: 0.0027\n",
      "Epoch 20/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 23.4754 - acc: 0.0013\n",
      "Epoch 21/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 23.4522 - acc: 0.0027\n",
      "Epoch 22/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 23.3547 - acc: 0.0027\n",
      "Epoch 23/100\n",
      "746/746 [==============================] - 0s 87us/step - loss: 23.3238 - acc: 0.0027\n",
      "Epoch 24/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 23.4618 - acc: 0.0027\n",
      "Epoch 25/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.3876 - acc: 0.0027\n",
      "Epoch 26/100\n",
      "746/746 [==============================] - 0s 76us/step - loss: 23.2959 - acc: 0.0027\n",
      "Epoch 27/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 23.2526 - acc: 0.0027\n",
      "Epoch 28/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.2908 - acc: 0.0013\n",
      "Epoch 29/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.2774 - acc: 0.0013\n",
      "Epoch 30/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 23.1899 - acc: 0.0027\n",
      "Epoch 31/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.3900 - acc: 0.0013\n",
      "Epoch 32/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.3023 - acc: 0.0013\n",
      "Epoch 33/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 23.3792 - acc: 0.0027\n",
      "Epoch 34/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 23.1873 - acc: 0.0027\n",
      "Epoch 35/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.1898 - acc: 0.0027\n",
      "Epoch 36/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 23.1796 - acc: 0.0013\n",
      "Epoch 37/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 23.1633 - acc: 0.0013\n",
      "Epoch 38/100\n",
      "746/746 [==============================] - 0s 84us/step - loss: 23.1446 - acc: 0.0027\n",
      "Epoch 39/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 23.0920 - acc: 0.0027\n",
      "Epoch 40/100\n",
      "746/746 [==============================] - 0s 84us/step - loss: 23.1791 - acc: 0.0013\n",
      "Epoch 41/100\n",
      "746/746 [==============================] - 0s 76us/step - loss: 23.1044 - acc: 0.0027\n",
      "Epoch 42/100\n",
      "746/746 [==============================] - 0s 84us/step - loss: 23.0750 - acc: 0.0027\n",
      "Epoch 43/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 23.0764 - acc: 0.0013\n",
      "Epoch 44/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 23.0493 - acc: 0.0013\n",
      "Epoch 45/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 23.0556 - acc: 0.0013\n",
      "Epoch 46/100\n",
      "746/746 [==============================] - 0s 92us/step - loss: 23.1254 - acc: 0.0027\n",
      "Epoch 47/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 22.9958 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 22.9348 - acc: 0.0013\n",
      "Epoch 49/100\n",
      "746/746 [==============================] - 0s 84us/step - loss: 22.9909 - acc: 0.0013\n",
      "Epoch 50/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 22.9051 - acc: 0.0013\n",
      "Epoch 51/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 23.1108 - acc: 0.0013\n",
      "Epoch 52/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 22.9663 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "746/746 [==============================] - 0s 75us/step - loss: 22.9136 - acc: 0.0013\n",
      "Epoch 54/100\n",
      "746/746 [==============================] - 0s 90us/step - loss: 22.9365 - acc: 0.0013\n",
      "Epoch 55/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.8795 - acc: 0.0013\n",
      "Epoch 56/100\n",
      "746/746 [==============================] - 0s 88us/step - loss: 22.9374 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.8737 - acc: 0.0027\n",
      "Epoch 58/100\n",
      "746/746 [==============================] - 0s 87us/step - loss: 22.8519 - acc: 0.0013\n",
      "Epoch 59/100\n",
      "746/746 [==============================] - 0s 72us/step - loss: 22.8293 - acc: 0.0027\n",
      "Epoch 60/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.8156 - acc: 0.0013\n",
      "Epoch 61/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.8152 - acc: 0.0013\n",
      "Epoch 62/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.7729 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.8379 - acc: 0.0013\n",
      "Epoch 64/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.8995 - acc: 0.0013\n",
      "Epoch 65/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.7501 - acc: 0.0027\n",
      "Epoch 66/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.7120 - acc: 0.0013\n",
      "Epoch 67/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 22.7956 - acc: 0.0013\n",
      "Epoch 68/100\n",
      "746/746 [==============================] - 0s 72us/step - loss: 22.8645 - acc: 0.0013\n",
      "Epoch 69/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.7066 - acc: 0.0013\n",
      "Epoch 70/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.7300 - acc: 0.0013\n",
      "Epoch 71/100\n",
      "746/746 [==============================] - 0s 90us/step - loss: 22.7007 - acc: 0.0013\n",
      "Epoch 72/100\n",
      "746/746 [==============================] - 0s 87us/step - loss: 22.8158 - acc: 0.0013\n",
      "Epoch 73/100\n",
      "746/746 [==============================] - 0s 87us/step - loss: 22.7661 - acc: 0.0013\n",
      "Epoch 74/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.7627 - acc: 0.0013\n",
      "Epoch 75/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 22.6421 - acc: 0.0013\n",
      "Epoch 76/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 22.7898 - acc: 0.0013\n",
      "Epoch 77/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 22.6700 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 22.6555 - acc: 0.0013\n",
      "Epoch 79/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.6884 - acc: 0.0027\n",
      "Epoch 80/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 22.5600 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 22.5819 - acc: 0.0013\n",
      "Epoch 82/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.6557 - acc: 0.0013\n",
      "Epoch 83/100\n",
      "746/746 [==============================] - 0s 84us/step - loss: 22.6781 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 22.5281 - acc: 0.0013\n",
      "Epoch 85/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 22.6839 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.5308 - acc: 0.0013\n",
      "Epoch 87/100\n",
      "746/746 [==============================] - 0s 88us/step - loss: 22.5264 - acc: 0.0013\n",
      "Epoch 88/100\n",
      "746/746 [==============================] - 0s 75us/step - loss: 22.5098 - acc: 0.0013\n",
      "Epoch 89/100\n",
      "746/746 [==============================] - 0s 84us/step - loss: 22.5797 - acc: 0.0013\n",
      "Epoch 90/100\n",
      "746/746 [==============================] - 0s 75us/step - loss: 22.6773 - acc: 0.0013\n",
      "Epoch 91/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 22.5296 - acc: 0.0013\n",
      "Epoch 92/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 22.5223 - acc: 0.0013\n",
      "Epoch 93/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.7717 - acc: 0.0013\n",
      "Epoch 94/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.4826 - acc: 0.0013\n",
      "Epoch 95/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 22.4900 - acc: 0.0013\n",
      "Epoch 96/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 22.4201 - acc: 0.0013\n",
      "Epoch 97/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 22.4831 - acc: 0.0027\n",
      "Epoch 98/100\n",
      "746/746 [==============================] - 0s 79us/step - loss: 22.4229 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 22.5096 - acc: 0.0027\n",
      "Epoch 100/100\n",
      "746/746 [==============================] - 0s 88us/step - loss: 22.4046 - acc: 0.0000e+00\n",
      "172/172 [==============================] - 0s 46us/step\n",
      "Epoch 1/100\n",
      "918/918 [==============================] - 0s 73us/step - loss: 26.6476 - acc: 0.0011\n",
      "Epoch 2/100\n",
      "918/918 [==============================] - 0s 77us/step - loss: 26.3069 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "690/918 [=====================>........] - ETA: 0s - loss: 25.7142 - acc: 0.0014    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918/918 [==============================] - 0s 86us/step - loss: 26.2019 - acc: 0.0011\n",
      "Epoch 4/100\n",
      "918/918 [==============================] - 0s 84us/step - loss: 26.0149 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "918/918 [==============================] - 0s 86us/step - loss: 25.9953 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "918/918 [==============================] - 0s 71us/step - loss: 25.9066 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.8861 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.7632 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.7087 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "918/918 [==============================] - 0s 75us/step - loss: 25.7371 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "918/918 [==============================] - 0s 85us/step - loss: 25.6477 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "918/918 [==============================] - 0s 75us/step - loss: 25.6231 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "918/918 [==============================] - 0s 75us/step - loss: 25.6267 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.5978 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "918/918 [==============================] - 0s 77us/step - loss: 25.5429 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "918/918 [==============================] - 0s 73us/step - loss: 25.7501 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "918/918 [==============================] - 0s 84us/step - loss: 25.4299 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "918/918 [==============================] - 0s 81us/step - loss: 25.6189 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.5027 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "918/918 [==============================] - 0s 73us/step - loss: 25.4386 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "918/918 [==============================] - 0s 79us/step - loss: 25.4548 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "918/918 [==============================] - 0s 71us/step - loss: 25.5004 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.4006 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "918/918 [==============================] - 0s 73us/step - loss: 25.4103 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.3808 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "918/918 [==============================] - 0s 83us/step - loss: 25.5418 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.4039 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "918/918 [==============================] - 0s 83us/step - loss: 25.4838 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "918/918 [==============================] - 0s 72us/step - loss: 25.3217 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "918/918 [==============================] - 0s 77us/step - loss: 25.3899 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "918/918 [==============================] - 0s 77us/step - loss: 25.3424 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.3926 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "918/918 [==============================] - 0s 79us/step - loss: 25.3924 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "918/918 [==============================] - 0s 74us/step - loss: 25.3370 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "918/918 [==============================] - 0s 77us/step - loss: 25.2963 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "918/918 [==============================] - 0s 78us/step - loss: 25.2839 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "918/918 [==============================] - 0s 88us/step - loss: 25.2496 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "918/918 [==============================] - 0s 73us/step - loss: 25.3266 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.2331 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "918/918 [==============================] - 0s 74us/step - loss: 25.3680 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "918/918 [==============================] - 0s 78us/step - loss: 25.2570 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.2481 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "918/918 [==============================] - 0s 78us/step - loss: 25.2005 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "918/918 [==============================] - 0s 77us/step - loss: 25.2315 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "918/918 [==============================] - 0s 75us/step - loss: 25.2448 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "918/918 [==============================] - 0s 77us/step - loss: 25.2166 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.1100 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "918/918 [==============================] - 0s 75us/step - loss: 25.1156 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.1656 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "918/918 [==============================] - 0s 74us/step - loss: 25.1469 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "918/918 [==============================] - 0s 79us/step - loss: 25.1581 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "918/918 [==============================] - 0s 74us/step - loss: 25.0954 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.1013 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.1609 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "918/918 [==============================] - 0s 81us/step - loss: 25.1087 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "918/918 [==============================] - 0s 75us/step - loss: 25.1189 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "918/918 [==============================] - 0s 85us/step - loss: 25.0545 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "918/918 [==============================] - 0s 76us/step - loss: 25.0503 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "918/918 [==============================] - 0s 84us/step - loss: 25.0360 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "918/918 [==============================] - 0s 84us/step - loss: 25.0345 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "918/918 [==============================] - 0s 84us/step - loss: 25.0169 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "918/918 [==============================] - 0s 77us/step - loss: 25.0702 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "918/918 [==============================] - 0s 86us/step - loss: 24.9652 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.0075 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.0421 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 25.0060 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "918/918 [==============================] - 0s 81us/step - loss: 24.9191 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "918/918 [==============================] - 0s 83us/step - loss: 24.9537 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "918/918 [==============================] - 0s 85us/step - loss: 25.0449 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "918/918 [==============================] - 0s 92us/step - loss: 25.0437 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "918/918 [==============================] - 0s 79us/step - loss: 24.8672 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "918/918 [==============================] - 0s 83us/step - loss: 25.0691 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "918/918 [==============================] - 0s 86us/step - loss: 24.9962 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "918/918 [==============================] - 0s 81us/step - loss: 24.9783 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "918/918 [==============================] - 0s 79us/step - loss: 24.8778 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "918/918 [==============================] - 0s 86us/step - loss: 24.8927 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "918/918 [==============================] - 0s 74us/step - loss: 24.9235 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "918/918 [==============================] - 0s 88us/step - loss: 24.8731 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "918/918 [==============================] - 0s 98us/step - loss: 24.9630 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "918/918 [==============================] - 0s 81us/step - loss: 24.9118 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "918/918 [==============================] - 0s 89us/step - loss: 24.9525 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "918/918 [==============================] - 0s 80us/step - loss: 24.9245 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "918/918 [==============================] - 0s 95us/step - loss: 24.8517 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "918/918 [==============================] - 0s 109us/step - loss: 25.0189 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "918/918 [==============================] - 0s 110us/step - loss: 24.8723 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "918/918 [==============================] - 0s 109us/step - loss: 24.8970 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "918/918 [==============================] - 0s 88us/step - loss: 24.9186 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "918/918 [==============================] - 0s 84us/step - loss: 24.8625 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "918/918 [==============================] - 0s 84us/step - loss: 24.8026 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "918/918 [==============================] - 0s 86us/step - loss: 24.8357 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "918/918 [==============================] - 0s 83us/step - loss: 24.8073 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "918/918 [==============================] - 0s 90us/step - loss: 24.8273 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "918/918 [==============================] - 0s 85us/step - loss: 24.8338 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "918/918 [==============================] - 0s 74us/step - loss: 24.7414 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "918/918 [==============================] - 0s 89us/step - loss: 24.8687 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "918/918 [==============================] - 0s 81us/step - loss: 24.8332 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "918/918 [==============================] - 0s 73us/step - loss: 24.8142 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "918/918 [==============================] - 0s 79us/step - loss: 24.7027 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "918/918 [==============================] - 0s 75us/step - loss: 24.7370 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "918/918 [==============================] - 0s 81us/step - loss: 24.7279 - acc: 0.0000e+00\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "1090/1090 [==============================] - 0s 98us/step - loss: 25.9826 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " 500/1090 [============>.................] - ETA: 0s - loss: 27.7605 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090/1090 [==============================] - 0s 100us/step - loss: 25.8889 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1090/1090 [==============================] - 0s 87us/step - loss: 25.8722 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1090/1090 [==============================] - 0s 93us/step - loss: 25.9372 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1090/1090 [==============================] - 0s 106us/step - loss: 25.7615 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1090/1090 [==============================] - 0s 99us/step - loss: 25.8380 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1090/1090 [==============================] - 0s 95us/step - loss: 25.7914 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1090/1090 [==============================] - 0s 99us/step - loss: 25.6866 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1090/1090 [==============================] - 0s 89us/step - loss: 25.8380 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1090/1090 [==============================] - 0s 85us/step - loss: 25.7030 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1090/1090 [==============================] - 0s 82us/step - loss: 25.6290 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 25.6458 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1090/1090 [==============================] - 0s 87us/step - loss: 25.6238 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 25.5797 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1090/1090 [==============================] - 0s 87us/step - loss: 25.5632 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 25.6591 - acc: 9.1743e-04\n",
      "Epoch 17/100\n",
      "1090/1090 [==============================] - 0s 80us/step - loss: 25.5274 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1090/1090 [==============================] - 0s 87us/step - loss: 25.4495 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1090/1090 [==============================] - 0s 83us/step - loss: 25.6257 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 25.5599 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1090/1090 [==============================] - 0s 85us/step - loss: 25.5022 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1090/1090 [==============================] - 0s 83us/step - loss: 25.6267 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1090/1090 [==============================] - 0s 74us/step - loss: 25.5034 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1090/1090 [==============================] - 0s 74us/step - loss: 25.4271 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1090/1090 [==============================] - 0s 73us/step - loss: 25.4356 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1090/1090 [==============================] - 0s 80us/step - loss: 25.4039 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 25.2962 - acc: 9.1743e-04\n",
      "Epoch 28/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 25.4326 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1090/1090 [==============================] - 0s 76us/step - loss: 25.2930 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 25.3313 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1090/1090 [==============================] - 0s 76us/step - loss: 25.2398 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1090/1090 [==============================] - 0s 84us/step - loss: 25.1596 - acc: 9.1743e-04\n",
      "Epoch 33/100\n",
      "1090/1090 [==============================] - 0s 85us/step - loss: 25.3665 - acc: 9.1743e-04\n",
      "Epoch 34/100\n",
      "1090/1090 [==============================] - 0s 74us/step - loss: 25.2982 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 25.1716 - acc: 9.1743e-04\n",
      "Epoch 36/100\n",
      "1090/1090 [==============================] - 0s 73us/step - loss: 25.2754 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 25.2958 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1090/1090 [==============================] - 0s 87us/step - loss: 25.1203 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1090/1090 [==============================] - 0s 69us/step - loss: 25.2610 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1090/1090 [==============================] - 0s 83us/step - loss: 25.3447 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1090/1090 [==============================] - 0s 75us/step - loss: 25.1945 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1090/1090 [==============================] - 0s 78us/step - loss: 25.1829 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1090/1090 [==============================] - 0s 82us/step - loss: 25.2293 - acc: 9.1743e-04\n",
      "Epoch 44/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 25.0696 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1090/1090 [==============================] - 0s 76us/step - loss: 25.0601 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1090/1090 [==============================] - 0s 90us/step - loss: 25.1062 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 25.0578 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1090/1090 [==============================] - 0s 83us/step - loss: 25.0342 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1090/1090 [==============================] - 0s 76us/step - loss: 25.0479 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1090/1090 [==============================] - 0s 83us/step - loss: 25.0946 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1090/1090 [==============================] - 0s 80us/step - loss: 24.9895 - acc: 9.1743e-04\n",
      "Epoch 52/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 25.0014 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1090/1090 [==============================] - 0s 72us/step - loss: 24.9828 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1090/1090 [==============================] - 0s 82us/step - loss: 24.9737 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 24.9798 - acc: 9.1743e-04\n",
      "Epoch 56/100\n",
      "1090/1090 [==============================] - 0s 83us/step - loss: 25.0209 - acc: 9.1743e-04\n",
      "Epoch 57/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 25.0447 - acc: 9.1743e-04\n",
      "Epoch 58/100\n",
      "1090/1090 [==============================] - 0s 85us/step - loss: 24.8721 - acc: 9.1743e-04\n",
      "Epoch 59/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 24.9158 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1090/1090 [==============================] - 0s 73us/step - loss: 25.0432 - acc: 9.1743e-04\n",
      "Epoch 61/100\n",
      "1090/1090 [==============================] - 0s 82us/step - loss: 24.9528 - acc: 9.1743e-04\n",
      "Epoch 62/100\n",
      "1090/1090 [==============================] - 0s 70us/step - loss: 24.9424 - acc: 9.1743e-04\n",
      "Epoch 63/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 24.8921 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 24.8864 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1090/1090 [==============================] - 0s 85us/step - loss: 24.8952 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 24.9466 - acc: 9.1743e-04\n",
      "Epoch 67/100\n",
      "1090/1090 [==============================] - 0s 76us/step - loss: 24.8413 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 24.9963 - acc: 9.1743e-04\n",
      "Epoch 69/100\n",
      "1090/1090 [==============================] - 0s 84us/step - loss: 24.8768 - acc: 9.1743e-04\n",
      "Epoch 70/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 24.9131 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1090/1090 [==============================] - 0s 75us/step - loss: 24.8660 - acc: 9.1743e-04\n",
      "Epoch 72/100\n",
      "1090/1090 [==============================] - 0s 82us/step - loss: 24.7462 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 24.8747 - acc: 9.1743e-04\n",
      "Epoch 74/100\n",
      "1090/1090 [==============================] - 0s 76us/step - loss: 24.8097 - acc: 9.1743e-04\n",
      "Epoch 75/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 24.7460 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1090/1090 [==============================] - 0s 74us/step - loss: 24.7373 - acc: 9.1743e-04\n",
      "Epoch 77/100\n",
      "1090/1090 [==============================] - 0s 88us/step - loss: 24.7170 - acc: 9.1743e-04\n",
      "Epoch 78/100\n",
      "1090/1090 [==============================] - 0s 76us/step - loss: 24.7423 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1090/1090 [==============================] - 0s 83us/step - loss: 24.7255 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1090/1090 [==============================] - 0s 85us/step - loss: 24.7715 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1090/1090 [==============================] - 0s 72us/step - loss: 24.6453 - acc: 9.1743e-04\n",
      "Epoch 82/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 24.6747 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 24.7844 - acc: 9.1743e-04\n",
      "Epoch 84/100\n",
      "1090/1090 [==============================] - 0s 80us/step - loss: 24.5803 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1090/1090 [==============================] - 0s 76us/step - loss: 24.7576 - acc: 9.1743e-04\n",
      "Epoch 86/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 24.7064 - acc: 9.1743e-04\n",
      "Epoch 87/100\n",
      "1090/1090 [==============================] - 0s 71us/step - loss: 24.7250 - acc: 9.1743e-04\n",
      "Epoch 88/100\n",
      "1090/1090 [==============================] - 0s 74us/step - loss: 24.6157 - acc: 9.1743e-04\n",
      "Epoch 89/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 24.5960 - acc: 9.1743e-04\n",
      "Epoch 90/100\n",
      "1090/1090 [==============================] - 0s 73us/step - loss: 24.6527 - acc: 9.1743e-04\n",
      "Epoch 91/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 24.7097 - acc: 9.1743e-04\n",
      "Epoch 92/100\n",
      "1090/1090 [==============================] - 0s 78us/step - loss: 24.7228 - acc: 9.1743e-04\n",
      "Epoch 93/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 24.5418 - acc: 9.1743e-04\n",
      "Epoch 94/100\n",
      "1090/1090 [==============================] - 0s 80us/step - loss: 24.6716 - acc: 9.1743e-04\n",
      "Epoch 95/100\n",
      "1090/1090 [==============================] - 0s 78us/step - loss: 24.5618 - acc: 9.1743e-04\n",
      "Epoch 96/100\n",
      "1090/1090 [==============================] - 0s 77us/step - loss: 24.5528 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1090/1090 [==============================] - 0s 68us/step - loss: 24.5723 - acc: 9.1743e-04\n",
      "Epoch 98/100\n",
      "1090/1090 [==============================] - 0s 81us/step - loss: 24.4647 - acc: 9.1743e-04\n",
      "Epoch 99/100\n",
      "1090/1090 [==============================] - 0s 79us/step - loss: 24.4649 - acc: 9.1743e-04\n",
      "Epoch 100/100\n",
      "1090/1090 [==============================] - 0s 72us/step - loss: 24.5165 - acc: 9.1743e-04\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 26.3261 - acc: 7.9239e-04\n",
      "Epoch 2/100\n",
      "1262/1262 [==============================] - 0s 78us/step - loss: 26.1827 - acc: 7.9239e-04\n",
      "Epoch 3/100\n",
      "  10/1262 [..............................] - ETA: 0s - loss: 26.0471 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1262/1262 [==============================] - 0s 77us/step - loss: 25.9949 - acc: 7.9239e-04\n",
      "Epoch 4/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 25.9194 - acc: 7.9239e-04\n",
      "Epoch 5/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 25.7652 - acc: 0.0016\n",
      "Epoch 6/100\n",
      "1262/1262 [==============================] - 0s 63us/step - loss: 25.8730 - acc: 7.9239e-04\n",
      "Epoch 7/100\n",
      "1262/1262 [==============================] - 0s 68us/step - loss: 25.6216 - acc: 7.9239e-04\n",
      "Epoch 8/100\n",
      "1262/1262 [==============================] - 0s 89us/step - loss: 25.7210 - acc: 7.9239e-04\n",
      "Epoch 9/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 25.5312 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 25.4759 - acc: 7.9239e-04\n",
      "Epoch 11/100\n",
      "1262/1262 [==============================] - 0s 68us/step - loss: 25.3915 - acc: 7.9239e-04\n",
      "Epoch 12/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 25.2826 - acc: 7.9239e-04\n",
      "Epoch 13/100\n",
      "1262/1262 [==============================] - 0s 74us/step - loss: 25.2697 - acc: 7.9239e-04\n",
      "Epoch 14/100\n",
      "1262/1262 [==============================] - 0s 72us/step - loss: 25.2335 - acc: 0.0016\n",
      "Epoch 15/100\n",
      "1262/1262 [==============================] - 0s 70us/step - loss: 25.1197 - acc: 0.0016\n",
      "Epoch 16/100\n",
      "1262/1262 [==============================] - 0s 94us/step - loss: 24.9630 - acc: 7.9239e-04\n",
      "Epoch 17/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 25.2202 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 24.9701 - acc: 7.9239e-04\n",
      "Epoch 19/100\n",
      "1262/1262 [==============================] - 0s 75us/step - loss: 24.9300 - acc: 7.9239e-04\n",
      "Epoch 20/100\n",
      "1262/1262 [==============================] - 0s 70us/step - loss: 24.8653 - acc: 7.9239e-04\n",
      "Epoch 21/100\n",
      "1262/1262 [==============================] - 0s 74us/step - loss: 24.8495 - acc: 0.0016\n",
      "Epoch 22/100\n",
      "1262/1262 [==============================] - 0s 75us/step - loss: 24.7145 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 24.8076 - acc: 7.9239e-04\n",
      "Epoch 24/100\n",
      "1262/1262 [==============================] - 0s 71us/step - loss: 24.6719 - acc: 7.9239e-04\n",
      "Epoch 25/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 24.5822 - acc: 7.9239e-04\n",
      "Epoch 26/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 24.6441 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 24.6320 - acc: 7.9239e-04\n",
      "Epoch 28/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 24.5502 - acc: 7.9239e-04\n",
      "Epoch 29/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 24.4301 - acc: 7.9239e-04\n",
      "Epoch 30/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 24.3543 - acc: 7.9239e-04\n",
      "Epoch 31/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 24.4013 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 24.3063 - acc: 0.0016\n",
      "Epoch 33/100\n",
      "1262/1262 [==============================] - 0s 81us/step - loss: 24.2872 - acc: 7.9239e-04\n",
      "Epoch 34/100\n",
      "1262/1262 [==============================] - 0s 80us/step - loss: 24.2546 - acc: 7.9239e-04\n",
      "Epoch 35/100\n",
      "1262/1262 [==============================] - 0s 75us/step - loss: 24.1661 - acc: 7.9239e-04\n",
      "Epoch 36/100\n",
      "1262/1262 [==============================] - 0s 70us/step - loss: 24.1746 - acc: 7.9239e-04\n",
      "Epoch 37/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 24.1327 - acc: 0.0016\n",
      "Epoch 38/100\n",
      "1262/1262 [==============================] - 0s 78us/step - loss: 24.1051 - acc: 7.9239e-04\n",
      "Epoch 39/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 24.1281 - acc: 7.9239e-04\n",
      "Epoch 40/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 24.0538 - acc: 7.9239e-04\n",
      "Epoch 41/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 24.1114 - acc: 7.9239e-04\n",
      "Epoch 42/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 24.0883 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1262/1262 [==============================] - 0s 81us/step - loss: 24.0069 - acc: 7.9239e-04\n",
      "Epoch 44/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 23.9477 - acc: 0.0016\n",
      "Epoch 45/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 23.8955 - acc: 7.9239e-04\n",
      "Epoch 46/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 23.9754 - acc: 7.9239e-04\n",
      "Epoch 47/100\n",
      "1262/1262 [==============================] - 0s 74us/step - loss: 23.9110 - acc: 7.9239e-04\n",
      "Epoch 48/100\n",
      "1262/1262 [==============================] - 0s 78us/step - loss: 23.8723 - acc: 7.9239e-04\n",
      "Epoch 49/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 23.7751 - acc: 7.9239e-04\n",
      "Epoch 50/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 23.6614 - acc: 7.9239e-04\n",
      "Epoch 51/100\n",
      "1262/1262 [==============================] - 0s 78us/step - loss: 23.8625 - acc: 7.9239e-04\n",
      "Epoch 52/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 23.7399 - acc: 7.9239e-04\n",
      "Epoch 53/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 23.7008 - acc: 0.0016\n",
      "Epoch 54/100\n",
      "1262/1262 [==============================] - 0s 80us/step - loss: 23.5900 - acc: 7.9239e-04\n",
      "Epoch 55/100\n",
      "1262/1262 [==============================] - 0s 81us/step - loss: 23.4936 - acc: 7.9239e-04\n",
      "Epoch 56/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 23.5209 - acc: 7.9239e-04\n",
      "Epoch 57/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 23.4494 - acc: 7.9239e-04\n",
      "Epoch 58/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 23.4285 - acc: 7.9239e-04\n",
      "Epoch 59/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 23.4350 - acc: 7.9239e-04\n",
      "Epoch 60/100\n",
      "1262/1262 [==============================] - 0s 74us/step - loss: 23.4128 - acc: 7.9239e-04\n",
      "Epoch 61/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 23.3479 - acc: 7.9239e-04\n",
      "Epoch 62/100\n",
      "1262/1262 [==============================] - 0s 67us/step - loss: 23.3233 - acc: 7.9239e-04\n",
      "Epoch 63/100\n",
      "1262/1262 [==============================] - 0s 75us/step - loss: 23.4646 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 23.2366 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1262/1262 [==============================] - 0s 80us/step - loss: 23.1686 - acc: 7.9239e-04\n",
      "Epoch 66/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 23.2848 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1262/1262 [==============================] - 0s 81us/step - loss: 23.0709 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1262/1262 [==============================] - 0s 78us/step - loss: 23.2240 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 23.0626 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 23.0134 - acc: 7.9239e-04\n",
      "Epoch 71/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 23.0196 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1262/1262 [==============================] - 0s 78us/step - loss: 23.0326 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 22.9178 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1262/1262 [==============================] - 0s 78us/step - loss: 23.0711 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 22.8543 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1262/1262 [==============================] - 0s 80us/step - loss: 22.8112 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 22.8102 - acc: 7.9239e-04\n",
      "Epoch 78/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 22.7540 - acc: 7.9239e-04\n",
      "Epoch 79/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 22.7146 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 22.7243 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1262/1262 [==============================] - 0s 81us/step - loss: 22.5587 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1262/1262 [==============================] - 0s 75us/step - loss: 22.5810 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1262/1262 [==============================] - 0s 74us/step - loss: 22.6053 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 22.6546 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 22.5614 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 22.6645 - acc: 7.9239e-04\n",
      "Epoch 87/100\n",
      "1262/1262 [==============================] - 0s 82us/step - loss: 22.5450 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1262/1262 [==============================] - 0s 81us/step - loss: 22.5161 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1262/1262 [==============================] - 0s 76us/step - loss: 22.4523 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1262/1262 [==============================] - 0s 74us/step - loss: 22.4071 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1262/1262 [==============================] - 0s 78us/step - loss: 22.3334 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1262/1262 [==============================] - 0s 75us/step - loss: 22.3169 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1262/1262 [==============================] - 0s 73us/step - loss: 22.3005 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 22.4244 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1262/1262 [==============================] - 0s 83us/step - loss: 22.2938 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1262/1262 [==============================] - 0s 81us/step - loss: 22.2271 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1262/1262 [==============================] - 0s 86us/step - loss: 22.2361 - acc: 7.9239e-04\n",
      "Epoch 98/100\n",
      "1262/1262 [==============================] - 0s 77us/step - loss: 22.1220 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1262/1262 [==============================] - 0s 85us/step - loss: 22.2275 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1262/1262 [==============================] - 0s 79us/step - loss: 22.3090 - acc: 0.0000e+00\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "1434/1434 [==============================] - 0s 70us/step - loss: 23.8385 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " 720/1434 [==============>...............] - ETA: 0s - loss: 24.1539 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1434/1434 [==============================] - 0s 71us/step - loss: 23.7534 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 23.5606 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 23.5385 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 23.4692 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1434/1434 [==============================] - 0s 84us/step - loss: 23.5117 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 23.4754 - acc: 6.9735e-04\n",
      "Epoch 8/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 23.3532 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1434/1434 [==============================] - 0s 77us/step - loss: 23.2137 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1434/1434 [==============================] - 0s 75us/step - loss: 23.3559 - acc: 0.0014\n",
      "Epoch 11/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 23.2589 - acc: 6.9735e-04\n",
      "Epoch 12/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 23.1849 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 23.2747 - acc: 0.0014\n",
      "Epoch 14/100\n",
      "1434/1434 [==============================] - 0s 82us/step - loss: 23.2059 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 23.1197 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 23.0131 - acc: 0.0014\n",
      "Epoch 17/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 23.3000 - acc: 6.9735e-04\n",
      "Epoch 18/100\n",
      "1434/1434 [==============================] - 0s 80us/step - loss: 23.0848 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 23.0613 - acc: 6.9735e-04\n",
      "Epoch 20/100\n",
      "1434/1434 [==============================] - 0s 76us/step - loss: 22.9928 - acc: 6.9735e-04\n",
      "Epoch 21/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 22.9310 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 23.0104 - acc: 0.0014\n",
      "Epoch 23/100\n",
      "1434/1434 [==============================] - 0s 82us/step - loss: 22.9358 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1434/1434 [==============================] - 0s 96us/step - loss: 22.9276 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1434/1434 [==============================] - 0s 86us/step - loss: 22.8677 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1434/1434 [==============================] - 0s 77us/step - loss: 22.9401 - acc: 6.9735e-04\n",
      "Epoch 27/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.9382 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.8891 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.8928 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.8317 - acc: 6.9735e-04\n",
      "Epoch 31/100\n",
      "1434/1434 [==============================] - 0s 82us/step - loss: 22.8957 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1434/1434 [==============================] - 0s 80us/step - loss: 22.8972 - acc: 6.9735e-04\n",
      "Epoch 33/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.7653 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 22.8414 - acc: 0.0014\n",
      "Epoch 35/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.8356 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.6466 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1434/1434 [==============================] - 0s 73us/step - loss: 22.7916 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.6926 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.7498 - acc: 6.9735e-04\n",
      "Epoch 40/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 22.7285 - acc: 6.9735e-04\n",
      "Epoch 41/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.6625 - acc: 6.9735e-04\n",
      "Epoch 42/100\n",
      "1434/1434 [==============================] - 0s 90us/step - loss: 22.6825 - acc: 6.9735e-04\n",
      "Epoch 43/100\n",
      "1434/1434 [==============================] - 0s 87us/step - loss: 22.6345 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 22.5927 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.6889 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.6141 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1434/1434 [==============================] - 0s 80us/step - loss: 22.5441 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.5712 - acc: 6.9735e-04\n",
      "Epoch 49/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.6226 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.4805 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1434/1434 [==============================] - 0s 84us/step - loss: 22.5549 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1434/1434 [==============================] - 0s 82us/step - loss: 22.6229 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.6594 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.5050 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.4630 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1434/1434 [==============================] - 0s 84us/step - loss: 22.5296 - acc: 6.9735e-04\n",
      "Epoch 57/100\n",
      "1434/1434 [==============================] - 0s 85us/step - loss: 22.4242 - acc: 6.9735e-04\n",
      "Epoch 58/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 22.3844 - acc: 0.0014\n",
      "Epoch 59/100\n",
      "1434/1434 [==============================] - 0s 87us/step - loss: 22.4584 - acc: 0.0014\n",
      "Epoch 60/100\n",
      "1434/1434 [==============================] - 0s 80us/step - loss: 22.5412 - acc: 6.9735e-04\n",
      "Epoch 61/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.4157 - acc: 6.9735e-04\n",
      "Epoch 62/100\n",
      "1434/1434 [==============================] - 0s 82us/step - loss: 22.6080 - acc: 6.9735e-04\n",
      "Epoch 63/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 22.3693 - acc: 6.9735e-04\n",
      "Epoch 64/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 22.4426 - acc: 6.9735e-04\n",
      "Epoch 65/100\n",
      "1434/1434 [==============================] - 0s 82us/step - loss: 22.3543 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.7186 - acc: 6.9735e-04\n",
      "Epoch 67/100\n",
      "1434/1434 [==============================] - 0s 85us/step - loss: 22.4583 - acc: 6.9735e-04\n",
      "Epoch 68/100\n",
      "1434/1434 [==============================] - 0s 88us/step - loss: 22.4658 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.3678 - acc: 6.9735e-04\n",
      "Epoch 70/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.4816 - acc: 6.9735e-04\n",
      "Epoch 71/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.3551 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 22.4692 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1434/1434 [==============================] - 0s 82us/step - loss: 22.3720 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1434/1434 [==============================] - 0s 87us/step - loss: 22.3554 - acc: 6.9735e-04\n",
      "Epoch 75/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 22.3691 - acc: 6.9735e-04\n",
      "Epoch 76/100\n",
      "1434/1434 [==============================] - 0s 88us/step - loss: 22.3889 - acc: 6.9735e-04\n",
      "Epoch 77/100\n",
      "1434/1434 [==============================] - 0s 82us/step - loss: 22.4223 - acc: 6.9735e-04\n",
      "Epoch 78/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.2972 - acc: 6.9735e-04\n",
      "Epoch 79/100\n",
      "1434/1434 [==============================] - 0s 85us/step - loss: 22.2898 - acc: 6.9735e-04\n",
      "Epoch 80/100\n",
      "1434/1434 [==============================] - 0s 86us/step - loss: 22.5365 - acc: 6.9735e-04\n",
      "Epoch 81/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 22.2905 - acc: 0.0014\n",
      "Epoch 82/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.3958 - acc: 6.9735e-04\n",
      "Epoch 83/100\n",
      "1434/1434 [==============================] - 0s 77us/step - loss: 22.4723 - acc: 0.0014\n",
      "Epoch 84/100\n",
      "1434/1434 [==============================] - 0s 79us/step - loss: 22.3003 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1434/1434 [==============================] - 0s 83us/step - loss: 22.3312 - acc: 6.9735e-04\n",
      "Epoch 86/100\n",
      "1434/1434 [==============================] - 0s 76us/step - loss: 22.2650 - acc: 6.9735e-04\n",
      "Epoch 87/100\n",
      "1434/1434 [==============================] - 0s 75us/step - loss: 22.2379 - acc: 0.0014\n",
      "Epoch 88/100\n",
      "1434/1434 [==============================] - 0s 70us/step - loss: 22.3212 - acc: 6.9735e-04\n",
      "Epoch 89/100\n",
      "1434/1434 [==============================] - 0s 74us/step - loss: 22.2099 - acc: 0.0014\n",
      "Epoch 90/100\n",
      "1434/1434 [==============================] - 0s 77us/step - loss: 22.2497 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1434/1434 [==============================] - 0s 91us/step - loss: 22.1561 - acc: 6.9735e-04\n",
      "Epoch 92/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.2113 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1434/1434 [==============================] - 0s 80us/step - loss: 22.2701 - acc: 6.9735e-04\n",
      "Epoch 94/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.1917 - acc: 6.9735e-04\n",
      "Epoch 95/100\n",
      "1434/1434 [==============================] - 0s 80us/step - loss: 22.2866 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1434/1434 [==============================] - 0s 76us/step - loss: 22.1975 - acc: 6.9735e-04\n",
      "Epoch 97/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 22.1694 - acc: 6.9735e-04\n",
      "Epoch 98/100\n",
      "1434/1434 [==============================] - 0s 81us/step - loss: 22.2375 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1434/1434 [==============================] - 0s 80us/step - loss: 22.3096 - acc: 6.9735e-04\n",
      "Epoch 100/100\n",
      "1434/1434 [==============================] - 0s 78us/step - loss: 22.1985 - acc: 0.0014\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "1606/1606 [==============================] - 0s 77us/step - loss: 25.3393 - acc: 6.2267e-04\n",
      "Epoch 2/100\n",
      " 660/1606 [===========>..................] - ETA: 0s - loss: 27.0694 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606/1606 [==============================] - 0s 86us/step - loss: 24.9761 - acc: 6.2267e-04\n",
      "Epoch 3/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 24.4081 - acc: 6.2267e-04\n",
      "Epoch 4/100\n",
      "1606/1606 [==============================] - 0s 74us/step - loss: 24.4035 - acc: 6.2267e-04\n",
      "Epoch 5/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 24.2043 - acc: 6.2267e-04\n",
      "Epoch 6/100\n",
      "1606/1606 [==============================] - 0s 77us/step - loss: 24.0953 - acc: 6.2267e-04\n",
      "Epoch 7/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 24.0165 - acc: 0.0012\n",
      "Epoch 8/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 24.0436 - acc: 0.0012\n",
      "Epoch 9/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.8132 - acc: 0.0012\n",
      "Epoch 10/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 23.8665 - acc: 6.2267e-04\n",
      "Epoch 11/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.8031 - acc: 0.0012\n",
      "Epoch 12/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.7838 - acc: 0.0012\n",
      "Epoch 13/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 23.9275 - acc: 0.0012\n",
      "Epoch 14/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 23.7959 - acc: 6.2267e-04\n",
      "Epoch 15/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 23.7268 - acc: 0.0012\n",
      "Epoch 16/100\n",
      "1606/1606 [==============================] - 0s 85us/step - loss: 23.6152 - acc: 0.0012\n",
      "Epoch 17/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 23.5671 - acc: 6.2267e-04\n",
      "Epoch 18/100\n",
      "1606/1606 [==============================] - 0s 83us/step - loss: 23.6247 - acc: 0.0012\n",
      "Epoch 19/100\n",
      "1606/1606 [==============================] - 0s 74us/step - loss: 23.7110 - acc: 6.2267e-04\n",
      "Epoch 20/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 23.5902 - acc: 0.0012\n",
      "Epoch 21/100\n",
      "1606/1606 [==============================] - 0s 82us/step - loss: 23.5237 - acc: 6.2267e-04\n",
      "Epoch 22/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 23.5861 - acc: 0.0012\n",
      "Epoch 23/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.5545 - acc: 6.2267e-04\n",
      "Epoch 24/100\n",
      "1606/1606 [==============================] - 0s 85us/step - loss: 23.5303 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 23.6586 - acc: 0.0012\n",
      "Epoch 26/100\n",
      "1606/1606 [==============================] - 0s 84us/step - loss: 23.4998 - acc: 6.2267e-04\n",
      "Epoch 27/100\n",
      "1606/1606 [==============================] - 0s 83us/step - loss: 23.5205 - acc: 6.2267e-04\n",
      "Epoch 28/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 23.4314 - acc: 6.2267e-04\n",
      "Epoch 29/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.4059 - acc: 6.2267e-04\n",
      "Epoch 30/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 23.4311 - acc: 0.0012\n",
      "Epoch 31/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 23.4753 - acc: 0.0012\n",
      "Epoch 32/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 23.3501 - acc: 0.0012\n",
      "Epoch 33/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.4383 - acc: 6.2267e-04\n",
      "Epoch 34/100\n",
      "1606/1606 [==============================] - 0s 85us/step - loss: 23.4158 - acc: 0.0012\n",
      "Epoch 35/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 23.4259 - acc: 6.2267e-04\n",
      "Epoch 36/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.4662 - acc: 6.2267e-04\n",
      "Epoch 37/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.4115 - acc: 6.2267e-04\n",
      "Epoch 38/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 23.3402 - acc: 0.0019\n",
      "Epoch 39/100\n",
      "1606/1606 [==============================] - 0s 83us/step - loss: 23.3824 - acc: 0.0012\n",
      "Epoch 40/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 23.3313 - acc: 0.0012\n",
      "Epoch 41/100\n",
      "1606/1606 [==============================] - 0s 77us/step - loss: 23.4941 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1606/1606 [==============================] - 0s 80us/step - loss: 23.2300 - acc: 0.0012\n",
      "Epoch 43/100\n",
      "1606/1606 [==============================] - 0s 82us/step - loss: 23.3332 - acc: 6.2267e-04\n",
      "Epoch 44/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 23.2212 - acc: 0.0012\n",
      "Epoch 45/100\n",
      "1606/1606 [==============================] - 0s 96us/step - loss: 23.3755 - acc: 0.0012\n",
      "Epoch 46/100\n",
      "1606/1606 [==============================] - 0s 84us/step - loss: 23.1898 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1606/1606 [==============================] - 0s 80us/step - loss: 23.3024 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 23.1724 - acc: 0.0012\n",
      "Epoch 49/100\n",
      "1606/1606 [==============================] - 0s 88us/step - loss: 23.2915 - acc: 6.2267e-04\n",
      "Epoch 50/100\n",
      "1606/1606 [==============================] - 0s 85us/step - loss: 23.2596 - acc: 6.2267e-04\n",
      "Epoch 51/100\n",
      "1606/1606 [==============================] - 0s 77us/step - loss: 23.1942 - acc: 0.0012\n",
      "Epoch 52/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.2897 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 23.2088 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1606/1606 [==============================] - 0s 77us/step - loss: 23.1576 - acc: 0.0012\n",
      "Epoch 55/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 23.2161 - acc: 0.0012\n",
      "Epoch 56/100\n",
      "1606/1606 [==============================] - 0s 87us/step - loss: 23.1383 - acc: 6.2267e-04\n",
      "Epoch 57/100\n",
      "1606/1606 [==============================] - 0s 83us/step - loss: 23.1176 - acc: 0.0012\n",
      "Epoch 58/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 23.0650 - acc: 0.0012\n",
      "Epoch 59/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.0671 - acc: 0.0012\n",
      "Epoch 60/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 23.1706 - acc: 6.2267e-04\n",
      "Epoch 61/100\n",
      "1606/1606 [==============================] - 0s 83us/step - loss: 22.9702 - acc: 0.0019\n",
      "Epoch 62/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 23.1094 - acc: 0.0019\n",
      "Epoch 63/100\n",
      "1606/1606 [==============================] - 0s 76us/step - loss: 23.0572 - acc: 0.0012\n",
      "Epoch 64/100\n",
      "1606/1606 [==============================] - 0s 83us/step - loss: 23.0316 - acc: 0.0012\n",
      "Epoch 65/100\n",
      "1606/1606 [==============================] - 0s 88us/step - loss: 23.1071 - acc: 0.0019\n",
      "Epoch 66/100\n",
      "1606/1606 [==============================] - 0s 80us/step - loss: 22.9645 - acc: 6.2267e-04\n",
      "Epoch 67/100\n",
      "1606/1606 [==============================] - 0s 80us/step - loss: 23.0365 - acc: 0.0012\n",
      "Epoch 68/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 23.1666 - acc: 0.0012\n",
      "Epoch 69/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.9822 - acc: 6.2267e-04\n",
      "Epoch 70/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.9744 - acc: 0.0019\n",
      "Epoch 71/100\n",
      "1606/1606 [==============================] - 0s 80us/step - loss: 22.8325 - acc: 0.0012\n",
      "Epoch 72/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.9188 - acc: 0.0012\n",
      "Epoch 73/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.8539 - acc: 0.0012\n",
      "Epoch 74/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.9573 - acc: 6.2267e-04\n",
      "Epoch 75/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 22.8357 - acc: 6.2267e-04\n",
      "Epoch 76/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.8505 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1606/1606 [==============================] - 0s 82us/step - loss: 22.9146 - acc: 0.0012\n",
      "Epoch 78/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.9385 - acc: 6.2267e-04\n",
      "Epoch 79/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.8104 - acc: 0.0012\n",
      "Epoch 80/100\n",
      "1606/1606 [==============================] - 0s 83us/step - loss: 22.7741 - acc: 6.2267e-04\n",
      "Epoch 81/100\n",
      "1606/1606 [==============================] - 0s 82us/step - loss: 22.8800 - acc: 0.0019\n",
      "Epoch 82/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 22.7885 - acc: 0.0012\n",
      "Epoch 83/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.7207 - acc: 6.2267e-04\n",
      "Epoch 84/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 22.7255 - acc: 0.0012\n",
      "Epoch 85/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 22.6949 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 22.7236 - acc: 0.0019\n",
      "Epoch 87/100\n",
      "1606/1606 [==============================] - 0s 77us/step - loss: 22.7299 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1606/1606 [==============================] - 0s 83us/step - loss: 22.6885 - acc: 0.0012\n",
      "Epoch 89/100\n",
      "1606/1606 [==============================] - 0s 80us/step - loss: 22.8104 - acc: 6.2267e-04\n",
      "Epoch 90/100\n",
      "1606/1606 [==============================] - 0s 73us/step - loss: 22.7672 - acc: 0.0019\n",
      "Epoch 91/100\n",
      "1606/1606 [==============================] - 0s 77us/step - loss: 22.6922 - acc: 0.0012\n",
      "Epoch 92/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 22.5907 - acc: 6.2267e-04\n",
      "Epoch 93/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.6248 - acc: 0.0012\n",
      "Epoch 94/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 22.6803 - acc: 6.2267e-04\n",
      "Epoch 95/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 22.6144 - acc: 6.2267e-04\n",
      "Epoch 96/100\n",
      "1606/1606 [==============================] - 0s 80us/step - loss: 22.6137 - acc: 6.2267e-04\n",
      "Epoch 97/100\n",
      "1606/1606 [==============================] - 0s 79us/step - loss: 22.5278 - acc: 0.0012\n",
      "Epoch 98/100\n",
      "1606/1606 [==============================] - 0s 81us/step - loss: 22.5495 - acc: 0.0012\n",
      "Epoch 99/100\n",
      "1606/1606 [==============================] - 0s 75us/step - loss: 22.5194 - acc: 6.2267e-04\n",
      "Epoch 100/100\n",
      "1606/1606 [==============================] - 0s 78us/step - loss: 22.5115 - acc: 6.2267e-04\n",
      "172/172 [==============================] - 0s 41us/step\n",
      "Epoch 1/100\n",
      "1778/1778 [==============================] - 0s 78us/step - loss: 21.8331 - acc: 0.0011\n",
      "Epoch 2/100\n",
      " 670/1778 [==========>...................] - ETA: 0s - loss: 22.0570 - acc: 0.0015    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1778/1778 [==============================] - 0s 82us/step - loss: 21.7553 - acc: 5.6243e-04\n",
      "Epoch 3/100\n",
      "1778/1778 [==============================] - 0s 80us/step - loss: 21.8379 - acc: 0.0017\n",
      "Epoch 4/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 21.6828 - acc: 0.0017\n",
      "Epoch 5/100\n",
      "1778/1778 [==============================] - 0s 76us/step - loss: 21.7494 - acc: 0.0022\n",
      "Epoch 6/100\n",
      "1778/1778 [==============================] - 0s 71us/step - loss: 21.6857 - acc: 0.0017\n",
      "Epoch 7/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 21.6566 - acc: 0.0017\n",
      "Epoch 8/100\n",
      "1778/1778 [==============================] - 0s 72us/step - loss: 21.6656 - acc: 0.0022\n",
      "Epoch 9/100\n",
      "1778/1778 [==============================] - 0s 71us/step - loss: 21.6251 - acc: 0.0017\n",
      "Epoch 10/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 21.6645 - acc: 0.0011\n",
      "Epoch 11/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 21.6371 - acc: 0.0017\n",
      "Epoch 12/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 21.6833 - acc: 5.6243e-04\n",
      "Epoch 13/100\n",
      "1778/1778 [==============================] - 0s 73us/step - loss: 21.6022 - acc: 0.0011\n",
      "Epoch 14/100\n",
      "1778/1778 [==============================] - 0s 83us/step - loss: 21.6010 - acc: 0.0011\n",
      "Epoch 15/100\n",
      "1778/1778 [==============================] - 0s 98us/step - loss: 21.5679 - acc: 0.0011\n",
      "Epoch 16/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 21.5534 - acc: 0.0017\n",
      "Epoch 17/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 21.5320 - acc: 0.0011\n",
      "Epoch 18/100\n",
      "1778/1778 [==============================] - 0s 80us/step - loss: 21.6039 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 21.5267 - acc: 5.6243e-04\n",
      "Epoch 20/100\n",
      "1778/1778 [==============================] - 0s 75us/step - loss: 21.5123 - acc: 0.0011\n",
      "Epoch 21/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 21.4289 - acc: 0.0022\n",
      "Epoch 22/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 21.5464 - acc: 0.0022\n",
      "Epoch 23/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 21.4062 - acc: 0.0011\n",
      "Epoch 24/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 21.3037 - acc: 0.0011\n",
      "Epoch 25/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 21.4648 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1778/1778 [==============================] - 0s 78us/step - loss: 21.3269 - acc: 5.6243e-04\n",
      "Epoch 27/100\n",
      "1778/1778 [==============================] - 0s 80us/step - loss: 21.2660 - acc: 0.0011\n",
      "Epoch 28/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 21.2087 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1778/1778 [==============================] - 0s 80us/step - loss: 21.3202 - acc: 0.0011\n",
      "Epoch 30/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 21.1636 - acc: 0.0011\n",
      "Epoch 31/100\n",
      "1778/1778 [==============================] - 0s 76us/step - loss: 21.2671 - acc: 0.0011\n",
      "Epoch 32/100\n",
      "1778/1778 [==============================] - 0s 84us/step - loss: 21.0892 - acc: 0.0011\n",
      "Epoch 33/100\n",
      "1778/1778 [==============================] - 0s 73us/step - loss: 21.1587 - acc: 5.6243e-04\n",
      "Epoch 34/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 21.0703 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 21.1887 - acc: 5.6243e-04\n",
      "Epoch 36/100\n",
      "1778/1778 [==============================] - 0s 76us/step - loss: 21.1761 - acc: 0.0017\n",
      "Epoch 37/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 21.1242 - acc: 5.6243e-04\n",
      "Epoch 38/100\n",
      "1778/1778 [==============================] - 0s 75us/step - loss: 21.0562 - acc: 0.0017\n",
      "Epoch 39/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 21.1178 - acc: 0.0011\n",
      "Epoch 40/100\n",
      "1778/1778 [==============================] - 0s 76us/step - loss: 20.9914 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1778/1778 [==============================] - 0s 76us/step - loss: 21.0699 - acc: 5.6243e-04\n",
      "Epoch 42/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.9069 - acc: 0.0017\n",
      "Epoch 43/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.9689 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.9185 - acc: 5.6243e-04\n",
      "Epoch 45/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 21.0917 - acc: 0.0011\n",
      "Epoch 46/100\n",
      "1778/1778 [==============================] - 0s 84us/step - loss: 20.8749 - acc: 5.6243e-04\n",
      "Epoch 47/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 20.7787 - acc: 0.0011\n",
      "Epoch 48/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.8903 - acc: 5.6243e-04\n",
      "Epoch 49/100\n",
      "1778/1778 [==============================] - 0s 78us/step - loss: 20.8081 - acc: 0.0011\n",
      "Epoch 50/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.8667 - acc: 0.0011\n",
      "Epoch 51/100\n",
      "1778/1778 [==============================] - 0s 85us/step - loss: 20.8365 - acc: 5.6243e-04\n",
      "Epoch 52/100\n",
      "1778/1778 [==============================] - 0s 80us/step - loss: 20.8165 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1778/1778 [==============================] - 0s 84us/step - loss: 20.8850 - acc: 5.6243e-04\n",
      "Epoch 54/100\n",
      "1778/1778 [==============================] - 0s 83us/step - loss: 20.7361 - acc: 0.0011\n",
      "Epoch 55/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.7130 - acc: 5.6243e-04\n",
      "Epoch 56/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 20.7573 - acc: 0.0011\n",
      "Epoch 57/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.6701 - acc: 5.6243e-04\n",
      "Epoch 58/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.6790 - acc: 0.0011\n",
      "Epoch 59/100\n",
      "1778/1778 [==============================] - 0s 75us/step - loss: 20.6825 - acc: 0.0011\n",
      "Epoch 60/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.7195 - acc: 5.6243e-04\n",
      "Epoch 61/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.6310 - acc: 5.6243e-04\n",
      "Epoch 62/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 20.6898 - acc: 5.6243e-04\n",
      "Epoch 63/100\n",
      "1778/1778 [==============================] - 0s 73us/step - loss: 20.6970 - acc: 5.6243e-04\n",
      "Epoch 64/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.6432 - acc: 5.6243e-04\n",
      "Epoch 65/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.5726 - acc: 0.0011\n",
      "Epoch 66/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.6518 - acc: 0.0011\n",
      "Epoch 67/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.5018 - acc: 0.0011\n",
      "Epoch 68/100\n",
      "1778/1778 [==============================] - 0s 84us/step - loss: 20.5169 - acc: 0.0011\n",
      "Epoch 69/100\n",
      "1778/1778 [==============================] - 0s 84us/step - loss: 20.5195 - acc: 0.0011\n",
      "Epoch 70/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 20.4795 - acc: 0.0011\n",
      "Epoch 71/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.5275 - acc: 0.0017\n",
      "Epoch 72/100\n",
      "1778/1778 [==============================] - 0s 78us/step - loss: 20.4836 - acc: 0.0011\n",
      "Epoch 73/100\n",
      "1778/1778 [==============================] - 0s 75us/step - loss: 20.3771 - acc: 0.0011\n",
      "Epoch 74/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 20.4219 - acc: 5.6243e-04\n",
      "Epoch 75/100\n",
      "1778/1778 [==============================] - 0s 80us/step - loss: 20.5726 - acc: 5.6243e-04\n",
      "Epoch 76/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 20.4090 - acc: 0.0011\n",
      "Epoch 77/100\n",
      "1778/1778 [==============================] - 0s 82us/step - loss: 20.3209 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 20.4761 - acc: 0.0011\n",
      "Epoch 79/100\n",
      "1778/1778 [==============================] - 0s 80us/step - loss: 20.3938 - acc: 0.0011\n",
      "Epoch 80/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.4021 - acc: 0.0011\n",
      "Epoch 81/100\n",
      "1778/1778 [==============================] - 0s 81us/step - loss: 20.3469 - acc: 0.0011\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.3204 - acc: 5.6243e-04\n",
      "Epoch 83/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.3906 - acc: 0.0011\n",
      "Epoch 84/100\n",
      "1778/1778 [==============================] - 0s 74us/step - loss: 20.3541 - acc: 0.0011\n",
      "Epoch 85/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.3262 - acc: 0.0017\n",
      "Epoch 86/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.3417 - acc: 0.0011\n",
      "Epoch 87/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.2411 - acc: 0.0011\n",
      "Epoch 88/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.2323 - acc: 5.6243e-04\n",
      "Epoch 89/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.1952 - acc: 0.0017\n",
      "Epoch 90/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.2647 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.2253 - acc: 0.0017\n",
      "Epoch 92/100\n",
      "1778/1778 [==============================] - 0s 73us/step - loss: 20.2075 - acc: 0.0011\n",
      "Epoch 93/100\n",
      "1778/1778 [==============================] - 0s 75us/step - loss: 20.2075 - acc: 0.0022\n",
      "Epoch 94/100\n",
      "1778/1778 [==============================] - 0s 73us/step - loss: 20.1337 - acc: 0.0011\n",
      "Epoch 95/100\n",
      "1778/1778 [==============================] - 0s 74us/step - loss: 20.1182 - acc: 0.0011\n",
      "Epoch 96/100\n",
      "1778/1778 [==============================] - 0s 75us/step - loss: 20.1508 - acc: 5.6243e-04\n",
      "Epoch 97/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.0850 - acc: 0.0011\n",
      "Epoch 98/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.1229 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1778/1778 [==============================] - 0s 79us/step - loss: 20.0512 - acc: 0.0017\n",
      "Epoch 100/100\n",
      "1778/1778 [==============================] - 0s 77us/step - loss: 20.0563 - acc: 0.0011\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "1950/1950 [==============================] - 0s 73us/step - loss: 20.7011 - acc: 0.0015\n",
      "Epoch 2/100\n",
      " 590/1950 [========>.....................] - ETA: 0s - loss: 19.6290 - acc: 0.0051    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950/1950 [==============================] - 0s 83us/step - loss: 20.5989 - acc: 0.0021\n",
      "Epoch 3/100\n",
      "1950/1950 [==============================] - 0s 75us/step - loss: 20.3342 - acc: 0.0010\n",
      "Epoch 4/100\n",
      "1950/1950 [==============================] - 0s 72us/step - loss: 20.2765 - acc: 0.0015\n",
      "Epoch 5/100\n",
      "1950/1950 [==============================] - 0s 73us/step - loss: 20.2137 - acc: 0.0026\n",
      "Epoch 6/100\n",
      "1950/1950 [==============================] - 0s 75us/step - loss: 20.2451 - acc: 0.0026\n",
      "Epoch 7/100\n",
      "1950/1950 [==============================] - 0s 72us/step - loss: 20.1716 - acc: 0.0026\n",
      "Epoch 8/100\n",
      "1950/1950 [==============================] - 0s 73us/step - loss: 20.1343 - acc: 0.0010\n",
      "Epoch 9/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 20.0586 - acc: 0.0010\n",
      "Epoch 10/100\n",
      "1950/1950 [==============================] - 0s 76us/step - loss: 20.0217 - acc: 0.0021\n",
      "Epoch 11/100\n",
      "1950/1950 [==============================] - 0s 73us/step - loss: 20.0571 - acc: 0.0010\n",
      "Epoch 12/100\n",
      "1950/1950 [==============================] - 0s 78us/step - loss: 20.0548 - acc: 0.0015\n",
      "Epoch 13/100\n",
      "1950/1950 [==============================] - 0s 72us/step - loss: 20.0019 - acc: 0.0010\n",
      "Epoch 14/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.9782 - acc: 0.0010\n",
      "Epoch 15/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.9870 - acc: 0.0021\n",
      "Epoch 16/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.9199 - acc: 0.0015\n",
      "Epoch 17/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.9756 - acc: 0.0015\n",
      "Epoch 18/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.9576 - acc: 0.0026\n",
      "Epoch 19/100\n",
      "1950/1950 [==============================] - 0s 72us/step - loss: 19.9024 - acc: 0.0015\n",
      "Epoch 20/100\n",
      "1950/1950 [==============================] - 0s 82us/step - loss: 19.8468 - acc: 0.0010\n",
      "Epoch 21/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.7764 - acc: 0.0015\n",
      "Epoch 22/100\n",
      "1950/1950 [==============================] - 0s 73us/step - loss: 19.7925 - acc: 0.0015\n",
      "Epoch 23/100\n",
      "1950/1950 [==============================] - 0s 76us/step - loss: 19.8148 - acc: 0.0026\n",
      "Epoch 24/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.7805 - acc: 0.0015\n",
      "Epoch 25/100\n",
      "1950/1950 [==============================] - 0s 78us/step - loss: 19.8087 - acc: 0.0021\n",
      "Epoch 26/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.7297 - acc: 0.0036\n",
      "Epoch 27/100\n",
      "1950/1950 [==============================] - 0s 76us/step - loss: 19.7563 - acc: 0.0015\n",
      "Epoch 28/100\n",
      "1950/1950 [==============================] - 0s 72us/step - loss: 19.6880 - acc: 0.0015\n",
      "Epoch 29/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.6780 - acc: 0.0015\n",
      "Epoch 30/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.6870 - acc: 0.0021\n",
      "Epoch 31/100\n",
      "1950/1950 [==============================] - 0s 73us/step - loss: 19.6427 - acc: 0.0015\n",
      "Epoch 32/100\n",
      "1950/1950 [==============================] - 0s 79us/step - loss: 19.6827 - acc: 0.0021\n",
      "Epoch 33/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.6328 - acc: 0.0031\n",
      "Epoch 34/100\n",
      "1950/1950 [==============================] - 0s 78us/step - loss: 19.5572 - acc: 0.0031\n",
      "Epoch 35/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.6477 - acc: 0.0026\n",
      "Epoch 36/100\n",
      "1950/1950 [==============================] - 0s 80us/step - loss: 19.6326 - acc: 0.0021\n",
      "Epoch 37/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.6871 - acc: 0.0026\n",
      "Epoch 38/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.6024 - acc: 0.0021\n",
      "Epoch 39/100\n",
      "1950/1950 [==============================] - 0s 81us/step - loss: 19.5329 - acc: 0.0010\n",
      "Epoch 40/100\n",
      "1950/1950 [==============================] - 0s 79us/step - loss: 19.4892 - acc: 0.0026\n",
      "Epoch 41/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.4423 - acc: 0.0021\n",
      "Epoch 42/100\n",
      "1950/1950 [==============================] - 0s 78us/step - loss: 19.5350 - acc: 0.0021\n",
      "Epoch 43/100\n",
      "1950/1950 [==============================] - 0s 75us/step - loss: 19.4880 - acc: 0.0021\n",
      "Epoch 44/100\n",
      "1950/1950 [==============================] - 0s 78us/step - loss: 19.4837 - acc: 0.0021\n",
      "Epoch 45/100\n",
      "1950/1950 [==============================] - 0s 73us/step - loss: 19.4796 - acc: 0.0015\n",
      "Epoch 46/100\n",
      "1950/1950 [==============================] - 0s 82us/step - loss: 19.4425 - acc: 0.0026\n",
      "Epoch 47/100\n",
      "1950/1950 [==============================] - 0s 80us/step - loss: 19.5601 - acc: 0.0015\n",
      "Epoch 48/100\n",
      "1950/1950 [==============================] - 0s 81us/step - loss: 19.4462 - acc: 0.0021\n",
      "Epoch 49/100\n",
      "1950/1950 [==============================] - 0s 79us/step - loss: 19.4695 - acc: 0.0026\n",
      "Epoch 50/100\n",
      "1950/1950 [==============================] - 0s 79us/step - loss: 19.3441 - acc: 0.0015\n",
      "Epoch 51/100\n",
      "1950/1950 [==============================] - 0s 79us/step - loss: 19.3812 - acc: 0.0036\n",
      "Epoch 52/100\n",
      "1950/1950 [==============================] - 0s 83us/step - loss: 19.3755 - acc: 0.0015\n",
      "Epoch 53/100\n",
      "1950/1950 [==============================] - 0s 83us/step - loss: 19.3880 - acc: 0.0026\n",
      "Epoch 54/100\n",
      "1950/1950 [==============================] - 0s 75us/step - loss: 19.3122 - acc: 0.0015\n",
      "Epoch 55/100\n",
      "1950/1950 [==============================] - 0s 79us/step - loss: 19.3775 - acc: 0.0026\n",
      "Epoch 56/100\n",
      "1950/1950 [==============================] - 0s 81us/step - loss: 19.3852 - acc: 0.0015\n",
      "Epoch 57/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.4427 - acc: 0.0015\n",
      "Epoch 58/100\n",
      "1950/1950 [==============================] - 0s 76us/step - loss: 19.2084 - acc: 0.0026\n",
      "Epoch 59/100\n",
      "1950/1950 [==============================] - 0s 86us/step - loss: 19.3355 - acc: 0.0026\n",
      "Epoch 60/100\n",
      "1950/1950 [==============================] - 0s 78us/step - loss: 19.2980 - acc: 0.0021\n",
      "Epoch 61/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.3438 - acc: 0.0026\n",
      "Epoch 62/100\n",
      "1950/1950 [==============================] - 0s 78us/step - loss: 19.2957 - acc: 0.0021\n",
      "Epoch 63/100\n",
      "1950/1950 [==============================] - 0s 84us/step - loss: 19.3113 - acc: 0.0021\n",
      "Epoch 64/100\n",
      "1950/1950 [==============================] - 0s 86us/step - loss: 19.2813 - acc: 0.0026\n",
      "Epoch 65/100\n",
      "1950/1950 [==============================] - 0s 85us/step - loss: 19.1807 - acc: 0.0021\n",
      "Epoch 66/100\n",
      "1950/1950 [==============================] - 0s 88us/step - loss: 19.1838 - acc: 0.0021\n",
      "Epoch 67/100\n",
      "1950/1950 [==============================] - 0s 84us/step - loss: 19.2312 - acc: 0.0015\n",
      "Epoch 68/100\n",
      "1950/1950 [==============================] - 0s 84us/step - loss: 19.2048 - acc: 0.0021\n",
      "Epoch 69/100\n",
      "1950/1950 [==============================] - 0s 87us/step - loss: 19.2243 - acc: 0.0010\n",
      "Epoch 70/100\n",
      "1950/1950 [==============================] - 0s 83us/step - loss: 19.2480 - acc: 0.0015\n",
      "Epoch 71/100\n",
      "1950/1950 [==============================] - 0s 95us/step - loss: 19.1547 - acc: 0.0021\n",
      "Epoch 72/100\n",
      "1950/1950 [==============================] - 0s 90us/step - loss: 19.2312 - acc: 0.0031\n",
      "Epoch 73/100\n",
      "1950/1950 [==============================] - 0s 86us/step - loss: 19.1273 - acc: 0.0021\n",
      "Epoch 74/100\n",
      "1950/1950 [==============================] - 0s 111us/step - loss: 19.0258 - acc: 0.0015\n",
      "Epoch 75/100\n",
      "1950/1950 [==============================] - 0s 122us/step - loss: 19.2765 - acc: 0.0021\n",
      "Epoch 76/100\n",
      "1950/1950 [==============================] - 0s 128us/step - loss: 19.1575 - acc: 0.0010\n",
      "Epoch 77/100\n",
      "1950/1950 [==============================] - 0s 117us/step - loss: 19.2040 - acc: 0.0036\n",
      "Epoch 78/100\n",
      "1950/1950 [==============================] - 0s 117us/step - loss: 19.0299 - acc: 0.0026\n",
      "Epoch 79/100\n",
      "1950/1950 [==============================] - 0s 83us/step - loss: 19.0482 - acc: 0.0031\n",
      "Epoch 80/100\n",
      "1950/1950 [==============================] - 0s 85us/step - loss: 19.1075 - acc: 0.0021\n",
      "Epoch 81/100\n",
      "1950/1950 [==============================] - 0s 90us/step - loss: 19.1634 - acc: 0.0015\n",
      "Epoch 82/100\n",
      "1950/1950 [==============================] - 0s 120us/step - loss: 19.0233 - acc: 0.0015\n",
      "Epoch 83/100\n",
      "1950/1950 [==============================] - 0s 124us/step - loss: 19.0367 - acc: 0.0015\n",
      "Epoch 84/100\n",
      "1950/1950 [==============================] - 0s 146us/step - loss: 19.2028 - acc: 0.0010TA: 0s - loss: 19.5261 - acc: 6.7568\n",
      "Epoch 85/100\n",
      "1950/1950 [==============================] - 0s 117us/step - loss: 19.1049 - acc: 0.0015\n",
      "Epoch 86/100\n",
      "1950/1950 [==============================] - 0s 105us/step - loss: 19.1044 - acc: 0.0026\n",
      "Epoch 87/100\n",
      "1950/1950 [==============================] - 0s 87us/step - loss: 18.9183 - acc: 0.0026\n",
      "Epoch 88/100\n",
      "1950/1950 [==============================] - 0s 88us/step - loss: 19.1039 - acc: 0.0031\n",
      "Epoch 89/100\n",
      "1950/1950 [==============================] - 0s 73us/step - loss: 18.9854 - acc: 0.0021\n",
      "Epoch 90/100\n",
      "1950/1950 [==============================] - 0s 101us/step - loss: 19.0046 - acc: 0.0026\n",
      "Epoch 91/100\n",
      "1950/1950 [==============================] - 0s 82us/step - loss: 19.0157 - acc: 0.0026\n",
      "Epoch 92/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.0768 - acc: 0.0021\n",
      "Epoch 93/100\n",
      "1950/1950 [==============================] - 0s 75us/step - loss: 18.9373 - acc: 0.0031\n",
      "Epoch 94/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 19.0184 - acc: 0.0026\n",
      "Epoch 95/100\n",
      "1950/1950 [==============================] - 0s 71us/step - loss: 18.9519 - acc: 0.0015\n",
      "Epoch 96/100\n",
      "1950/1950 [==============================] - 0s 76us/step - loss: 19.0670 - acc: 0.0021\n",
      "Epoch 97/100\n",
      "1950/1950 [==============================] - 0s 77us/step - loss: 19.0320 - acc: 0.0021\n",
      "Epoch 98/100\n",
      "1950/1950 [==============================] - 0s 74us/step - loss: 18.9714 - acc: 0.0010\n",
      "Epoch 99/100\n",
      "1950/1950 [==============================] - 0s 78us/step - loss: 19.0162 - acc: 0.0015\n",
      "Epoch 100/100\n",
      "1950/1950 [==============================] - 0s 76us/step - loss: 18.9143 - acc: 0.0021\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2122/2122 [==============================] - 0s 76us/step - loss: 18.8821 - acc: 0.0014\n",
      "Epoch 2/100\n",
      "  10/2122 [..............................] - ETA: 0s - loss: 8.1102 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122/2122 [==============================] - 0s 75us/step - loss: 18.9011 - acc: 0.0014\n",
      "Epoch 3/100\n",
      "2122/2122 [==============================] - 0s 71us/step - loss: 18.7910 - acc: 0.0014\n",
      "Epoch 4/100\n",
      "2122/2122 [==============================] - 0s 78us/step - loss: 18.7441 - acc: 0.0014\n",
      "Epoch 5/100\n",
      "2122/2122 [==============================] - 0s 74us/step - loss: 18.7278 - acc: 0.0014\n",
      "Epoch 6/100\n",
      "2122/2122 [==============================] - 0s 74us/step - loss: 18.7315 - acc: 9.4251e-04\n",
      "Epoch 7/100\n",
      "2122/2122 [==============================] - 0s 72us/step - loss: 18.7112 - acc: 0.0019\n",
      "Epoch 8/100\n",
      "2122/2122 [==============================] - 0s 70us/step - loss: 18.6988 - acc: 0.0019\n",
      "Epoch 9/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 18.6359 - acc: 0.0024\n",
      "Epoch 10/100\n",
      "2122/2122 [==============================] - 0s 78us/step - loss: 18.6613 - acc: 9.4251e-04\n",
      "Epoch 11/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.6530 - acc: 0.0019\n",
      "Epoch 12/100\n",
      "2122/2122 [==============================] - 0s 76us/step - loss: 18.5776 - acc: 9.4251e-04\n",
      "Epoch 13/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 18.6060 - acc: 0.0028\n",
      "Epoch 14/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 18.6700 - acc: 9.4251e-04\n",
      "Epoch 15/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 18.6361 - acc: 9.4251e-04\n",
      "Epoch 16/100\n",
      "2122/2122 [==============================] - 0s 76us/step - loss: 18.5673 - acc: 0.0019\n",
      "Epoch 17/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 18.4868 - acc: 0.0014\n",
      "Epoch 18/100\n",
      "2122/2122 [==============================] - 0s 78us/step - loss: 18.6315 - acc: 0.0014\n",
      "Epoch 19/100\n",
      "2122/2122 [==============================] - 0s 73us/step - loss: 18.4943 - acc: 4.7125e-04\n",
      "Epoch 20/100\n",
      "2122/2122 [==============================] - 0s 72us/step - loss: 18.5825 - acc: 4.7125e-04\n",
      "Epoch 21/100\n",
      "2122/2122 [==============================] - 0s 71us/step - loss: 18.5274 - acc: 9.4251e-04\n",
      "Epoch 22/100\n",
      "2122/2122 [==============================] - 0s 76us/step - loss: 18.5878 - acc: 9.4251e-04\n",
      "Epoch 23/100\n",
      "2122/2122 [==============================] - 0s 72us/step - loss: 18.6114 - acc: 9.4251e-04\n",
      "Epoch 24/100\n",
      "2122/2122 [==============================] - 0s 76us/step - loss: 18.5057 - acc: 0.0014\n",
      "Epoch 25/100\n",
      "2122/2122 [==============================] - 0s 83us/step - loss: 18.4684 - acc: 9.4251e-04\n",
      "Epoch 26/100\n",
      "2122/2122 [==============================] - 0s 82us/step - loss: 18.5667 - acc: 9.4251e-04\n",
      "Epoch 27/100\n",
      "2122/2122 [==============================] - 0s 84us/step - loss: 18.5567 - acc: 9.4251e-04\n",
      "Epoch 28/100\n",
      "2122/2122 [==============================] - 0s 79us/step - loss: 18.4603 - acc: 0.0028\n",
      "Epoch 29/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.5697 - acc: 0.0019\n",
      "Epoch 30/100\n",
      "2122/2122 [==============================] - 0s 78us/step - loss: 18.5370 - acc: 9.4251e-04\n",
      "Epoch 31/100\n",
      "2122/2122 [==============================] - 0s 82us/step - loss: 18.4102 - acc: 9.4251e-04\n",
      "Epoch 32/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.3585 - acc: 0.0019\n",
      "Epoch 33/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.4749 - acc: 0.0024\n",
      "Epoch 34/100\n",
      "2122/2122 [==============================] - 0s 78us/step - loss: 18.3248 - acc: 0.0019\n",
      "Epoch 35/100\n",
      "2122/2122 [==============================] - 0s 78us/step - loss: 18.3890 - acc: 0.0024\n",
      "Epoch 36/100\n",
      "2122/2122 [==============================] - 0s 77us/step - loss: 18.4354 - acc: 0.0014\n",
      "Epoch 37/100\n",
      "2122/2122 [==============================] - 0s 74us/step - loss: 18.5214 - acc: 0.0014\n",
      "Epoch 38/100\n",
      "2122/2122 [==============================] - 0s 100us/step - loss: 18.4138 - acc: 0.0028\n",
      "Epoch 39/100\n",
      "2122/2122 [==============================] - 0s 85us/step - loss: 18.3091 - acc: 0.0014\n",
      "Epoch 40/100\n",
      "2122/2122 [==============================] - 0s 105us/step - loss: 18.3289 - acc: 0.0019\n",
      "Epoch 41/100\n",
      "2122/2122 [==============================] - 0s 102us/step - loss: 18.3633 - acc: 0.0014\n",
      "Epoch 42/100\n",
      "2122/2122 [==============================] - 0s 81us/step - loss: 18.3523 - acc: 9.4251e-04\n",
      "Epoch 43/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.3793 - acc: 0.0014\n",
      "Epoch 44/100\n",
      "2122/2122 [==============================] - 0s 79us/step - loss: 18.2938 - acc: 0.0014\n",
      "Epoch 45/100\n",
      "2122/2122 [==============================] - 0s 77us/step - loss: 18.3151 - acc: 0.0019\n",
      "Epoch 46/100\n",
      "2122/2122 [==============================] - 0s 84us/step - loss: 18.2390 - acc: 0.0014\n",
      "Epoch 47/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.3173 - acc: 0.0014\n",
      "Epoch 48/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.3001 - acc: 0.0019\n",
      "Epoch 49/100\n",
      "2122/2122 [==============================] - 0s 94us/step - loss: 18.2599 - acc: 9.4251e-04\n",
      "Epoch 50/100\n",
      "2122/2122 [==============================] - 0s 95us/step - loss: 18.2654 - acc: 9.4251e-04\n",
      "Epoch 51/100\n",
      "2122/2122 [==============================] - 0s 94us/step - loss: 18.2395 - acc: 0.0019\n",
      "Epoch 52/100\n",
      "2122/2122 [==============================] - 0s 107us/step - loss: 18.2089 - acc: 0.0024\n",
      "Epoch 53/100\n",
      "2122/2122 [==============================] - 0s 97us/step - loss: 18.3180 - acc: 0.0014\n",
      "Epoch 54/100\n",
      "2122/2122 [==============================] - 0s 77us/step - loss: 18.1845 - acc: 0.0014\n",
      "Epoch 55/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.2283 - acc: 0.0019\n",
      "Epoch 56/100\n",
      "2122/2122 [==============================] - 0s 81us/step - loss: 18.1915 - acc: 9.4251e-04\n",
      "Epoch 57/100\n",
      "2122/2122 [==============================] - 0s 83us/step - loss: 18.2307 - acc: 0.0014\n",
      "Epoch 58/100\n",
      "2122/2122 [==============================] - 0s 81us/step - loss: 18.1282 - acc: 9.4251e-04\n",
      "Epoch 59/100\n",
      "2122/2122 [==============================] - 0s 82us/step - loss: 18.1493 - acc: 9.4251e-04\n",
      "Epoch 60/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.1962 - acc: 9.4251e-04\n",
      "Epoch 61/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 18.2976 - acc: 0.0019\n",
      "Epoch 62/100\n",
      "2122/2122 [==============================] - 0s 82us/step - loss: 18.2308 - acc: 0.0024\n",
      "Epoch 63/100\n",
      "2122/2122 [==============================] - 0s 83us/step - loss: 18.1083 - acc: 0.0019\n",
      "Epoch 64/100\n",
      "2122/2122 [==============================] - 0s 82us/step - loss: 18.1029 - acc: 9.4251e-04\n",
      "Epoch 65/100\n",
      "2122/2122 [==============================] - 0s 89us/step - loss: 18.1202 - acc: 0.0014\n",
      "Epoch 66/100\n",
      "2122/2122 [==============================] - 0s 82us/step - loss: 18.0710 - acc: 0.0019\n",
      "Epoch 67/100\n",
      "2122/2122 [==============================] - 0s 91us/step - loss: 18.1222 - acc: 0.0024\n",
      "Epoch 68/100\n",
      "2122/2122 [==============================] - 0s 96us/step - loss: 18.2779 - acc: 0.0024\n",
      "Epoch 69/100\n",
      "2122/2122 [==============================] - 0s 101us/step - loss: 18.0951 - acc: 0.0019\n",
      "Epoch 70/100\n",
      "2122/2122 [==============================] - 0s 93us/step - loss: 18.0726 - acc: 0.0014\n",
      "Epoch 71/100\n",
      "2122/2122 [==============================] - 0s 92us/step - loss: 18.2295 - acc: 0.0033\n",
      "Epoch 72/100\n",
      "2122/2122 [==============================] - 0s 90us/step - loss: 18.1374 - acc: 0.0028\n",
      "Epoch 73/100\n",
      "2122/2122 [==============================] - 0s 94us/step - loss: 18.1277 - acc: 0.0028\n",
      "Epoch 74/100\n",
      "2122/2122 [==============================] - 0s 87us/step - loss: 18.0205 - acc: 0.0019\n",
      "Epoch 75/100\n",
      "2122/2122 [==============================] - 0s 86us/step - loss: 18.1048 - acc: 0.0014\n",
      "Epoch 76/100\n",
      "2122/2122 [==============================] - 0s 87us/step - loss: 18.1151 - acc: 0.0019\n",
      "Epoch 77/100\n",
      "2122/2122 [==============================] - 0s 86us/step - loss: 18.0399 - acc: 9.4251e-04\n",
      "Epoch 78/100\n",
      "2122/2122 [==============================] - 0s 83us/step - loss: 18.0526 - acc: 0.0014\n",
      "Epoch 79/100\n",
      "2122/2122 [==============================] - 0s 88us/step - loss: 18.0894 - acc: 0.0014\n",
      "Epoch 80/100\n",
      "2122/2122 [==============================] - 0s 82us/step - loss: 18.0646 - acc: 0.0014\n",
      "Epoch 81/100\n",
      "2122/2122 [==============================] - 0s 82us/step - loss: 17.9788 - acc: 4.7125e-04\n",
      "Epoch 82/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 17.9653 - acc: 9.4251e-04\n",
      "Epoch 83/100\n",
      "2122/2122 [==============================] - 0s 77us/step - loss: 17.9967 - acc: 0.0014\n",
      "Epoch 84/100\n",
      "2122/2122 [==============================] - 0s 80us/step - loss: 17.9294 - acc: 0.0014\n",
      "Epoch 85/100\n",
      "2122/2122 [==============================] - 0s 79us/step - loss: 17.9533 - acc: 0.0014\n",
      "Epoch 86/100\n",
      "2122/2122 [==============================] - 0s 85us/step - loss: 18.0147 - acc: 9.4251e-04\n",
      "Epoch 87/100\n",
      "2122/2122 [==============================] - 0s 77us/step - loss: 17.9832 - acc: 0.0014\n",
      "Epoch 88/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 18.0385 - acc: 0.0014\n",
      "Epoch 89/100\n",
      "2122/2122 [==============================] - 0s 76us/step - loss: 17.9217 - acc: 0.0024\n",
      "Epoch 90/100\n",
      "2122/2122 [==============================] - 0s 79us/step - loss: 18.0551 - acc: 0.0019\n",
      "Epoch 91/100\n",
      "2122/2122 [==============================] - 0s 85us/step - loss: 17.8770 - acc: 9.4251e-04\n",
      "Epoch 92/100\n",
      "2122/2122 [==============================] - 0s 95us/step - loss: 18.0254 - acc: 0.0014\n",
      "Epoch 93/100\n",
      "2122/2122 [==============================] - 0s 101us/step - loss: 18.0215 - acc: 0.0024\n",
      "Epoch 94/100\n",
      "2122/2122 [==============================] - 0s 101us/step - loss: 17.9225 - acc: 9.4251e-04\n",
      "Epoch 95/100\n",
      "2122/2122 [==============================] - 0s 96us/step - loss: 17.8981 - acc: 0.0028\n",
      "Epoch 96/100\n",
      "2122/2122 [==============================] - 0s 88us/step - loss: 17.8591 - acc: 0.0014\n",
      "Epoch 97/100\n",
      "2122/2122 [==============================] - 0s 87us/step - loss: 17.8475 - acc: 0.0019\n",
      "Epoch 98/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 17.8738 - acc: 0.0014\n",
      "Epoch 99/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 17.8108 - acc: 0.0019\n",
      "Epoch 100/100\n",
      "2122/2122 [==============================] - 0s 75us/step - loss: 17.8319 - acc: 0.0014\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2294/2294 [==============================] - 0s 75us/step - loss: 17.6062 - acc: 0.0013\n",
      "Epoch 2/100\n",
      "  10/2294 [..............................] - ETA: 0s - loss: 8.8543 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2294/2294 [==============================] - 0s 81us/step - loss: 17.6436 - acc: 0.0013\n",
      "Epoch 3/100\n",
      "2294/2294 [==============================] - 0s 73us/step - loss: 17.5325 - acc: 0.0017\n",
      "Epoch 4/100\n",
      "2294/2294 [==============================] - 0s 74us/step - loss: 17.5514 - acc: 0.0013\n",
      "Epoch 5/100\n",
      "2294/2294 [==============================] - 0s 75us/step - loss: 17.5318 - acc: 0.0022\n",
      "Epoch 6/100\n",
      "2294/2294 [==============================] - 0s 73us/step - loss: 17.5912 - acc: 0.0022\n",
      "Epoch 7/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.5163 - acc: 0.0017\n",
      "Epoch 8/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.4873 - acc: 0.0022\n",
      "Epoch 9/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.6053 - acc: 0.0013\n",
      "Epoch 10/100\n",
      "2294/2294 [==============================] - 0s 77us/step - loss: 17.4329 - acc: 8.7184e-04\n",
      "Epoch 11/100\n",
      "2294/2294 [==============================] - 0s 77us/step - loss: 17.5068 - acc: 0.0013\n",
      "Epoch 12/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 17.4797 - acc: 0.0022\n",
      "Epoch 13/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.3994 - acc: 0.0017\n",
      "Epoch 14/100\n",
      "2294/2294 [==============================] - 0s 82us/step - loss: 17.4185 - acc: 0.0013\n",
      "Epoch 15/100\n",
      "2294/2294 [==============================] - 0s 77us/step - loss: 17.5217 - acc: 0.0017\n",
      "Epoch 16/100\n",
      "2294/2294 [==============================] - 0s 84us/step - loss: 17.4977 - acc: 0.0017\n",
      "Epoch 17/100\n",
      "2294/2294 [==============================] - 0s 101us/step - loss: 17.3483 - acc: 0.0013\n",
      "Epoch 18/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.4417 - acc: 0.0022\n",
      "Epoch 19/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.3631 - acc: 0.0013\n",
      "Epoch 20/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.5377 - acc: 0.0022\n",
      "Epoch 21/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.4578 - acc: 0.0022\n",
      "Epoch 22/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.3296 - acc: 0.0026\n",
      "Epoch 23/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 17.5573 - acc: 0.0017\n",
      "Epoch 24/100\n",
      "2294/2294 [==============================] - 0s 81us/step - loss: 17.3761 - acc: 0.0022\n",
      "Epoch 25/100\n",
      "2294/2294 [==============================] - 0s 84us/step - loss: 17.2634 - acc: 0.0022\n",
      "Epoch 26/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.4024 - acc: 0.0017\n",
      "Epoch 27/100\n",
      "2294/2294 [==============================] - 0s 74us/step - loss: 17.3623 - acc: 0.0026\n",
      "Epoch 28/100\n",
      "2294/2294 [==============================] - 0s 85us/step - loss: 17.2913 - acc: 0.0017\n",
      "Epoch 29/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.3091 - acc: 0.0026\n",
      "Epoch 30/100\n",
      "2294/2294 [==============================] - 0s 90us/step - loss: 17.2868 - acc: 0.0022\n",
      "Epoch 31/100\n",
      "2294/2294 [==============================] - 0s 77us/step - loss: 17.3088 - acc: 0.0017\n",
      "Epoch 32/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.3580 - acc: 8.7184e-04\n",
      "Epoch 33/100\n",
      "2294/2294 [==============================] - 0s 76us/step - loss: 17.2389 - acc: 0.0017\n",
      "Epoch 34/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.2204 - acc: 0.0026\n",
      "Epoch 35/100\n",
      "2294/2294 [==============================] - 0s 77us/step - loss: 17.2135 - acc: 0.0022\n",
      "Epoch 36/100\n",
      "2294/2294 [==============================] - 0s 85us/step - loss: 17.2785 - acc: 0.0017\n",
      "Epoch 37/100\n",
      "2294/2294 [==============================] - 0s 96us/step - loss: 17.2356 - acc: 0.0026\n",
      "Epoch 38/100\n",
      "2294/2294 [==============================] - 0s 90us/step - loss: 17.2743 - acc: 0.0017\n",
      "Epoch 39/100\n",
      "2294/2294 [==============================] - 0s 90us/step - loss: 17.2435 - acc: 0.0017\n",
      "Epoch 40/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.2107 - acc: 0.0022\n",
      "Epoch 41/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.3242 - acc: 0.0022\n",
      "Epoch 42/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.1675 - acc: 0.0017\n",
      "Epoch 43/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.3802 - acc: 0.0017\n",
      "Epoch 44/100\n",
      "2294/2294 [==============================] - 0s 87us/step - loss: 17.1939 - acc: 0.0022\n",
      "Epoch 45/100\n",
      "2294/2294 [==============================] - 0s 87us/step - loss: 17.2212 - acc: 0.0031\n",
      "Epoch 46/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.1867 - acc: 0.0022\n",
      "Epoch 47/100\n",
      "2294/2294 [==============================] - 0s 87us/step - loss: 17.1260 - acc: 0.0017\n",
      "Epoch 48/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.2245 - acc: 0.0022\n",
      "Epoch 49/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.1706 - acc: 0.0026\n",
      "Epoch 50/100\n",
      "2294/2294 [==============================] - 0s 81us/step - loss: 17.2309 - acc: 0.0013\n",
      "Epoch 51/100\n",
      "2294/2294 [==============================] - 0s 81us/step - loss: 17.1504 - acc: 0.0031\n",
      "Epoch 52/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.1513 - acc: 0.0022\n",
      "Epoch 53/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 17.1846 - acc: 0.0022\n",
      "Epoch 54/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.2466 - acc: 0.0022\n",
      "Epoch 55/100\n",
      "2294/2294 [==============================] - 0s 94us/step - loss: 17.1899 - acc: 0.0017\n",
      "Epoch 56/100\n",
      "2294/2294 [==============================] - 0s 85us/step - loss: 17.0772 - acc: 0.0013\n",
      "Epoch 57/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.1365 - acc: 0.0026\n",
      "Epoch 58/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.1176 - acc: 0.0026\n",
      "Epoch 59/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.2391 - acc: 0.0013\n",
      "Epoch 60/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.1626 - acc: 0.0031\n",
      "Epoch 61/100\n",
      "2294/2294 [==============================] - 0s 82us/step - loss: 17.0967 - acc: 0.0022\n",
      "Epoch 62/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.1019 - acc: 0.0031\n",
      "Epoch 63/100\n",
      "2294/2294 [==============================] - 0s 82us/step - loss: 17.0714 - acc: 0.0031\n",
      "Epoch 64/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 17.1529 - acc: 0.0017\n",
      "Epoch 65/100\n",
      "2294/2294 [==============================] - 0s 81us/step - loss: 17.1670 - acc: 0.0026\n",
      "Epoch 66/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.1320 - acc: 0.0017\n",
      "Epoch 67/100\n",
      "2294/2294 [==============================] - 0s 86us/step - loss: 17.0983 - acc: 0.0013\n",
      "Epoch 68/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 17.0321 - acc: 0.0013\n",
      "Epoch 69/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 17.0960 - acc: 0.0013\n",
      "Epoch 70/100\n",
      "2294/2294 [==============================] - 0s 85us/step - loss: 17.1392 - acc: 0.0013\n",
      "Epoch 71/100\n",
      "2294/2294 [==============================] - 0s 82us/step - loss: 17.0988 - acc: 0.0017\n",
      "Epoch 72/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.1206 - acc: 0.0022\n",
      "Epoch 73/100\n",
      "2294/2294 [==============================] - 0s 83us/step - loss: 17.0487 - acc: 0.0026\n",
      "Epoch 74/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.0797 - acc: 0.0017\n",
      "Epoch 75/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.1605 - acc: 0.0022\n",
      "Epoch 76/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.1171 - acc: 0.0026\n",
      "Epoch 77/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.0523 - acc: 0.0026\n",
      "Epoch 78/100\n",
      "2294/2294 [==============================] - 0s 84us/step - loss: 17.0416 - acc: 0.0017\n",
      "Epoch 79/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 17.0085 - acc: 0.0017\n",
      "Epoch 80/100\n",
      "2294/2294 [==============================] - 0s 79us/step - loss: 17.1170 - acc: 0.0031\n",
      "Epoch 81/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 16.9884 - acc: 0.0017\n",
      "Epoch 82/100\n",
      "2294/2294 [==============================] - 0s 81us/step - loss: 17.0777 - acc: 0.0017\n",
      "Epoch 83/100\n",
      "2294/2294 [==============================] - 0s 81us/step - loss: 16.9610 - acc: 0.0013\n",
      "Epoch 84/100\n",
      "2294/2294 [==============================] - 0s 73us/step - loss: 17.0626 - acc: 0.0035\n",
      "Epoch 85/100\n",
      "2294/2294 [==============================] - 0s 72us/step - loss: 17.0271 - acc: 0.0035\n",
      "Epoch 86/100\n",
      "2294/2294 [==============================] - 0s 71us/step - loss: 17.1060 - acc: 0.0017\n",
      "Epoch 87/100\n",
      "2294/2294 [==============================] - 0s 73us/step - loss: 17.0231 - acc: 0.0013\n",
      "Epoch 88/100\n",
      "2294/2294 [==============================] - 0s 74us/step - loss: 17.0802 - acc: 0.0026\n",
      "Epoch 89/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 16.9995 - acc: 0.0017\n",
      "Epoch 90/100\n",
      "2294/2294 [==============================] - 0s 73us/step - loss: 17.0050 - acc: 0.0026\n",
      "Epoch 91/100\n",
      "2294/2294 [==============================] - 0s 73us/step - loss: 17.1230 - acc: 0.0031\n",
      "Epoch 92/100\n",
      "2294/2294 [==============================] - 0s 75us/step - loss: 16.9783 - acc: 0.0035\n",
      "Epoch 93/100\n",
      "2294/2294 [==============================] - 0s 74us/step - loss: 17.0460 - acc: 0.0013\n",
      "Epoch 94/100\n",
      "2294/2294 [==============================] - 0s 77us/step - loss: 17.0247 - acc: 0.0035\n",
      "Epoch 95/100\n",
      "2294/2294 [==============================] - 0s 75us/step - loss: 17.0120 - acc: 0.0022\n",
      "Epoch 96/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 16.9570 - acc: 0.0017\n",
      "Epoch 97/100\n",
      "2294/2294 [==============================] - 0s 76us/step - loss: 16.9814 - acc: 0.0013\n",
      "Epoch 98/100\n",
      "2294/2294 [==============================] - 0s 80us/step - loss: 16.9789 - acc: 0.0031\n",
      "Epoch 99/100\n",
      "2294/2294 [==============================] - 0s 76us/step - loss: 16.9971 - acc: 0.0017\n",
      "Epoch 100/100\n",
      "2294/2294 [==============================] - 0s 78us/step - loss: 17.0166 - acc: 0.0022\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.9026 - acc: 0.0024\n",
      "Epoch 2/100\n",
      "  10/2466 [..............................] - ETA: 0s - loss: 19.2932 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.7860 - acc: 0.0036\n",
      "Epoch 3/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.7234 - acc: 0.0020\n",
      "Epoch 4/100\n",
      "2466/2466 [==============================] - 0s 72us/step - loss: 16.7387 - acc: 0.0032\n",
      "Epoch 5/100\n",
      "2466/2466 [==============================] - 0s 82us/step - loss: 16.8599 - acc: 0.0012\n",
      "Epoch 6/100\n",
      "2466/2466 [==============================] - 0s 83us/step - loss: 16.7353 - acc: 0.0024\n",
      "Epoch 7/100\n",
      "2466/2466 [==============================] - 0s 89us/step - loss: 16.7211 - acc: 0.0020\n",
      "Epoch 8/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.7679 - acc: 0.0028\n",
      "Epoch 9/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.7456 - acc: 0.0020\n",
      "Epoch 10/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.7348 - acc: 0.0028\n",
      "Epoch 11/100\n",
      "2466/2466 [==============================] - 0s 77us/step - loss: 16.7726 - acc: 0.0020\n",
      "Epoch 12/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.7430 - acc: 0.0028\n",
      "Epoch 13/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.7250 - acc: 0.0032\n",
      "Epoch 14/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.7173 - acc: 0.0032\n",
      "Epoch 15/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.7816 - acc: 0.0028\n",
      "Epoch 16/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.7565 - acc: 0.0032\n",
      "Epoch 17/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.6417 - acc: 0.0028\n",
      "Epoch 18/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.7352 - acc: 0.0024\n",
      "Epoch 19/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.7555 - acc: 0.0024\n",
      "Epoch 20/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.6549 - acc: 0.0024\n",
      "Epoch 21/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.7047 - acc: 0.0036\n",
      "Epoch 22/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.6529 - acc: 0.0028\n",
      "Epoch 23/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.7549 - acc: 0.0028\n",
      "Epoch 24/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.6651 - acc: 0.0024\n",
      "Epoch 25/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.7161 - acc: 0.0028\n",
      "Epoch 26/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.6244 - acc: 0.0032\n",
      "Epoch 27/100\n",
      "2466/2466 [==============================] - 0s 80us/step - loss: 16.7315 - acc: 0.0032\n",
      "Epoch 28/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.6578 - acc: 0.0028\n",
      "Epoch 29/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.6727 - acc: 0.0020\n",
      "Epoch 30/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.6751 - acc: 0.0028\n",
      "Epoch 31/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.7382 - acc: 0.0032\n",
      "Epoch 32/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.7231 - acc: 0.0036\n",
      "Epoch 33/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.6864 - acc: 0.0012\n",
      "Epoch 34/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.7066 - acc: 0.0032\n",
      "Epoch 35/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.6632 - acc: 0.0024\n",
      "Epoch 36/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.6670 - acc: 0.0024\n",
      "Epoch 37/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.6887 - acc: 0.0032\n",
      "Epoch 38/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.5674 - acc: 0.0024\n",
      "Epoch 39/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.6557 - acc: 0.0024\n",
      "Epoch 40/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.6394 - acc: 0.0032\n",
      "Epoch 41/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.6106 - acc: 0.0032\n",
      "Epoch 42/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.7604 - acc: 0.0012\n",
      "Epoch 43/100\n",
      "2466/2466 [==============================] - 0s 77us/step - loss: 16.7316 - acc: 0.0032\n",
      "Epoch 44/100\n",
      "2466/2466 [==============================] - 0s 80us/step - loss: 16.6203 - acc: 0.0024\n",
      "Epoch 45/100\n",
      "2466/2466 [==============================] - 0s 72us/step - loss: 16.6535 - acc: 0.0020\n",
      "Epoch 46/100\n",
      "2466/2466 [==============================] - 0s 77us/step - loss: 16.6826 - acc: 0.0028\n",
      "Epoch 47/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.6747 - acc: 0.0041\n",
      "Epoch 48/100\n",
      "2466/2466 [==============================] - 0s 80us/step - loss: 16.6965 - acc: 0.0028\n",
      "Epoch 49/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.6466 - acc: 0.0032\n",
      "Epoch 50/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.6854 - acc: 0.0028\n",
      "Epoch 51/100\n",
      "2466/2466 [==============================] - 0s 77us/step - loss: 16.5491 - acc: 0.0020\n",
      "Epoch 52/100\n",
      "2466/2466 [==============================] - 0s 77us/step - loss: 16.6618 - acc: 0.0028\n",
      "Epoch 53/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.6429 - acc: 0.0028\n",
      "Epoch 54/100\n",
      "2466/2466 [==============================] - 0s 77us/step - loss: 16.6338 - acc: 0.0028\n",
      "Epoch 55/100\n",
      "2466/2466 [==============================] - 0s 80us/step - loss: 16.6932 - acc: 0.0024\n",
      "Epoch 56/100\n",
      "2466/2466 [==============================] - 0s 81us/step - loss: 16.6540 - acc: 0.0024\n",
      "Epoch 57/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.6590 - acc: 0.0020\n",
      "Epoch 58/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.6267 - acc: 0.0032\n",
      "Epoch 59/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.5763 - acc: 0.0020\n",
      "Epoch 60/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.5925 - acc: 0.0032\n",
      "Epoch 61/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.6057 - acc: 0.0036\n",
      "Epoch 62/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.6174 - acc: 0.0032\n",
      "Epoch 63/100\n",
      "2466/2466 [==============================] - 0s 80us/step - loss: 16.6703 - acc: 0.0020\n",
      "Epoch 64/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.6027 - acc: 0.0024\n",
      "Epoch 65/100\n",
      "2466/2466 [==============================] - 0s 82us/step - loss: 16.6887 - acc: 0.0020\n",
      "Epoch 66/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.6736 - acc: 0.0020\n",
      "Epoch 67/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.6832 - acc: 0.0016\n",
      "Epoch 68/100\n",
      "2466/2466 [==============================] - 0s 77us/step - loss: 16.7149 - acc: 0.0020\n",
      "Epoch 69/100\n",
      "2466/2466 [==============================] - 0s 83us/step - loss: 16.6711 - acc: 0.0028\n",
      "Epoch 70/100\n",
      "2466/2466 [==============================] - 0s 82us/step - loss: 16.6406 - acc: 0.0016\n",
      "Epoch 71/100\n",
      "2466/2466 [==============================] - 0s 87us/step - loss: 16.6216 - acc: 0.0028\n",
      "Epoch 72/100\n",
      "2466/2466 [==============================] - 0s 83us/step - loss: 16.6741 - acc: 0.0024\n",
      "Epoch 73/100\n",
      "2466/2466 [==============================] - 0s 82us/step - loss: 16.6328 - acc: 0.0024\n",
      "Epoch 74/100\n",
      "2466/2466 [==============================] - 0s 82us/step - loss: 16.5278 - acc: 0.0016\n",
      "Epoch 75/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.6630 - acc: 0.0028\n",
      "Epoch 76/100\n",
      "2466/2466 [==============================] - 0s 81us/step - loss: 16.6128 - acc: 0.0028\n",
      "Epoch 77/100\n",
      "2466/2466 [==============================] - 0s 80us/step - loss: 16.7022 - acc: 0.0032\n",
      "Epoch 78/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.5758 - acc: 0.0036\n",
      "Epoch 79/100\n",
      "2466/2466 [==============================] - 0s 84us/step - loss: 16.6171 - acc: 0.0032\n",
      "Epoch 80/100\n",
      "2466/2466 [==============================] - 0s 82us/step - loss: 16.5639 - acc: 0.0028\n",
      "Epoch 81/100\n",
      "2466/2466 [==============================] - 0s 82us/step - loss: 16.5544 - acc: 0.0020\n",
      "Epoch 82/100\n",
      "2466/2466 [==============================] - 0s 77us/step - loss: 16.6439 - acc: 0.0024\n",
      "Epoch 83/100\n",
      "2466/2466 [==============================] - 0s 80us/step - loss: 16.6473 - acc: 0.0036\n",
      "Epoch 84/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.6394 - acc: 0.0028\n",
      "Epoch 85/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.5994 - acc: 0.0032\n",
      "Epoch 86/100\n",
      "2466/2466 [==============================] - 0s 74us/step - loss: 16.6035 - acc: 0.0028\n",
      "Epoch 87/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.5959 - acc: 0.0032\n",
      "Epoch 88/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.5808 - acc: 0.0020\n",
      "Epoch 89/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.5774 - acc: 0.0016\n",
      "Epoch 90/100\n",
      "2466/2466 [==============================] - 0s 72us/step - loss: 16.6626 - acc: 0.0024\n",
      "Epoch 91/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.5654 - acc: 0.0024\n",
      "Epoch 92/100\n",
      "2466/2466 [==============================] - 0s 79us/step - loss: 16.5900 - acc: 0.0024\n",
      "Epoch 93/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.5411 - acc: 0.0028\n",
      "Epoch 94/100\n",
      "2466/2466 [==============================] - 0s 73us/step - loss: 16.6021 - acc: 0.0028\n",
      "Epoch 95/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.5703 - acc: 0.0036\n",
      "Epoch 96/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.5074 - acc: 0.0020\n",
      "Epoch 97/100\n",
      "2466/2466 [==============================] - 0s 78us/step - loss: 16.6337 - acc: 0.0028\n",
      "Epoch 98/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.5104 - acc: 0.0020\n",
      "Epoch 99/100\n",
      "2466/2466 [==============================] - 0s 75us/step - loss: 16.5776 - acc: 0.0024\n",
      "Epoch 100/100\n",
      "2466/2466 [==============================] - 0s 76us/step - loss: 16.6079 - acc: 0.0032\n",
      "172/172 [==============================] - 0s 41us/step\n",
      "Epoch 1/100\n",
      "1990/2638 [=====================>........] - ETA: 0s - loss: 17.0611 - acc: 0.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2638/2638 [==============================] - 0s 76us/step - loss: 17.3380 - acc: 0.0027\n",
      "Epoch 2/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 17.2955 - acc: 0.0030\n",
      "Epoch 3/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 17.2081 - acc: 0.0027\n",
      "Epoch 4/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 17.1264 - acc: 0.0038\n",
      "Epoch 5/100\n",
      "2638/2638 [==============================] - 0s 82us/step - loss: 17.1008 - acc: 0.0023\n",
      "Epoch 6/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 17.1821 - acc: 0.0034\n",
      "Epoch 7/100\n",
      "2638/2638 [==============================] - 0s 72us/step - loss: 17.0663 - acc: 0.0023\n",
      "Epoch 8/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 17.1606 - acc: 0.0023\n",
      "Epoch 9/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 17.1691 - acc: 0.0015\n",
      "Epoch 10/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 16.9759 - acc: 0.0027\n",
      "Epoch 11/100\n",
      "2638/2638 [==============================] - 0s 71us/step - loss: 17.0205 - acc: 0.0023\n",
      "Epoch 12/100\n",
      "2638/2638 [==============================] - 0s 80us/step - loss: 16.9611 - acc: 0.0027\n",
      "Epoch 13/100\n",
      "2638/2638 [==============================] - 0s 73us/step - loss: 16.9005 - acc: 0.0027\n",
      "Epoch 14/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 17.0351 - acc: 0.0023\n",
      "Epoch 15/100\n",
      "2638/2638 [==============================] - 0s 85us/step - loss: 16.9105 - acc: 0.0023\n",
      "Epoch 16/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.9978 - acc: 0.0027\n",
      "Epoch 17/100\n",
      "2638/2638 [==============================] - 0s 84us/step - loss: 16.8966 - acc: 0.0019\n",
      "Epoch 18/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 16.8317 - acc: 0.0015\n",
      "Epoch 19/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 16.8268 - acc: 0.0027\n",
      "Epoch 20/100\n",
      "2638/2638 [==============================] - 0s 71us/step - loss: 16.8127 - acc: 0.0011\n",
      "Epoch 21/100\n",
      "2638/2638 [==============================] - 0s 78us/step - loss: 16.8604 - acc: 0.0023\n",
      "Epoch 22/100\n",
      "2638/2638 [==============================] - 0s 78us/step - loss: 16.7599 - acc: 0.0019\n",
      "Epoch 23/100\n",
      "2638/2638 [==============================] - 0s 73us/step - loss: 16.8348 - acc: 0.0030\n",
      "Epoch 24/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 16.7733 - acc: 0.0019\n",
      "Epoch 25/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.7410 - acc: 0.0015\n",
      "Epoch 26/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.7039 - acc: 0.0011\n",
      "Epoch 27/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.7476 - acc: 0.0015\n",
      "Epoch 28/100\n",
      "2638/2638 [==============================] - 0s 71us/step - loss: 16.7027 - acc: 0.0027\n",
      "Epoch 29/100\n",
      "2638/2638 [==============================] - 0s 73us/step - loss: 16.7283 - acc: 0.0015\n",
      "Epoch 30/100\n",
      "2638/2638 [==============================] - 0s 72us/step - loss: 16.7449 - acc: 0.0030\n",
      "Epoch 31/100\n",
      "2638/2638 [==============================] - 0s 78us/step - loss: 16.6709 - acc: 0.0015\n",
      "Epoch 32/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.6801 - acc: 0.0019\n",
      "Epoch 33/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 16.6716 - acc: 0.0019\n",
      "Epoch 34/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.6166 - acc: 0.0011\n",
      "Epoch 35/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.7490 - acc: 7.5815e-04\n",
      "Epoch 36/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.6493 - acc: 0.0015\n",
      "Epoch 37/100\n",
      "2638/2638 [==============================] - 0s 79us/step - loss: 16.5324 - acc: 0.0023\n",
      "Epoch 38/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 16.6256 - acc: 0.0015\n",
      "Epoch 39/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 16.5251 - acc: 0.0027\n",
      "Epoch 40/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 16.5641 - acc: 0.0027\n",
      "Epoch 41/100\n",
      "2638/2638 [==============================] - 0s 79us/step - loss: 16.5589 - acc: 0.0019\n",
      "Epoch 42/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.5010 - acc: 0.0019\n",
      "Epoch 43/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.5391 - acc: 0.0015\n",
      "Epoch 44/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 16.5698 - acc: 0.0027\n",
      "Epoch 45/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.4757 - acc: 0.0015\n",
      "Epoch 46/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 16.5415 - acc: 0.0023\n",
      "Epoch 47/100\n",
      "2638/2638 [==============================] - 0s 82us/step - loss: 16.3785 - acc: 7.5815e-04\n",
      "Epoch 48/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 16.4684 - acc: 0.0027\n",
      "Epoch 49/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 16.5037 - acc: 0.0015\n",
      "Epoch 50/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 16.4305 - acc: 0.0019\n",
      "Epoch 51/100\n",
      "2638/2638 [==============================] - 0s 78us/step - loss: 16.4192 - acc: 0.0015\n",
      "Epoch 52/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.4755 - acc: 0.0027\n",
      "Epoch 53/100\n",
      "2638/2638 [==============================] - 0s 78us/step - loss: 16.4221 - acc: 7.5815e-04\n",
      "Epoch 54/100\n",
      "2638/2638 [==============================] - 0s 79us/step - loss: 16.4847 - acc: 0.0019\n",
      "Epoch 55/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 16.4595 - acc: 0.0015\n",
      "Epoch 56/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.3906 - acc: 0.0023\n",
      "Epoch 57/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.3920 - acc: 0.0019\n",
      "Epoch 58/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.3768 - acc: 0.0023\n",
      "Epoch 59/100\n",
      "2638/2638 [==============================] - 0s 79us/step - loss: 16.4127 - acc: 0.0015\n",
      "Epoch 60/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 16.3851 - acc: 0.0019\n",
      "Epoch 61/100\n",
      "2638/2638 [==============================] - 0s 82us/step - loss: 16.4205 - acc: 0.0019\n",
      "Epoch 62/100\n",
      "2638/2638 [==============================] - 0s 80us/step - loss: 16.4081 - acc: 0.0019\n",
      "Epoch 63/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 16.3119 - acc: 0.0019\n",
      "Epoch 64/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.4038 - acc: 0.0011\n",
      "Epoch 65/100\n",
      "2638/2638 [==============================] - 0s 73us/step - loss: 16.4437 - acc: 0.0023\n",
      "Epoch 66/100\n",
      "2638/2638 [==============================] - 0s 85us/step - loss: 16.2729 - acc: 0.0027\n",
      "Epoch 67/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.3135 - acc: 0.0027\n",
      "Epoch 68/100\n",
      "2638/2638 [==============================] - 0s 80us/step - loss: 16.2935 - acc: 0.0027\n",
      "Epoch 69/100\n",
      "2638/2638 [==============================] - 0s 77us/step - loss: 16.3129 - acc: 0.0015\n",
      "Epoch 70/100\n",
      "2638/2638 [==============================] - 0s 80us/step - loss: 16.2858 - acc: 0.0030\n",
      "Epoch 71/100\n",
      "2638/2638 [==============================] - 0s 82us/step - loss: 16.2518 - acc: 0.0027\n",
      "Epoch 72/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.2741 - acc: 0.0030\n",
      "Epoch 73/100\n",
      "2638/2638 [==============================] - 0s 78us/step - loss: 16.3051 - acc: 0.0019\n",
      "Epoch 74/100\n",
      "2638/2638 [==============================] - 0s 78us/step - loss: 16.1923 - acc: 0.0023\n",
      "Epoch 75/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.2582 - acc: 0.0023\n",
      "Epoch 76/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.2954 - acc: 0.0019\n",
      "Epoch 77/100\n",
      "2638/2638 [==============================] - 0s 73us/step - loss: 16.2238 - acc: 0.0019\n",
      "Epoch 78/100\n",
      "2638/2638 [==============================] - 0s 82us/step - loss: 16.2020 - acc: 0.0019\n",
      "Epoch 79/100\n",
      "2638/2638 [==============================] - 0s 80us/step - loss: 16.1817 - acc: 0.0019\n",
      "Epoch 80/100\n",
      "2638/2638 [==============================] - 0s 83us/step - loss: 16.1769 - acc: 0.0015\n",
      "Epoch 81/100\n",
      "2638/2638 [==============================] - 0s 84us/step - loss: 16.1437 - acc: 0.0027\n",
      "Epoch 82/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 16.1742 - acc: 7.5815e-04\n",
      "Epoch 83/100\n",
      "2638/2638 [==============================] - 0s 72us/step - loss: 16.1742 - acc: 0.0030\n",
      "Epoch 84/100\n",
      "2638/2638 [==============================] - 0s 73us/step - loss: 16.1476 - acc: 0.0023\n",
      "Epoch 85/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.1304 - acc: 0.0015\n",
      "Epoch 86/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.1497 - acc: 0.0015\n",
      "Epoch 87/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 16.1485 - acc: 0.0023\n",
      "Epoch 88/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.1480 - acc: 0.0019\n",
      "Epoch 89/100\n",
      "2638/2638 [==============================] - 0s 73us/step - loss: 16.1796 - acc: 0.0019\n",
      "Epoch 90/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.0752 - acc: 0.0023\n",
      "Epoch 91/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.1467 - acc: 0.0027\n",
      "Epoch 92/100\n",
      "2638/2638 [==============================] - 0s 73us/step - loss: 16.1499 - acc: 0.0019\n",
      "Epoch 93/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 16.1920 - acc: 0.0023\n",
      "Epoch 94/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 16.0479 - acc: 0.0015\n",
      "Epoch 95/100\n",
      "2638/2638 [==============================] - 0s 72us/step - loss: 16.0808 - acc: 0.0023\n",
      "Epoch 96/100\n",
      "2638/2638 [==============================] - 0s 76us/step - loss: 16.0956 - acc: 0.0011\n",
      "Epoch 97/100\n",
      "2638/2638 [==============================] - 0s 81us/step - loss: 16.0916 - acc: 0.0023\n",
      "Epoch 98/100\n",
      "2638/2638 [==============================] - 0s 75us/step - loss: 16.0905 - acc: 0.0030\n",
      "Epoch 99/100\n",
      "2638/2638 [==============================] - 0s 74us/step - loss: 16.1197 - acc: 0.0015\n",
      "Epoch 100/100\n",
      "2638/2638 [==============================] - 0s 78us/step - loss: 16.0338 - acc: 0.0019\n",
      "172/172 [==============================] - 0s 41us/step\n",
      "Epoch 1/100\n",
      "2090/2810 [=====================>........] - ETA: 0s - loss: 15.5521 - acc: 0.0014  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2810/2810 [==============================] - 0s 100us/step - loss: 15.6915 - acc: 0.0021\n",
      "Epoch 2/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.7165 - acc: 0.0021\n",
      "Epoch 3/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.7237 - acc: 0.0025\n",
      "Epoch 4/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.6845 - acc: 0.0011\n",
      "Epoch 5/100\n",
      "2810/2810 [==============================] - 0s 86us/step - loss: 15.8201 - acc: 0.0021\n",
      "Epoch 6/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.7308 - acc: 0.0018\n",
      "Epoch 7/100\n",
      "2810/2810 [==============================] - 0s 78us/step - loss: 15.6825 - acc: 0.0018\n",
      "Epoch 8/100\n",
      "2810/2810 [==============================] - 0s 78us/step - loss: 15.6309 - acc: 0.0021\n",
      "Epoch 9/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.5250 - acc: 0.0021\n",
      "Epoch 10/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.6449 - acc: 0.0014\n",
      "Epoch 11/100\n",
      "2810/2810 [==============================] - 0s 74us/step - loss: 15.6879 - acc: 0.0014\n",
      "Epoch 12/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.6731 - acc: 0.0018\n",
      "Epoch 13/100\n",
      "2810/2810 [==============================] - 0s 74us/step - loss: 15.6315 - acc: 0.0018\n",
      "Epoch 14/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.6190 - acc: 0.0021\n",
      "Epoch 15/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.6156 - acc: 0.0018\n",
      "Epoch 16/100\n",
      "2810/2810 [==============================] - 0s 78us/step - loss: 15.6252 - acc: 0.0021\n",
      "Epoch 17/100\n",
      "2810/2810 [==============================] - 0s 73us/step - loss: 15.6186 - acc: 0.0021\n",
      "Epoch 18/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.6188 - acc: 0.0014\n",
      "Epoch 19/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.5915 - acc: 0.0014\n",
      "Epoch 20/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.6029 - acc: 0.0025\n",
      "Epoch 21/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.6010 - acc: 0.0021\n",
      "Epoch 22/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.5594 - acc: 0.0011\n",
      "Epoch 23/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.5976 - acc: 0.0014\n",
      "Epoch 24/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5576 - acc: 0.0021\n",
      "Epoch 25/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.6455 - acc: 0.0021\n",
      "Epoch 26/100\n",
      "2810/2810 [==============================] - 0s 75us/step - loss: 15.6309 - acc: 0.0014\n",
      "Epoch 27/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.5377 - acc: 0.0021\n",
      "Epoch 28/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.6136 - acc: 0.0021\n",
      "Epoch 29/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.6177 - acc: 0.0014\n",
      "Epoch 30/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.6610 - acc: 0.0018\n",
      "Epoch 31/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.6789 - acc: 0.0014\n",
      "Epoch 32/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.5462 - acc: 0.0021\n",
      "Epoch 33/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5482 - acc: 0.0011\n",
      "Epoch 34/100\n",
      "2810/2810 [==============================] - 0s 78us/step - loss: 15.5639 - acc: 0.0014\n",
      "Epoch 35/100\n",
      "2810/2810 [==============================] - 0s 74us/step - loss: 15.5643 - acc: 0.0021\n",
      "Epoch 36/100\n",
      "2810/2810 [==============================] - 0s 73us/step - loss: 15.6141 - acc: 0.0011\n",
      "Epoch 37/100\n",
      "2810/2810 [==============================] - 0s 82us/step - loss: 15.5331 - acc: 0.0014\n",
      "Epoch 38/100\n",
      "2810/2810 [==============================] - 0s 83us/step - loss: 15.5970 - acc: 0.0021\n",
      "Epoch 39/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.6022 - acc: 0.0025\n",
      "Epoch 40/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.6677 - acc: 0.0018\n",
      "Epoch 41/100\n",
      "2810/2810 [==============================] - 0s 75us/step - loss: 15.5065 - acc: 0.0018\n",
      "Epoch 42/100\n",
      "2810/2810 [==============================] - 0s 82us/step - loss: 15.5459 - acc: 0.0018\n",
      "Epoch 43/100\n",
      "2810/2810 [==============================] - 0s 78us/step - loss: 15.5916 - acc: 0.0025\n",
      "Epoch 44/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.6254 - acc: 0.0025\n",
      "Epoch 45/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.5423 - acc: 0.0018\n",
      "Epoch 46/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.6326 - acc: 0.0021\n",
      "Epoch 47/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.5698 - acc: 0.0014\n",
      "Epoch 48/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.5999 - acc: 0.0018\n",
      "Epoch 49/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.5392 - acc: 0.0025\n",
      "Epoch 50/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.5420 - acc: 0.0014\n",
      "Epoch 51/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.5327 - acc: 0.0014\n",
      "Epoch 52/100\n",
      "2810/2810 [==============================] - 0s 82us/step - loss: 15.6268 - acc: 0.0014\n",
      "Epoch 53/100\n",
      "2810/2810 [==============================] - 0s 78us/step - loss: 15.5738 - acc: 0.0021\n",
      "Epoch 54/100\n",
      "2810/2810 [==============================] - 0s 72us/step - loss: 15.5971 - acc: 0.0018\n",
      "Epoch 55/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.4958 - acc: 0.0014\n",
      "Epoch 56/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5995 - acc: 0.0032\n",
      "Epoch 57/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5808 - acc: 0.0021\n",
      "Epoch 58/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.4799 - acc: 3.5587e-04\n",
      "Epoch 59/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5249 - acc: 0.0011\n",
      "Epoch 60/100\n",
      "2810/2810 [==============================] - 0s 84us/step - loss: 15.4583 - acc: 0.0025\n",
      "Epoch 61/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5047 - acc: 0.0018\n",
      "Epoch 62/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.5109 - acc: 0.0025\n",
      "Epoch 63/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.5035 - acc: 0.0018\n",
      "Epoch 64/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5782 - acc: 0.0014\n",
      "Epoch 65/100\n",
      "2810/2810 [==============================] - 0s 83us/step - loss: 15.4768 - acc: 0.0014\n",
      "Epoch 66/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5001 - acc: 0.0014\n",
      "Epoch 67/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.5405 - acc: 0.0014\n",
      "Epoch 68/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.5236 - acc: 0.0021\n",
      "Epoch 69/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.4679 - acc: 0.0011\n",
      "Epoch 70/100\n",
      "2810/2810 [==============================] - 0s 83us/step - loss: 15.4486 - acc: 0.0025\n",
      "Epoch 71/100\n",
      "2810/2810 [==============================] - 0s 78us/step - loss: 15.4744 - acc: 0.0021\n",
      "Epoch 72/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.5572 - acc: 0.0014\n",
      "Epoch 73/100\n",
      "2810/2810 [==============================] - 0s 83us/step - loss: 15.4752 - acc: 0.0021\n",
      "Epoch 74/100\n",
      "2810/2810 [==============================] - 0s 82us/step - loss: 15.4439 - acc: 0.0018\n",
      "Epoch 75/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.4587 - acc: 0.0011\n",
      "Epoch 76/100\n",
      "2810/2810 [==============================] - 0s 78us/step - loss: 15.4439 - acc: 0.0014\n",
      "Epoch 77/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.4369 - acc: 0.0014\n",
      "Epoch 78/100\n",
      "2810/2810 [==============================] - 0s 83us/step - loss: 15.5685 - acc: 0.0025\n",
      "Epoch 79/100\n",
      "2810/2810 [==============================] - 0s 82us/step - loss: 15.4591 - acc: 0.0032\n",
      "Epoch 80/100\n",
      "2810/2810 [==============================] - 0s 82us/step - loss: 15.4619 - acc: 0.0025\n",
      "Epoch 81/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.5327 - acc: 0.0014\n",
      "Epoch 82/100\n",
      "2810/2810 [==============================] - 0s 80us/step - loss: 15.4100 - acc: 0.0021\n",
      "Epoch 83/100\n",
      "2810/2810 [==============================] - 0s 75us/step - loss: 15.4750 - acc: 0.0018\n",
      "Epoch 84/100\n",
      "2810/2810 [==============================] - 0s 70us/step - loss: 15.4421 - acc: 0.0021\n",
      "Epoch 85/100\n",
      "2810/2810 [==============================] - 0s 72us/step - loss: 15.4375 - acc: 0.0021\n",
      "Epoch 86/100\n",
      "2810/2810 [==============================] - 0s 71us/step - loss: 15.4191 - acc: 0.0011\n",
      "Epoch 87/100\n",
      "2810/2810 [==============================] - 0s 72us/step - loss: 15.4408 - acc: 0.0014\n",
      "Epoch 88/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.3743 - acc: 0.0011\n",
      "Epoch 89/100\n",
      "2810/2810 [==============================] - 0s 72us/step - loss: 15.4472 - acc: 0.0025\n",
      "Epoch 90/100\n",
      "2810/2810 [==============================] - 0s 70us/step - loss: 15.4599 - acc: 0.0028\n",
      "Epoch 91/100\n",
      "2810/2810 [==============================] - 0s 81us/step - loss: 15.4673 - acc: 0.0021\n",
      "Epoch 92/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.3699 - acc: 0.0032\n",
      "Epoch 93/100\n",
      "2810/2810 [==============================] - 0s 79us/step - loss: 15.4538 - acc: 0.0025\n",
      "Epoch 94/100\n",
      "2810/2810 [==============================] - 0s 72us/step - loss: 15.3866 - acc: 0.0018\n",
      "Epoch 95/100\n",
      "2810/2810 [==============================] - 0s 72us/step - loss: 15.4642 - acc: 0.0018\n",
      "Epoch 96/100\n",
      "2810/2810 [==============================] - 0s 77us/step - loss: 15.4628 - acc: 0.0018\n",
      "Epoch 97/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.4591 - acc: 0.0018\n",
      "Epoch 98/100\n",
      "2810/2810 [==============================] - 0s 76us/step - loss: 15.4223 - acc: 0.0025\n",
      "Epoch 99/100\n",
      "2810/2810 [==============================] - 0s 72us/step - loss: 15.4522 - acc: 0.0025\n",
      "Epoch 100/100\n",
      "2810/2810 [==============================] - 0s 70us/step - loss: 15.4282 - acc: 0.0028\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2080/2982 [===================>..........] - ETA: 0s - loss: 15.2729 - acc: 0.0019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.3877 - acc: 0.0027\n",
      "Epoch 2/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.2650 - acc: 0.0027\n",
      "Epoch 3/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 15.2625 - acc: 0.0023\n",
      "Epoch 4/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.3136 - acc: 0.0020\n",
      "Epoch 5/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 15.2784 - acc: 0.0023\n",
      "Epoch 6/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.2429 - acc: 0.0020\n",
      "Epoch 7/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.2586 - acc: 6.7069e-04\n",
      "Epoch 8/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.2594 - acc: 0.0023\n",
      "Epoch 9/100\n",
      "2982/2982 [==============================] - 0s 73us/step - loss: 15.2351 - acc: 0.0023\n",
      "Epoch 10/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.2652 - acc: 0.0020\n",
      "Epoch 11/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.1987 - acc: 0.0027\n",
      "Epoch 12/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.2129 - acc: 0.0023\n",
      "Epoch 13/100\n",
      "2982/2982 [==============================] - 0s 71us/step - loss: 15.2620 - acc: 0.0017\n",
      "Epoch 14/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.1954 - acc: 0.0023\n",
      "Epoch 15/100\n",
      "2982/2982 [==============================] - 0s 73us/step - loss: 15.1403 - acc: 0.0023\n",
      "Epoch 16/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 15.1768 - acc: 0.0027\n",
      "Epoch 17/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.2087 - acc: 0.0023\n",
      "Epoch 18/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.1936 - acc: 0.0020\n",
      "Epoch 19/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.2184 - acc: 0.0023\n",
      "Epoch 20/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.1874 - acc: 0.0017\n",
      "Epoch 21/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.2242 - acc: 0.0020\n",
      "Epoch 22/100\n",
      "2982/2982 [==============================] - 0s 72us/step - loss: 15.1118 - acc: 0.0027\n",
      "Epoch 23/100\n",
      "2982/2982 [==============================] - 0s 73us/step - loss: 15.0835 - acc: 0.0020\n",
      "Epoch 24/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.0772 - acc: 0.0023\n",
      "Epoch 25/100\n",
      "2982/2982 [==============================] - 0s 79us/step - loss: 15.1085 - acc: 0.0030\n",
      "Epoch 26/100\n",
      "2982/2982 [==============================] - 0s 72us/step - loss: 15.0281 - acc: 0.0037\n",
      "Epoch 27/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.1792 - acc: 0.0030\n",
      "Epoch 28/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.1727 - acc: 0.0013\n",
      "Epoch 29/100\n",
      "2982/2982 [==============================] - 0s 79us/step - loss: 15.0667 - acc: 0.0020\n",
      "Epoch 30/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.0211 - acc: 0.0023\n",
      "Epoch 31/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 15.1122 - acc: 0.0027\n",
      "Epoch 32/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 15.0484 - acc: 0.0027\n",
      "Epoch 33/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.1234 - acc: 0.0017\n",
      "Epoch 34/100\n",
      "2982/2982 [==============================] - 0s 81us/step - loss: 15.0462 - acc: 0.0030\n",
      "Epoch 35/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.1034 - acc: 0.0020\n",
      "Epoch 36/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.0810 - acc: 0.0023\n",
      "Epoch 37/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.0770 - acc: 0.0023\n",
      "Epoch 38/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.0060 - acc: 0.0023\n",
      "Epoch 39/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 15.0154 - acc: 0.0020\n",
      "Epoch 40/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 15.0727 - acc: 0.0027\n",
      "Epoch 41/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.1136 - acc: 0.0023\n",
      "Epoch 42/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 15.0804 - acc: 0.0034\n",
      "Epoch 43/100\n",
      "2982/2982 [==============================] - 0s 79us/step - loss: 15.0633 - acc: 0.0030\n",
      "Epoch 44/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.0315 - acc: 0.0030\n",
      "Epoch 45/100\n",
      "2982/2982 [==============================] - 0s 80us/step - loss: 15.0240 - acc: 0.0027\n",
      "Epoch 46/100\n",
      "2982/2982 [==============================] - 0s 94us/step - loss: 14.9863 - acc: 0.0017\n",
      "Epoch 47/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 14.9999 - acc: 0.0020\n",
      "Epoch 48/100\n",
      "2982/2982 [==============================] - 0s 86us/step - loss: 15.0356 - acc: 0.0017\n",
      "Epoch 49/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 15.1156 - acc: 0.0027\n",
      "Epoch 50/100\n",
      "2982/2982 [==============================] - 0s 90us/step - loss: 15.0410 - acc: 0.0023\n",
      "Epoch 51/100\n",
      "2982/2982 [==============================] - 0s 110us/step - loss: 14.9596 - acc: 0.0030\n",
      "Epoch 52/100\n",
      "2982/2982 [==============================] - 0s 98us/step - loss: 14.9990 - acc: 0.0013\n",
      "Epoch 53/100\n",
      "2982/2982 [==============================] - 0s 79us/step - loss: 15.0006 - acc: 0.0023\n",
      "Epoch 54/100\n",
      "2982/2982 [==============================] - 0s 80us/step - loss: 14.9492 - acc: 0.0034\n",
      "Epoch 55/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 14.9485 - acc: 0.0010\n",
      "Epoch 56/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 14.9860 - acc: 0.0023\n",
      "Epoch 57/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 15.0513 - acc: 0.0030\n",
      "Epoch 58/100\n",
      "2982/2982 [==============================] - 0s 79us/step - loss: 14.9076 - acc: 0.0027\n",
      "Epoch 59/100\n",
      "2982/2982 [==============================] - 0s 81us/step - loss: 15.0535 - acc: 0.0020\n",
      "Epoch 60/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 14.9405 - acc: 0.0020\n",
      "Epoch 61/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 14.9242 - acc: 0.0037\n",
      "Epoch 62/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 14.9803 - acc: 0.0034\n",
      "Epoch 63/100\n",
      "2982/2982 [==============================] - 0s 80us/step - loss: 15.0061 - acc: 0.0034\n",
      "Epoch 64/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 14.9362 - acc: 0.0030\n",
      "Epoch 65/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.9774 - acc: 0.0030\n",
      "Epoch 66/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.8982 - acc: 0.0023\n",
      "Epoch 67/100\n",
      "2982/2982 [==============================] - 0s 80us/step - loss: 14.8705 - acc: 0.0023\n",
      "Epoch 68/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.9725 - acc: 0.0023\n",
      "Epoch 69/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.9031 - acc: 0.0027\n",
      "Epoch 70/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 14.9373 - acc: 0.0027\n",
      "Epoch 71/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.9589 - acc: 0.0023\n",
      "Epoch 72/100\n",
      "2982/2982 [==============================] - 0s 81us/step - loss: 14.9661 - acc: 0.0017\n",
      "Epoch 73/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.9301 - acc: 0.0027\n",
      "Epoch 74/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 15.0312 - acc: 0.0030\n",
      "Epoch 75/100\n",
      "2982/2982 [==============================] - 0s 79us/step - loss: 15.0186 - acc: 0.0030\n",
      "Epoch 76/100\n",
      "2982/2982 [==============================] - 0s 80us/step - loss: 14.9648 - acc: 0.0020\n",
      "Epoch 77/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 15.0326 - acc: 0.0030\n",
      "Epoch 78/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 14.9340 - acc: 0.0023\n",
      "Epoch 79/100\n",
      "2982/2982 [==============================] - 0s 78us/step - loss: 14.8830 - acc: 0.0020\n",
      "Epoch 80/100\n",
      "2982/2982 [==============================] - 0s 81us/step - loss: 14.9349 - acc: 0.0017\n",
      "Epoch 81/100\n",
      "2982/2982 [==============================] - 0s 82us/step - loss: 14.9526 - acc: 0.0034\n",
      "Epoch 82/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.8940 - acc: 0.0030\n",
      "Epoch 83/100\n",
      "2982/2982 [==============================] - 0s 73us/step - loss: 14.8912 - acc: 0.0020\n",
      "Epoch 84/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.9175 - acc: 0.0037\n",
      "Epoch 85/100\n",
      "2982/2982 [==============================] - 0s 73us/step - loss: 14.9951 - acc: 0.0023\n",
      "Epoch 86/100\n",
      "2982/2982 [==============================] - 0s 73us/step - loss: 14.9379 - acc: 0.0027\n",
      "Epoch 87/100\n",
      "2982/2982 [==============================] - 0s 73us/step - loss: 14.8299 - acc: 0.0023\n",
      "Epoch 88/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 14.9309 - acc: 0.0017\n",
      "Epoch 89/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 14.8370 - acc: 0.0030\n",
      "Epoch 90/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 14.8366 - acc: 0.0034\n",
      "Epoch 91/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.9749 - acc: 0.0023\n",
      "Epoch 92/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 14.9694 - acc: 0.0030\n",
      "Epoch 93/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 14.9206 - acc: 0.0023\n",
      "Epoch 94/100\n",
      "2982/2982 [==============================] - 0s 76us/step - loss: 14.9500 - acc: 0.0023\n",
      "Epoch 95/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 14.8863 - acc: 0.0030\n",
      "Epoch 96/100\n",
      "2982/2982 [==============================] - 0s 73us/step - loss: 15.0456 - acc: 0.0017\n",
      "Epoch 97/100\n",
      "2982/2982 [==============================] - 0s 74us/step - loss: 14.9863 - acc: 0.0027\n",
      "Epoch 98/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 14.9247 - acc: 0.0037\n",
      "Epoch 99/100\n",
      "2982/2982 [==============================] - 0s 77us/step - loss: 14.8498 - acc: 0.0037\n",
      "Epoch 100/100\n",
      "2982/2982 [==============================] - 0s 75us/step - loss: 14.8329 - acc: 0.0040\n",
      "172/172 [==============================] - 0s 46us/step\n",
      "Epoch 1/100\n",
      "2760/3154 [=========================>....] - ETA: 0s - loss: 16.5418 - acc: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3154/3154 [==============================] - 0s 75us/step - loss: 16.5575 - acc: 0.0038\n",
      "Epoch 2/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 16.4519 - acc: 0.0035\n",
      "Epoch 3/100\n",
      "3154/3154 [==============================] - 0s 83us/step - loss: 16.2895 - acc: 0.0029\n",
      "Epoch 4/100\n",
      "3154/3154 [==============================] - 0s 72us/step - loss: 16.2149 - acc: 0.0019\n",
      "Epoch 5/100\n",
      "3154/3154 [==============================] - 0s 73us/step - loss: 16.1679 - acc: 0.0029\n",
      "Epoch 6/100\n",
      "3154/3154 [==============================] - 0s 74us/step - loss: 16.0809 - acc: 0.0022\n",
      "Epoch 7/100\n",
      "3154/3154 [==============================] - 0s 75us/step - loss: 16.0644 - acc: 0.0025\n",
      "Epoch 8/100\n",
      "3154/3154 [==============================] - 0s 76us/step - loss: 16.0731 - acc: 0.0025\n",
      "Epoch 9/100\n",
      "3154/3154 [==============================] - 0s 71us/step - loss: 16.0908 - acc: 0.0029\n",
      "Epoch 10/100\n",
      "3154/3154 [==============================] - 0s 72us/step - loss: 16.0279 - acc: 0.0019\n",
      "Epoch 11/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 16.0568 - acc: 0.0019\n",
      "Epoch 12/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.9771 - acc: 0.0019\n",
      "Epoch 13/100\n",
      "3154/3154 [==============================] - 0s 81us/step - loss: 15.9784 - acc: 0.0035\n",
      "Epoch 14/100\n",
      "3154/3154 [==============================] - 0s 81us/step - loss: 15.9914 - acc: 0.0035\n",
      "Epoch 15/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.9676 - acc: 0.0022\n",
      "Epoch 16/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.9203 - acc: 9.5117e-04\n",
      "Epoch 17/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.9551 - acc: 0.0022\n",
      "Epoch 18/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.8783 - acc: 0.0029\n",
      "Epoch 19/100\n",
      "3154/3154 [==============================] - 0s 75us/step - loss: 16.0210 - acc: 0.0038\n",
      "Epoch 20/100\n",
      "3154/3154 [==============================] - 0s 75us/step - loss: 15.9353 - acc: 0.0035\n",
      "Epoch 21/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.9128 - acc: 0.0032\n",
      "Epoch 22/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.9419 - acc: 0.0025\n",
      "Epoch 23/100\n",
      "3154/3154 [==============================] - 0s 83us/step - loss: 15.9195 - acc: 0.0025\n",
      "Epoch 24/100\n",
      "3154/3154 [==============================] - 0s 110us/step - loss: 15.9319 - acc: 0.0038\n",
      "Epoch 25/100\n",
      "3154/3154 [==============================] - 0s 87us/step - loss: 15.9013 - acc: 0.0029\n",
      "Epoch 26/100\n",
      "3154/3154 [==============================] - 0s 84us/step - loss: 15.9652 - acc: 0.0035\n",
      "Epoch 27/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.8627 - acc: 0.0035\n",
      "Epoch 28/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.9566 - acc: 0.0022\n",
      "Epoch 29/100\n",
      "3154/3154 [==============================] - 0s 74us/step - loss: 15.8781 - acc: 0.0025\n",
      "Epoch 30/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.8788 - acc: 0.0025\n",
      "Epoch 31/100\n",
      "3154/3154 [==============================] - 0s 76us/step - loss: 15.8385 - acc: 0.0019\n",
      "Epoch 32/100\n",
      "3154/3154 [==============================] - 0s 81us/step - loss: 15.8841 - acc: 0.0029\n",
      "Epoch 33/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.8018 - acc: 0.0029\n",
      "Epoch 34/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.8650 - acc: 0.0022\n",
      "Epoch 35/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.8524 - acc: 0.0022\n",
      "Epoch 36/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.8564 - acc: 0.0025\n",
      "Epoch 37/100\n",
      "3154/3154 [==============================] - 0s 73us/step - loss: 15.8730 - acc: 0.0022\n",
      "Epoch 38/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.8098 - acc: 0.0038\n",
      "Epoch 39/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.8636 - acc: 0.0032\n",
      "Epoch 40/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.8666 - acc: 0.0035\n",
      "Epoch 41/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.7952 - acc: 0.0025\n",
      "Epoch 42/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.7901 - acc: 0.0035\n",
      "Epoch 43/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.7690 - acc: 0.0019\n",
      "Epoch 44/100\n",
      "3154/3154 [==============================] - 0s 82us/step - loss: 15.7085 - acc: 0.0019\n",
      "Epoch 45/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.7564 - acc: 0.0032\n",
      "Epoch 46/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.7013 - acc: 0.0025\n",
      "Epoch 47/100\n",
      "3154/3154 [==============================] - 0s 74us/step - loss: 15.7437 - acc: 0.0032\n",
      "Epoch 48/100\n",
      "3154/3154 [==============================] - 0s 82us/step - loss: 15.7463 - acc: 0.0032\n",
      "Epoch 49/100\n",
      "3154/3154 [==============================] - 0s 74us/step - loss: 15.7861 - acc: 0.0029\n",
      "Epoch 50/100\n",
      "3154/3154 [==============================] - 0s 83us/step - loss: 15.6696 - acc: 0.0029\n",
      "Epoch 51/100\n",
      "3154/3154 [==============================] - 0s 72us/step - loss: 15.7350 - acc: 0.0029\n",
      "Epoch 52/100\n",
      "3154/3154 [==============================] - 0s 81us/step - loss: 15.5933 - acc: 0.0035\n",
      "Epoch 53/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.6558 - acc: 0.0022\n",
      "Epoch 54/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.7372 - acc: 0.0022\n",
      "Epoch 55/100\n",
      "3154/3154 [==============================] - 0s 75us/step - loss: 15.7140 - acc: 0.0029\n",
      "Epoch 56/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.7032 - acc: 0.0022\n",
      "Epoch 57/100\n",
      "3154/3154 [==============================] - 0s 81us/step - loss: 15.7437 - acc: 0.0032\n",
      "Epoch 58/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.7234 - acc: 0.0035\n",
      "Epoch 59/100\n",
      "3154/3154 [==============================] - 0s 81us/step - loss: 15.6838 - acc: 0.0019\n",
      "Epoch 60/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.6124 - acc: 0.0019\n",
      "Epoch 61/100\n",
      "3154/3154 [==============================] - 0s 84us/step - loss: 15.7649 - acc: 0.0032\n",
      "Epoch 62/100\n",
      "3154/3154 [==============================] - 0s 83us/step - loss: 15.5823 - acc: 0.0035\n",
      "Epoch 63/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.7092 - acc: 0.0025\n",
      "Epoch 64/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.6807 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "3154/3154 [==============================] - 0s 82us/step - loss: 15.6608 - acc: 0.0029\n",
      "Epoch 66/100\n",
      "3154/3154 [==============================] - 0s 82us/step - loss: 15.6323 - acc: 0.0032\n",
      "Epoch 67/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.7251 - acc: 0.0022\n",
      "Epoch 68/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.6167 - acc: 0.0022\n",
      "Epoch 69/100\n",
      "3154/3154 [==============================] - 0s 81us/step - loss: 15.6449 - acc: 0.0019\n",
      "Epoch 70/100\n",
      "3154/3154 [==============================] - 0s 83us/step - loss: 15.5757 - acc: 0.0029\n",
      "Epoch 71/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.6294 - acc: 0.0022\n",
      "Epoch 72/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.6167 - acc: 0.0016\n",
      "Epoch 73/100\n",
      "3154/3154 [==============================] - 0s 83us/step - loss: 15.5757 - acc: 0.0025\n",
      "Epoch 74/100\n",
      "3154/3154 [==============================] - 0s 84us/step - loss: 15.5862 - acc: 0.0032\n",
      "Epoch 75/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.5750 - acc: 0.0032\n",
      "Epoch 76/100\n",
      "3154/3154 [==============================] - 0s 86us/step - loss: 15.6496 - acc: 0.0022\n",
      "Epoch 77/100\n",
      "3154/3154 [==============================] - 0s 86us/step - loss: 15.5761 - acc: 0.0022\n",
      "Epoch 78/100\n",
      "3154/3154 [==============================] - 0s 82us/step - loss: 15.6083 - acc: 0.0019\n",
      "Epoch 79/100\n",
      "3154/3154 [==============================] - 0s 89us/step - loss: 15.6557 - acc: 0.0013\n",
      "Epoch 80/100\n",
      "3154/3154 [==============================] - 0s 90us/step - loss: 15.6201 - acc: 0.0022\n",
      "Epoch 81/100\n",
      "3154/3154 [==============================] - 0s 91us/step - loss: 15.5242 - acc: 0.0032\n",
      "Epoch 82/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.6260 - acc: 0.0029\n",
      "Epoch 83/100\n",
      "3154/3154 [==============================] - 0s 76us/step - loss: 15.5005 - acc: 0.0022\n",
      "Epoch 84/100\n",
      "3154/3154 [==============================] - 0s 79us/step - loss: 15.5778 - acc: 0.0019\n",
      "Epoch 85/100\n",
      "3154/3154 [==============================] - 0s 76us/step - loss: 15.5727 - acc: 0.0022\n",
      "Epoch 86/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.6069 - acc: 0.0022\n",
      "Epoch 87/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.5536 - acc: 0.0019\n",
      "Epoch 88/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.6711 - acc: 0.0022\n",
      "Epoch 89/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.5788 - acc: 0.0025\n",
      "Epoch 90/100\n",
      "3154/3154 [==============================] - 0s 73us/step - loss: 15.6042 - acc: 0.0016\n",
      "Epoch 91/100\n",
      "3154/3154 [==============================] - 0s 73us/step - loss: 15.4795 - acc: 0.0032\n",
      "Epoch 92/100\n",
      "3154/3154 [==============================] - 0s 82us/step - loss: 15.5262 - acc: 0.0029\n",
      "Epoch 93/100\n",
      "3154/3154 [==============================] - 0s 82us/step - loss: 15.5055 - acc: 0.0029\n",
      "Epoch 94/100\n",
      "3154/3154 [==============================] - 0s 80us/step - loss: 15.5798 - acc: 0.0013\n",
      "Epoch 95/100\n",
      "3154/3154 [==============================] - 0s 81us/step - loss: 15.4584 - acc: 0.0019\n",
      "Epoch 96/100\n",
      "3154/3154 [==============================] - 0s 83us/step - loss: 15.5465 - acc: 0.0025\n",
      "Epoch 97/100\n",
      "3154/3154 [==============================] - 0s 77us/step - loss: 15.5298 - acc: 0.0025\n",
      "Epoch 98/100\n",
      "3154/3154 [==============================] - 0s 75us/step - loss: 15.5125 - acc: 0.0029\n",
      "Epoch 99/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.4271 - acc: 0.0022\n",
      "Epoch 100/100\n",
      "3154/3154 [==============================] - 0s 78us/step - loss: 15.4929 - acc: 0.0019\n",
      "172/172 [==============================] - 0s 46us/step\n",
      "Epoch 1/100\n",
      "2490/3326 [=====================>........] - ETA: 0s - loss: 15.4550 - acc: 0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3326/3326 [==============================] - 0s 84us/step - loss: 15.4227 - acc: 0.0018\n",
      "Epoch 2/100\n",
      "3326/3326 [==============================] - 0s 72us/step - loss: 15.4941 - acc: 0.0030\n",
      "Epoch 3/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.3863 - acc: 0.0021\n",
      "Epoch 4/100\n",
      "3326/3326 [==============================] - 0s 74us/step - loss: 15.4862 - acc: 0.0027\n",
      "Epoch 5/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.4134 - acc: 0.0027\n",
      "Epoch 6/100\n",
      "3326/3326 [==============================] - 0s 71us/step - loss: 15.3812 - acc: 0.0015\n",
      "Epoch 7/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.3125 - acc: 0.0030\n",
      "Epoch 8/100\n",
      "3326/3326 [==============================] - 0s 74us/step - loss: 15.4364 - acc: 0.0027\n",
      "Epoch 9/100\n",
      "3326/3326 [==============================] - 0s 74us/step - loss: 15.4383 - acc: 0.0024\n",
      "Epoch 10/100\n",
      "3326/3326 [==============================] - 0s 88us/step - loss: 15.4541 - acc: 0.0018\n",
      "Epoch 11/100\n",
      "3326/3326 [==============================] - 0s 99us/step - loss: 15.3634 - acc: 0.0021\n",
      "Epoch 12/100\n",
      "3326/3326 [==============================] - 0s 107us/step - loss: 15.4083 - acc: 0.0015\n",
      "Epoch 13/100\n",
      "3326/3326 [==============================] - 0s 99us/step - loss: 15.3857 - acc: 0.0015\n",
      "Epoch 14/100\n",
      "3326/3326 [==============================] - 0s 76us/step - loss: 15.4034 - acc: 0.0021\n",
      "Epoch 15/100\n",
      "3326/3326 [==============================] - 0s 83us/step - loss: 15.3808 - acc: 0.0024\n",
      "Epoch 16/100\n",
      "3326/3326 [==============================] - 0s 84us/step - loss: 15.4080 - acc: 0.0012\n",
      "Epoch 17/100\n",
      "3326/3326 [==============================] - 0s 74us/step - loss: 15.4653 - acc: 0.0015\n",
      "Epoch 18/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.3846 - acc: 0.0018\n",
      "Epoch 19/100\n",
      "3326/3326 [==============================] - 0s 76us/step - loss: 15.3521 - acc: 0.0021\n",
      "Epoch 20/100\n",
      "3326/3326 [==============================] - 0s 78us/step - loss: 15.3611 - acc: 0.0018\n",
      "Epoch 21/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.3789 - acc: 0.0018\n",
      "Epoch 22/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.3351 - acc: 0.0027\n",
      "Epoch 23/100\n",
      "3326/3326 [==============================] - 0s 78us/step - loss: 15.3784 - acc: 0.0024\n",
      "Epoch 24/100\n",
      "3326/3326 [==============================] - 0s 77us/step - loss: 15.3345 - acc: 0.0012\n",
      "Epoch 25/100\n",
      "3326/3326 [==============================] - 0s 76us/step - loss: 15.4205 - acc: 0.0024\n",
      "Epoch 26/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.3263 - acc: 0.0018\n",
      "Epoch 27/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.4414 - acc: 0.0015\n",
      "Epoch 28/100\n",
      "3326/3326 [==============================] - 0s 76us/step - loss: 15.3729 - acc: 0.0021\n",
      "Epoch 29/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.3650 - acc: 0.0021\n",
      "Epoch 30/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.4167 - acc: 0.0018\n",
      "Epoch 31/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.3163 - acc: 0.0018\n",
      "Epoch 32/100\n",
      "3326/3326 [==============================] - 0s 77us/step - loss: 15.5055 - acc: 0.0015\n",
      "Epoch 33/100\n",
      "3326/3326 [==============================] - 0s 72us/step - loss: 15.4191 - acc: 0.0024\n",
      "Epoch 34/100\n",
      "3326/3326 [==============================] - 0s 78us/step - loss: 15.3516 - acc: 0.0021\n",
      "Epoch 35/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.3190 - acc: 0.0015\n",
      "Epoch 36/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.3891 - acc: 0.0021\n",
      "Epoch 37/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.4462 - acc: 9.0198e-04\n",
      "Epoch 38/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.2973 - acc: 0.0027\n",
      "Epoch 39/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.4494 - acc: 0.0024\n",
      "Epoch 40/100\n",
      "3326/3326 [==============================] - 0s 78us/step - loss: 15.3340 - acc: 0.0018\n",
      "Epoch 41/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.4447 - acc: 0.0021\n",
      "Epoch 42/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.4207 - acc: 0.0015\n",
      "Epoch 43/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.2858 - acc: 0.0021\n",
      "Epoch 44/100\n",
      "3326/3326 [==============================] - 0s 88us/step - loss: 15.4142 - acc: 9.0198e-04\n",
      "Epoch 45/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.3098 - acc: 0.0018\n",
      "Epoch 46/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.4326 - acc: 0.0018\n",
      "Epoch 47/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.2664 - acc: 0.0024\n",
      "Epoch 48/100\n",
      "3326/3326 [==============================] - 0s 78us/step - loss: 15.3866 - acc: 0.0021\n",
      "Epoch 49/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.3410 - acc: 0.0021\n",
      "Epoch 50/100\n",
      "3326/3326 [==============================] - 0s 83us/step - loss: 15.3372 - acc: 0.0021\n",
      "Epoch 51/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.3370 - acc: 0.0024\n",
      "Epoch 52/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.3858 - acc: 0.0012\n",
      "Epoch 53/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.3865 - acc: 0.0012\n",
      "Epoch 54/100\n",
      "3326/3326 [==============================] - 0s 85us/step - loss: 15.3621 - acc: 0.0012\n",
      "Epoch 55/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.3674 - acc: 0.0015\n",
      "Epoch 56/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.4266 - acc: 0.0021\n",
      "Epoch 57/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.3378 - acc: 0.0018\n",
      "Epoch 58/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.3989 - acc: 0.0018\n",
      "Epoch 59/100\n",
      "3326/3326 [==============================] - 0s 78us/step - loss: 15.3500 - acc: 0.0024\n",
      "Epoch 60/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.2962 - acc: 0.0021\n",
      "Epoch 61/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.3487 - acc: 0.0018\n",
      "Epoch 62/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.3528 - acc: 0.0027\n",
      "Epoch 63/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.4204 - acc: 0.0021\n",
      "Epoch 64/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.2737 - acc: 0.0021\n",
      "Epoch 65/100\n",
      "3326/3326 [==============================] - 0s 83us/step - loss: 15.3454 - acc: 0.0021\n",
      "Epoch 66/100\n",
      "3326/3326 [==============================] - 0s 78us/step - loss: 15.3503 - acc: 0.0018\n",
      "Epoch 67/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.3487 - acc: 0.0015\n",
      "Epoch 68/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.2892 - acc: 0.0024\n",
      "Epoch 69/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.3330 - acc: 0.0027\n",
      "Epoch 70/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.3874 - acc: 0.0015\n",
      "Epoch 71/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.3560 - acc: 0.0030\n",
      "Epoch 72/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.3840 - acc: 0.0018\n",
      "Epoch 73/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.3142 - acc: 0.0021\n",
      "Epoch 74/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.3134 - acc: 0.0027\n",
      "Epoch 75/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.3508 - acc: 0.0018\n",
      "Epoch 76/100\n",
      "3326/3326 [==============================] - 0s 83us/step - loss: 15.3146 - acc: 0.0018\n",
      "Epoch 77/100\n",
      "3326/3326 [==============================] - 0s 80us/step - loss: 15.3662 - acc: 0.0018\n",
      "Epoch 78/100\n",
      "3326/3326 [==============================] - 0s 81us/step - loss: 15.3177 - acc: 0.0021\n",
      "Epoch 79/100\n",
      "3326/3326 [==============================] - 0s 82us/step - loss: 15.3106 - acc: 0.0018\n",
      "Epoch 80/100\n",
      "3326/3326 [==============================] - 0s 85us/step - loss: 15.3088 - acc: 0.0015\n",
      "Epoch 81/100\n",
      "3326/3326 [==============================] - 0s 79us/step - loss: 15.2944 - acc: 0.0024\n",
      "Epoch 82/100\n",
      "3326/3326 [==============================] - 0s 78us/step - loss: 15.3003 - acc: 0.0024\n",
      "Epoch 83/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.3911 - acc: 0.0024\n",
      "Epoch 84/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.3239 - acc: 0.0015\n",
      "Epoch 85/100\n",
      "3326/3326 [==============================] - 0s 71us/step - loss: 15.3183 - acc: 0.0015\n",
      "Epoch 86/100\n",
      "3326/3326 [==============================] - 0s 70us/step - loss: 15.3638 - acc: 0.0018\n",
      "Epoch 87/100\n",
      "3326/3326 [==============================] - 0s 72us/step - loss: 15.2020 - acc: 0.0015\n",
      "Epoch 88/100\n",
      "3326/3326 [==============================] - 0s 76us/step - loss: 15.2613 - acc: 0.0018\n",
      "Epoch 89/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.3868 - acc: 0.0024\n",
      "Epoch 90/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.2747 - acc: 9.0198e-04\n",
      "Epoch 91/100\n",
      "3326/3326 [==============================] - 0s 72us/step - loss: 15.2387 - acc: 0.0018\n",
      "Epoch 92/100\n",
      "3326/3326 [==============================] - 0s 76us/step - loss: 15.2823 - acc: 0.0015\n",
      "Epoch 93/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.3524 - acc: 0.0018\n",
      "Epoch 94/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.2791 - acc: 0.0018\n",
      "Epoch 95/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.4261 - acc: 0.0024\n",
      "Epoch 96/100\n",
      "3326/3326 [==============================] - 0s 77us/step - loss: 15.2487 - acc: 0.0015\n",
      "Epoch 97/100\n",
      "3326/3326 [==============================] - 0s 74us/step - loss: 15.2886 - acc: 0.0018\n",
      "Epoch 98/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.3938 - acc: 0.0018\n",
      "Epoch 99/100\n",
      "3326/3326 [==============================] - 0s 75us/step - loss: 15.2652 - acc: 0.0021\n",
      "Epoch 100/100\n",
      "3326/3326 [==============================] - 0s 73us/step - loss: 15.2701 - acc: 0.0018\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2870/3498 [=======================>......] - ETA: 0s - loss: 16.2434 - acc: 0.0028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.7626 - acc: 0.0029\n",
      "Epoch 2/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.7695 - acc: 0.0017\n",
      "Epoch 3/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.7285 - acc: 0.0029\n",
      "Epoch 4/100\n",
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.7744 - acc: 0.0026\n",
      "Epoch 5/100\n",
      "3498/3498 [==============================] - 0s 70us/step - loss: 15.7179 - acc: 0.0011\n",
      "Epoch 6/100\n",
      "3498/3498 [==============================] - 0s 69us/step - loss: 15.6859 - acc: 0.0017\n",
      "Epoch 7/100\n",
      "3498/3498 [==============================] - 0s 71us/step - loss: 15.7279 - acc: 0.0026\n",
      "Epoch 8/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.7498 - acc: 0.0017\n",
      "Epoch 9/100\n",
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.6920 - acc: 0.0020\n",
      "Epoch 10/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.7034 - acc: 0.0020\n",
      "Epoch 11/100\n",
      "3498/3498 [==============================] - 0s 70us/step - loss: 15.7065 - acc: 0.0017\n",
      "Epoch 12/100\n",
      "3498/3498 [==============================] - 0s 73us/step - loss: 15.6428 - acc: 0.0023\n",
      "Epoch 13/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.7092 - acc: 0.0026\n",
      "Epoch 14/100\n",
      "3498/3498 [==============================] - 0s 71us/step - loss: 15.7353 - acc: 0.0023\n",
      "Epoch 15/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.7600 - acc: 0.0026\n",
      "Epoch 16/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.6690 - acc: 0.0029\n",
      "Epoch 17/100\n",
      "3498/3498 [==============================] - 0s 80us/step - loss: 15.7401 - acc: 0.0017\n",
      "Epoch 18/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.7100 - acc: 0.0020\n",
      "Epoch 19/100\n",
      "3498/3498 [==============================] - 0s 81us/step - loss: 15.6833 - acc: 0.0031A: 0s - loss: 15.2615 - acc: \n",
      "Epoch 20/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.7772 - acc: 0.0031\n",
      "Epoch 21/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.6944 - acc: 0.0020\n",
      "Epoch 22/100\n",
      "3498/3498 [==============================] - 0s 73us/step - loss: 15.7354 - acc: 0.0029\n",
      "Epoch 23/100\n",
      "3498/3498 [==============================] - 0s 71us/step - loss: 15.7043 - acc: 0.0020\n",
      "Epoch 24/100\n",
      "3498/3498 [==============================] - 0s 84us/step - loss: 15.6776 - acc: 0.0017\n",
      "Epoch 25/100\n",
      "3498/3498 [==============================] - 0s 76us/step - loss: 15.6585 - acc: 0.0020\n",
      "Epoch 26/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.6892 - acc: 0.0026\n",
      "Epoch 27/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6322 - acc: 0.0029\n",
      "Epoch 28/100\n",
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.6515 - acc: 0.0031\n",
      "Epoch 29/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.7165 - acc: 0.0026\n",
      "Epoch 30/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.6621 - acc: 0.0029\n",
      "Epoch 31/100\n",
      "3498/3498 [==============================] - 0s 80us/step - loss: 15.6922 - acc: 0.0020\n",
      "Epoch 32/100\n",
      "3498/3498 [==============================] - 0s 80us/step - loss: 15.7772 - acc: 0.0023\n",
      "Epoch 33/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.7823 - acc: 0.0026\n",
      "Epoch 34/100\n",
      "3498/3498 [==============================] - 0s 88us/step - loss: 15.6896 - acc: 0.0020\n",
      "Epoch 35/100\n",
      "3498/3498 [==============================] - 0s 88us/step - loss: 15.7279 - acc: 0.0029\n",
      "Epoch 36/100\n",
      "3498/3498 [==============================] - 0s 87us/step - loss: 15.7085 - acc: 0.0023\n",
      "Epoch 37/100\n",
      "3498/3498 [==============================] - 0s 82us/step - loss: 15.7375 - acc: 0.0017\n",
      "Epoch 38/100\n",
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.7147 - acc: 0.0020\n",
      "Epoch 39/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6977 - acc: 0.0014\n",
      "Epoch 40/100\n",
      "3498/3498 [==============================] - 0s 73us/step - loss: 15.6185 - acc: 0.0023\n",
      "Epoch 41/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.6928 - acc: 0.0020\n",
      "Epoch 42/100\n",
      "3498/3498 [==============================] - 0s 76us/step - loss: 15.7000 - acc: 0.0020\n",
      "Epoch 43/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.7038 - acc: 0.0023\n",
      "Epoch 44/100\n",
      "3498/3498 [==============================] - 0s 76us/step - loss: 15.6887 - acc: 0.0020\n",
      "Epoch 45/100\n",
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.6621 - acc: 0.0031\n",
      "Epoch 46/100\n",
      "3498/3498 [==============================] - 0s 76us/step - loss: 15.7271 - acc: 0.0017\n",
      "Epoch 47/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6751 - acc: 0.0020\n",
      "Epoch 48/100\n",
      "3498/3498 [==============================] - 0s 80us/step - loss: 15.7109 - acc: 0.0023\n",
      "Epoch 49/100\n",
      "3498/3498 [==============================] - 0s 83us/step - loss: 15.6452 - acc: 0.0031\n",
      "Epoch 50/100\n",
      "3498/3498 [==============================] - 0s 79us/step - loss: 15.7838 - acc: 0.0017\n",
      "Epoch 51/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.7389 - acc: 0.0017\n",
      "Epoch 52/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.6955 - acc: 0.0020\n",
      "Epoch 53/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6665 - acc: 0.0026\n",
      "Epoch 54/100\n",
      "3498/3498 [==============================] - 0s 76us/step - loss: 15.6787 - acc: 0.0023\n",
      "Epoch 55/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6261 - acc: 0.0026\n",
      "Epoch 56/100\n",
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.6855 - acc: 0.0023\n",
      "Epoch 57/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.7224 - acc: 0.0023\n",
      "Epoch 58/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6646 - acc: 0.0023\n",
      "Epoch 59/100\n",
      "3498/3498 [==============================] - 0s 82us/step - loss: 15.6438 - acc: 0.0026\n",
      "Epoch 60/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6723 - acc: 0.0014\n",
      "Epoch 61/100\n",
      "3498/3498 [==============================] - 0s 79us/step - loss: 15.7184 - acc: 0.0020\n",
      "Epoch 62/100\n",
      "3498/3498 [==============================] - 0s 79us/step - loss: 15.6356 - acc: 0.0014\n",
      "Epoch 63/100\n",
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.6910 - acc: 0.0034\n",
      "Epoch 64/100\n",
      "3498/3498 [==============================] - 0s 79us/step - loss: 15.6445 - acc: 0.0031\n",
      "Epoch 65/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.7073 - acc: 0.0031\n",
      "Epoch 66/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6080 - acc: 0.0023\n",
      "Epoch 67/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.6705 - acc: 0.0017\n",
      "Epoch 68/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6975 - acc: 0.0017\n",
      "Epoch 69/100\n",
      "3498/3498 [==============================] - 0s 80us/step - loss: 15.6260 - acc: 0.0017\n",
      "Epoch 70/100\n",
      "3498/3498 [==============================] - 0s 76us/step - loss: 15.6580 - acc: 0.0023\n",
      "Epoch 71/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.7185 - acc: 0.0020\n",
      "Epoch 72/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6284 - acc: 0.0023\n",
      "Epoch 73/100\n",
      "3498/3498 [==============================] - 0s 80us/step - loss: 15.6340 - acc: 0.0031\n",
      "Epoch 74/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.6292 - acc: 0.0023\n",
      "Epoch 75/100\n",
      "3498/3498 [==============================] - 0s 79us/step - loss: 15.7210 - acc: 0.0020\n",
      "Epoch 76/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6354 - acc: 0.0023\n",
      "Epoch 77/100\n",
      "3498/3498 [==============================] - 0s 84us/step - loss: 15.6682 - acc: 0.0029\n",
      "Epoch 78/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6239 - acc: 0.0017\n",
      "Epoch 79/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6377 - acc: 0.0011\n",
      "Epoch 80/100\n",
      "3498/3498 [==============================] - 0s 79us/step - loss: 15.5912 - acc: 8.5763e-04\n",
      "Epoch 81/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6736 - acc: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "3498/3498 [==============================] - 0s 74us/step - loss: 15.5722 - acc: 0.0023\n",
      "Epoch 83/100\n",
      "3498/3498 [==============================] - 0s 72us/step - loss: 15.6725 - acc: 0.0031\n",
      "Epoch 84/100\n",
      "3498/3498 [==============================] - 0s 73us/step - loss: 15.7088 - acc: 0.0017\n",
      "Epoch 85/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6568 - acc: 0.0020\n",
      "Epoch 86/100\n",
      "3498/3498 [==============================] - 0s 80us/step - loss: 15.6986 - acc: 0.0020\n",
      "Epoch 87/100\n",
      "3498/3498 [==============================] - 0s 76us/step - loss: 15.5690 - acc: 0.0023\n",
      "Epoch 88/100\n",
      "3498/3498 [==============================] - 0s 87us/step - loss: 15.6735 - acc: 0.0023\n",
      "Epoch 89/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6180 - acc: 0.0020\n",
      "Epoch 90/100\n",
      "3498/3498 [==============================] - 0s 80us/step - loss: 15.6216 - acc: 0.0020\n",
      "Epoch 91/100\n",
      "3498/3498 [==============================] - 0s 82us/step - loss: 15.5358 - acc: 0.0020\n",
      "Epoch 92/100\n",
      "3498/3498 [==============================] - 0s 98us/step - loss: 15.6238 - acc: 0.0026\n",
      "Epoch 93/100\n",
      "3498/3498 [==============================] - 0s 82us/step - loss: 15.8138 - acc: 0.0023\n",
      "Epoch 94/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6312 - acc: 0.0020\n",
      "Epoch 95/100\n",
      "3498/3498 [==============================] - 0s 78us/step - loss: 15.6082 - acc: 0.0020\n",
      "Epoch 96/100\n",
      "3498/3498 [==============================] - 0s 73us/step - loss: 15.5818 - acc: 0.0020\n",
      "Epoch 97/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6537 - acc: 0.0034\n",
      "Epoch 98/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6318 - acc: 0.0026\n",
      "Epoch 99/100\n",
      "3498/3498 [==============================] - 0s 77us/step - loss: 15.6042 - acc: 0.0023\n",
      "Epoch 100/100\n",
      "3498/3498 [==============================] - 0s 75us/step - loss: 15.6059 - acc: 0.0023\n",
      "172/172 [==============================] - 0s 41us/step\n",
      "Epoch 1/100\n",
      "2710/3670 [=====================>........] - ETA: 0s - loss: 15.8110 - acc: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.7232 - acc: 0.0019\n",
      "Epoch 2/100\n",
      "3670/3670 [==============================] - 0s 75us/step - loss: 15.6341 - acc: 0.0016\n",
      "Epoch 3/100\n",
      "3670/3670 [==============================] - 0s 73us/step - loss: 15.7197 - acc: 0.0014\n",
      "Epoch 4/100\n",
      "3670/3670 [==============================] - 0s 75us/step - loss: 15.6517 - acc: 0.0022\n",
      "Epoch 5/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.6158 - acc: 0.0019\n",
      "Epoch 6/100\n",
      "3670/3670 [==============================] - 0s 85us/step - loss: 15.6904 - acc: 0.0022\n",
      "Epoch 7/100\n",
      "3670/3670 [==============================] - 0s 85us/step - loss: 15.6164 - acc: 0.0022\n",
      "Epoch 8/100\n",
      "3670/3670 [==============================] - 0s 74us/step - loss: 15.5945 - acc: 0.0019\n",
      "Epoch 9/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.5571 - acc: 0.0019\n",
      "Epoch 10/100\n",
      "3670/3670 [==============================] - 0s 72us/step - loss: 15.6196 - acc: 0.0019\n",
      "Epoch 11/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.6048 - acc: 0.0019\n",
      "Epoch 12/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.5232 - acc: 0.0019\n",
      "Epoch 13/100\n",
      "3670/3670 [==============================] - 0s 94us/step - loss: 15.6251 - acc: 0.0019\n",
      "Epoch 14/100\n",
      "3670/3670 [==============================] - 0s 103us/step - loss: 15.5261 - acc: 0.0022\n",
      "Epoch 15/100\n",
      "3670/3670 [==============================] - 0s 105us/step - loss: 15.5580 - acc: 0.0025\n",
      "Epoch 16/100\n",
      "3670/3670 [==============================] - 0s 102us/step - loss: 15.4894 - acc: 0.0014\n",
      "Epoch 17/100\n",
      "3670/3670 [==============================] - 0s 75us/step - loss: 15.6243 - acc: 0.0019\n",
      "Epoch 18/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.5623 - acc: 0.0025\n",
      "Epoch 19/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.5803 - acc: 0.0016\n",
      "Epoch 20/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.6686 - acc: 0.0025\n",
      "Epoch 21/100\n",
      "3670/3670 [==============================] - 0s 73us/step - loss: 15.5272 - acc: 0.0019\n",
      "Epoch 22/100\n",
      "3670/3670 [==============================] - 0s 81us/step - loss: 15.5543 - acc: 0.0022\n",
      "Epoch 23/100\n",
      "3670/3670 [==============================] - 0s 99us/step - loss: 15.5243 - acc: 0.0025\n",
      "Epoch 24/100\n",
      "3670/3670 [==============================] - 0s 92us/step - loss: 15.4889 - acc: 0.0019\n",
      "Epoch 25/100\n",
      "3670/3670 [==============================] - 0s 93us/step - loss: 15.5063 - acc: 0.0019\n",
      "Epoch 26/100\n",
      "3670/3670 [==============================] - 0s 91us/step - loss: 15.5921 - acc: 0.0027\n",
      "Epoch 27/100\n",
      "3670/3670 [==============================] - 0s 88us/step - loss: 15.5762 - acc: 0.0014\n",
      "Epoch 28/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.5434 - acc: 0.0022\n",
      "Epoch 29/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.5133 - acc: 0.0022\n",
      "Epoch 30/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.4579 - acc: 0.0027\n",
      "Epoch 31/100\n",
      "3670/3670 [==============================] - 0s 73us/step - loss: 15.5158 - acc: 0.0025\n",
      "Epoch 32/100\n",
      "3670/3670 [==============================] - 0s 81us/step - loss: 15.4993 - acc: 0.0025\n",
      "Epoch 33/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.4765 - acc: 0.0022\n",
      "Epoch 34/100\n",
      "3670/3670 [==============================] - 0s 74us/step - loss: 15.5053 - acc: 0.0025\n",
      "Epoch 35/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.5205 - acc: 0.0019\n",
      "Epoch 36/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.4655 - acc: 0.0016\n",
      "Epoch 37/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.5386 - acc: 0.0030\n",
      "Epoch 38/100\n",
      "3670/3670 [==============================] - 0s 74us/step - loss: 15.5940 - acc: 0.0016\n",
      "Epoch 39/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.5246 - acc: 0.0022\n",
      "Epoch 40/100\n",
      "3670/3670 [==============================] - 0s 76us/step - loss: 15.5137 - acc: 0.0030\n",
      "Epoch 41/100\n",
      "3670/3670 [==============================] - 0s 76us/step - loss: 15.4833 - acc: 0.0019\n",
      "Epoch 42/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.4700 - acc: 0.0027\n",
      "Epoch 43/100\n",
      "3670/3670 [==============================] - 0s 75us/step - loss: 15.4769 - acc: 0.0044\n",
      "Epoch 44/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.6029 - acc: 0.0030\n",
      "Epoch 45/100\n",
      "3670/3670 [==============================] - 0s 76us/step - loss: 15.4312 - acc: 0.0030\n",
      "Epoch 46/100\n",
      "3670/3670 [==============================] - 0s 83us/step - loss: 15.4622 - acc: 0.0027\n",
      "Epoch 47/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.5353 - acc: 0.0022\n",
      "Epoch 48/100\n",
      "3670/3670 [==============================] - 0s 75us/step - loss: 15.5527 - acc: 0.0016\n",
      "Epoch 49/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.4665 - acc: 0.0016\n",
      "Epoch 50/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.5915 - acc: 0.0025\n",
      "Epoch 51/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.5149 - acc: 0.0022\n",
      "Epoch 52/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.5871 - acc: 0.0030\n",
      "Epoch 53/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.5171 - acc: 0.0033\n",
      "Epoch 54/100\n",
      "3670/3670 [==============================] - 0s 81us/step - loss: 15.4688 - acc: 0.0030\n",
      "Epoch 55/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.4379 - acc: 0.0030\n",
      "Epoch 56/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.4856 - acc: 0.0025\n",
      "Epoch 57/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.4891 - acc: 0.0033\n",
      "Epoch 58/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.4699 - acc: 0.0030\n",
      "Epoch 59/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.5340 - acc: 0.0019\n",
      "Epoch 60/100\n",
      "3670/3670 [==============================] - 0s 82us/step - loss: 15.4808 - acc: 0.0030\n",
      "Epoch 61/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.4235 - acc: 0.0027\n",
      "Epoch 62/100\n",
      "3670/3670 [==============================] - 0s 76us/step - loss: 15.4799 - acc: 0.0030\n",
      "Epoch 63/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.4952 - acc: 0.0025\n",
      "Epoch 64/100\n",
      "3670/3670 [==============================] - 0s 83us/step - loss: 15.5009 - acc: 0.0027\n",
      "Epoch 65/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.4943 - acc: 0.0027\n",
      "Epoch 66/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.3820 - acc: 0.0019\n",
      "Epoch 67/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.4935 - acc: 0.0022\n",
      "Epoch 68/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.4530 - acc: 0.0019\n",
      "Epoch 69/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.4775 - acc: 0.0022\n",
      "Epoch 70/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.4346 - acc: 0.0019\n",
      "Epoch 71/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.5045 - acc: 0.0027\n",
      "Epoch 72/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.4739 - acc: 0.0022\n",
      "Epoch 73/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.5224 - acc: 0.0035\n",
      "Epoch 74/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.4264 - acc: 0.0016\n",
      "Epoch 75/100\n",
      "3670/3670 [==============================] - 0s 77us/step - loss: 15.4548 - acc: 0.0019\n",
      "Epoch 76/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.4894 - acc: 0.0030\n",
      "Epoch 77/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.4658 - acc: 0.0025\n",
      "Epoch 78/100\n",
      "3670/3670 [==============================] - 0s 82us/step - loss: 15.5061 - acc: 0.0022\n",
      "Epoch 79/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.4257 - acc: 0.0027\n",
      "Epoch 80/100\n",
      "3670/3670 [==============================] - 0s 80us/step - loss: 15.5604 - acc: 0.0033\n",
      "Epoch 81/100\n",
      "3670/3670 [==============================] - 0s 79us/step - loss: 15.4553 - acc: 0.0025\n",
      "Epoch 82/100\n",
      "3670/3670 [==============================] - 0s 75us/step - loss: 15.4757 - acc: 0.0027\n",
      "Epoch 83/100\n",
      "3670/3670 [==============================] - 0s 71us/step - loss: 15.4626 - acc: 0.0025\n",
      "Epoch 84/100\n",
      "3670/3670 [==============================] - 0s 69us/step - loss: 15.4618 - acc: 0.0027\n",
      "Epoch 85/100\n",
      "3670/3670 [==============================] - 0s 74us/step - loss: 15.3992 - acc: 0.0022\n",
      "Epoch 86/100\n",
      "3670/3670 [==============================] - 0s 71us/step - loss: 15.4799 - acc: 0.0035\n",
      "Epoch 87/100\n",
      "3670/3670 [==============================] - 0s 70us/step - loss: 15.4988 - acc: 0.0027\n",
      "Epoch 88/100\n",
      "3670/3670 [==============================] - 0s 74us/step - loss: 15.4826 - acc: 0.0019\n",
      "Epoch 89/100\n",
      "3670/3670 [==============================] - 0s 78us/step - loss: 15.4662 - acc: 0.0025\n",
      "Epoch 90/100\n",
      "3670/3670 [==============================] - 0s 70us/step - loss: 15.4347 - acc: 0.0016\n",
      "Epoch 91/100\n",
      "3670/3670 [==============================] - 0s 71us/step - loss: 15.4569 - acc: 0.0027\n",
      "Epoch 92/100\n",
      "3670/3670 [==============================] - 0s 72us/step - loss: 15.4095 - acc: 0.0019\n",
      "Epoch 93/100\n",
      "3670/3670 [==============================] - 0s 74us/step - loss: 15.3374 - acc: 0.0019\n",
      "Epoch 94/100\n",
      "3670/3670 [==============================] - 0s 69us/step - loss: 15.4806 - acc: 0.0030\n",
      "Epoch 95/100\n",
      "3670/3670 [==============================] - 0s 72us/step - loss: 15.5162 - acc: 0.0019\n",
      "Epoch 96/100\n",
      "3670/3670 [==============================] - 0s 72us/step - loss: 15.4456 - acc: 0.0030\n",
      "Epoch 97/100\n",
      "3670/3670 [==============================] - 0s 75us/step - loss: 15.4702 - acc: 0.0030\n",
      "Epoch 98/100\n",
      "3670/3670 [==============================] - 0s 72us/step - loss: 15.4299 - acc: 0.0027\n",
      "Epoch 99/100\n",
      "3670/3670 [==============================] - 0s 71us/step - loss: 15.5091 - acc: 0.0025\n",
      "Epoch 100/100\n",
      "3670/3670 [==============================] - 0s 73us/step - loss: 15.4474 - acc: 0.0025\n",
      "172/172 [==============================] - 0s 74us/step\n",
      "Epoch 1/100\n",
      "2260/3842 [================>.............] - ETA: 0s - loss: 16.0711 - acc: 0.0013    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.7853 - acc: 0.0023\n",
      "Epoch 2/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.6940 - acc: 0.0021\n",
      "Epoch 3/100\n",
      "3842/3842 [==============================] - 0s 71us/step - loss: 15.7260 - acc: 0.0018\n",
      "Epoch 4/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.6789 - acc: 0.0026\n",
      "Epoch 5/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.6447 - acc: 0.0018\n",
      "Epoch 6/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.6361 - acc: 0.0021\n",
      "Epoch 7/100\n",
      "3842/3842 [==============================] - 0s 69us/step - loss: 15.6021 - acc: 0.0021\n",
      "Epoch 8/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.5793 - acc: 0.0016\n",
      "Epoch 9/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.6060 - acc: 0.0016\n",
      "Epoch 10/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.6027 - acc: 0.0016\n",
      "Epoch 11/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.5915 - acc: 0.0010\n",
      "Epoch 12/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.6117 - acc: 0.0016\n",
      "Epoch 13/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.6286 - acc: 0.0013\n",
      "Epoch 14/100\n",
      "3842/3842 [==============================] - 0s 69us/step - loss: 15.6631 - acc: 0.0016\n",
      "Epoch 15/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.6123 - acc: 0.0018\n",
      "Epoch 16/100\n",
      "3842/3842 [==============================] - 0s 71us/step - loss: 15.5216 - acc: 0.0023\n",
      "Epoch 17/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.6063 - acc: 0.0013\n",
      "Epoch 18/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.5207 - acc: 0.0016\n",
      "Epoch 19/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.4885 - acc: 0.0016\n",
      "Epoch 20/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.4896 - acc: 0.0021\n",
      "Epoch 21/100\n",
      "3842/3842 [==============================] - 0s 67us/step - loss: 15.5891 - acc: 0.0021\n",
      "Epoch 22/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.5167 - acc: 0.0016\n",
      "Epoch 23/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.4734 - acc: 0.0018\n",
      "Epoch 24/100\n",
      "3842/3842 [==============================] - 0s 71us/step - loss: 15.6066 - acc: 0.0021\n",
      "Epoch 25/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.5311 - acc: 0.0026\n",
      "Epoch 26/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.5519 - acc: 0.0018\n",
      "Epoch 27/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.6132 - acc: 0.0013\n",
      "Epoch 28/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.5261 - acc: 0.0018\n",
      "Epoch 29/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.5832 - acc: 0.0016\n",
      "Epoch 30/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.5190 - acc: 0.0021\n",
      "Epoch 31/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.5503 - acc: 0.0013\n",
      "Epoch 32/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.5186 - acc: 0.0016\n",
      "Epoch 33/100\n",
      "3842/3842 [==============================] - 0s 77us/step - loss: 15.4899 - acc: 0.0016\n",
      "Epoch 34/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.5223 - acc: 0.0018\n",
      "Epoch 35/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.4891 - acc: 0.0018\n",
      "Epoch 36/100\n",
      "3842/3842 [==============================] - 0s 69us/step - loss: 15.5531 - acc: 0.0013\n",
      "Epoch 37/100\n",
      "3842/3842 [==============================] - 0s 77us/step - loss: 15.4569 - acc: 0.0018\n",
      "Epoch 38/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.5421 - acc: 0.0023\n",
      "Epoch 39/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.4873 - acc: 0.0021\n",
      "Epoch 40/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.5160 - acc: 0.0026\n",
      "Epoch 41/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.5742 - acc: 0.0018\n",
      "Epoch 42/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.5365 - acc: 0.0023\n",
      "Epoch 43/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.5159 - acc: 0.0013\n",
      "Epoch 44/100\n",
      "3842/3842 [==============================] - 0s 77us/step - loss: 15.5320 - acc: 0.0013\n",
      "Epoch 45/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.4900 - acc: 0.0018\n",
      "Epoch 46/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.4461 - acc: 0.0026\n",
      "Epoch 47/100\n",
      "3842/3842 [==============================] - 0s 77us/step - loss: 15.4627 - acc: 0.0018\n",
      "Epoch 48/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.5692 - acc: 0.0021\n",
      "Epoch 49/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.4570 - acc: 0.0016\n",
      "Epoch 50/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.4576 - acc: 0.0021\n",
      "Epoch 51/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.4706 - acc: 0.0018\n",
      "Epoch 52/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.4608 - acc: 0.0026\n",
      "Epoch 53/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.4099 - acc: 0.0016\n",
      "Epoch 54/100\n",
      "3842/3842 [==============================] - 0s 77us/step - loss: 15.5326 - acc: 0.0036\n",
      "Epoch 55/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.5367 - acc: 0.0023\n",
      "Epoch 56/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.4608 - acc: 0.0023\n",
      "Epoch 57/100\n",
      "3842/3842 [==============================] - 0s 78us/step - loss: 15.4410 - acc: 0.0021\n",
      "Epoch 58/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.4772 - acc: 0.0026\n",
      "Epoch 59/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.4589 - acc: 0.0016\n",
      "Epoch 60/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.5188 - acc: 0.0013\n",
      "Epoch 61/100\n",
      "3842/3842 [==============================] - 0s 79us/step - loss: 15.6035 - acc: 0.0018\n",
      "Epoch 62/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.4533 - acc: 0.0029\n",
      "Epoch 63/100\n",
      "3842/3842 [==============================] - 0s 77us/step - loss: 15.4879 - acc: 0.0018\n",
      "Epoch 64/100\n",
      "3842/3842 [==============================] - 0s 78us/step - loss: 15.4495 - acc: 7.8084e-04\n",
      "Epoch 65/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.4864 - acc: 0.0021\n",
      "Epoch 66/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.4810 - acc: 0.0029\n",
      "Epoch 67/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.4792 - acc: 0.0029\n",
      "Epoch 68/100\n",
      "3842/3842 [==============================] - 0s 78us/step - loss: 15.4631 - acc: 0.0023\n",
      "Epoch 69/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.6061 - acc: 0.0031\n",
      "Epoch 70/100\n",
      "3842/3842 [==============================] - 0s 75us/step - loss: 15.4367 - acc: 0.0018\n",
      "Epoch 71/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.4139 - acc: 0.0021\n",
      "Epoch 72/100\n",
      "3842/3842 [==============================] - 0s 78us/step - loss: 15.4694 - acc: 0.0031\n",
      "Epoch 73/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.4079 - acc: 0.0023\n",
      "Epoch 74/100\n",
      "3842/3842 [==============================] - 0s 78us/step - loss: 15.4323 - acc: 0.0023\n",
      "Epoch 75/100\n",
      "3842/3842 [==============================] - 0s 79us/step - loss: 15.4932 - acc: 0.0021\n",
      "Epoch 76/100\n",
      "3842/3842 [==============================] - 0s 79us/step - loss: 15.4281 - acc: 0.0031\n",
      "Epoch 77/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.4111 - acc: 0.0026\n",
      "Epoch 78/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.4305 - acc: 0.0021\n",
      "Epoch 79/100\n",
      "3842/3842 [==============================] - 0s 79us/step - loss: 15.4249 - acc: 0.0021\n",
      "Epoch 80/100\n",
      "3842/3842 [==============================] - 0s 77us/step - loss: 15.4500 - acc: 0.0018\n",
      "Epoch 81/100\n",
      "3842/3842 [==============================] - 0s 79us/step - loss: 15.4177 - acc: 0.0034\n",
      "Epoch 82/100\n",
      "3842/3842 [==============================] - 0s 76us/step - loss: 15.4673 - acc: 0.0023\n",
      "Epoch 83/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.4657 - acc: 0.0026\n",
      "Epoch 84/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.4062 - acc: 0.0021\n",
      "Epoch 85/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.4104 - acc: 0.0029\n",
      "Epoch 86/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.4030 - acc: 0.0018\n",
      "Epoch 87/100\n",
      "3842/3842 [==============================] - 0s 71us/step - loss: 15.4130 - acc: 0.0026\n",
      "Epoch 88/100\n",
      "3842/3842 [==============================] - 0s 69us/step - loss: 15.4758 - acc: 0.0026\n",
      "Epoch 89/100\n",
      "3842/3842 [==============================] - 0s 71us/step - loss: 15.4932 - acc: 0.0029\n",
      "Epoch 90/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.4867 - acc: 0.0018\n",
      "Epoch 91/100\n",
      "3842/3842 [==============================] - 0s 69us/step - loss: 15.3903 - acc: 0.0026\n",
      "Epoch 92/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.4569 - acc: 0.0023\n",
      "Epoch 93/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.4089 - acc: 0.0029\n",
      "Epoch 94/100\n",
      "3842/3842 [==============================] - 0s 74us/step - loss: 15.3904 - acc: 0.0016\n",
      "Epoch 95/100\n",
      "3842/3842 [==============================] - 0s 69us/step - loss: 15.3818 - acc: 0.0023\n",
      "Epoch 96/100\n",
      "3842/3842 [==============================] - 0s 73us/step - loss: 15.4321 - acc: 0.0021\n",
      "Epoch 97/100\n",
      "3842/3842 [==============================] - 0s 70us/step - loss: 15.3822 - acc: 0.0021\n",
      "Epoch 98/100\n",
      "3842/3842 [==============================] - 0s 77us/step - loss: 15.3325 - acc: 0.0034\n",
      "Epoch 99/100\n",
      "3842/3842 [==============================] - 0s 72us/step - loss: 15.4026 - acc: 0.0018\n",
      "Epoch 100/100\n",
      "3842/3842 [==============================] - 0s 68us/step - loss: 15.4158 - acc: 0.0023\n",
      "172/172 [==============================] - 0s 39us/step\n",
      "Epoch 1/100\n",
      "2090/4014 [==============>...............] - ETA: 0s - loss: 14.8748 - acc: 0.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.7270 - acc: 0.0017\n",
      "Epoch 2/100\n",
      "4014/4014 [==============================] - 0s 65us/step - loss: 15.6989 - acc: 0.0012\n",
      "Epoch 3/100\n",
      "4014/4014 [==============================] - 0s 69us/step - loss: 15.6325 - acc: 0.0017\n",
      "Epoch 4/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.6422 - acc: 0.0015\n",
      "Epoch 5/100\n",
      "4014/4014 [==============================] - 0s 69us/step - loss: 15.6927 - acc: 0.0025\n",
      "Epoch 6/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.5943 - acc: 0.0020\n",
      "Epoch 7/100\n",
      "4014/4014 [==============================] - 0s 67us/step - loss: 15.5203 - acc: 0.0015\n",
      "Epoch 8/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.5566 - acc: 0.0022\n",
      "Epoch 9/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.6451 - acc: 9.9651e-04\n",
      "Epoch 10/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.5885 - acc: 0.0020\n",
      "Epoch 11/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.5282 - acc: 0.0012\n",
      "Epoch 12/100\n",
      "4014/4014 [==============================] - 0s 70us/step - loss: 15.5695 - acc: 0.0022\n",
      "Epoch 13/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.6041 - acc: 0.0012\n",
      "Epoch 14/100\n",
      "4014/4014 [==============================] - 0s 70us/step - loss: 15.5369 - acc: 0.0015\n",
      "Epoch 15/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.5012 - acc: 0.0012\n",
      "Epoch 16/100\n",
      "4014/4014 [==============================] - 0s 70us/step - loss: 15.5205 - acc: 0.0017\n",
      "Epoch 17/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.5629 - acc: 0.0022\n",
      "Epoch 18/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.5909 - acc: 0.0027\n",
      "Epoch 19/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.5289 - acc: 0.0015\n",
      "Epoch 20/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.5286 - acc: 0.0015\n",
      "Epoch 21/100\n",
      "4014/4014 [==============================] - 0s 70us/step - loss: 15.4869 - acc: 0.0017\n",
      "Epoch 22/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.5465 - acc: 0.0015\n",
      "Epoch 23/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.5556 - acc: 0.0015\n",
      "Epoch 24/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.4975 - acc: 0.0020\n",
      "Epoch 25/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.5079 - acc: 0.0020\n",
      "Epoch 26/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.4491 - acc: 0.0022\n",
      "Epoch 27/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.5362 - acc: 0.0022\n",
      "Epoch 28/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.5118 - acc: 0.0012\n",
      "Epoch 29/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4786 - acc: 0.0035\n",
      "Epoch 30/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.5524 - acc: 0.0022\n",
      "Epoch 31/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.5053 - acc: 0.0017\n",
      "Epoch 32/100\n",
      "4014/4014 [==============================] - 0s 76us/step - loss: 15.5412 - acc: 0.0017\n",
      "Epoch 33/100\n",
      "4014/4014 [==============================] - 0s 70us/step - loss: 15.4577 - acc: 0.0022\n",
      "Epoch 34/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.4239 - acc: 0.0020\n",
      "Epoch 35/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.5142 - acc: 0.0020\n",
      "Epoch 36/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.5093 - acc: 0.0017\n",
      "Epoch 37/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.4857 - acc: 0.0022\n",
      "Epoch 38/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.4954 - acc: 0.0012\n",
      "Epoch 39/100\n",
      "4014/4014 [==============================] - 0s 77us/step - loss: 15.4800 - acc: 0.0012\n",
      "Epoch 40/100\n",
      "4014/4014 [==============================] - 0s 79us/step - loss: 15.4897 - acc: 0.0012\n",
      "Epoch 41/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.4647 - acc: 0.0030\n",
      "Epoch 42/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.4575 - acc: 0.0022\n",
      "Epoch 43/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4794 - acc: 0.0017\n",
      "Epoch 44/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.4270 - acc: 0.0020\n",
      "Epoch 45/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.5092 - acc: 0.0035\n",
      "Epoch 46/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.4885 - acc: 0.0020\n",
      "Epoch 47/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.5038 - acc: 0.0025\n",
      "Epoch 48/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.5103 - acc: 0.0015\n",
      "Epoch 49/100\n",
      "4014/4014 [==============================] - 0s 78us/step - loss: 15.4508 - acc: 0.0017\n",
      "Epoch 50/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4462 - acc: 0.0020\n",
      "Epoch 51/100\n",
      "4014/4014 [==============================] - 0s 76us/step - loss: 15.4214 - acc: 0.0022\n",
      "Epoch 52/100\n",
      "4014/4014 [==============================] - 0s 77us/step - loss: 15.4519 - acc: 0.0025\n",
      "Epoch 53/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.4441 - acc: 0.0020\n",
      "Epoch 54/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.4047 - acc: 0.0020\n",
      "Epoch 55/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.4162 - acc: 0.0017\n",
      "Epoch 56/100\n",
      "4014/4014 [==============================] - 0s 77us/step - loss: 15.4324 - acc: 0.0017\n",
      "Epoch 57/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.4678 - acc: 0.0025\n",
      "Epoch 58/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.4207 - acc: 0.0015\n",
      "Epoch 59/100\n",
      "4014/4014 [==============================] - 0s 77us/step - loss: 15.4413 - acc: 0.0017\n",
      "Epoch 60/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.4416 - acc: 0.0025\n",
      "Epoch 61/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4244 - acc: 0.0022\n",
      "Epoch 62/100\n",
      "4014/4014 [==============================] - 0s 78us/step - loss: 15.4582 - acc: 0.0020\n",
      "Epoch 63/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.3882 - acc: 0.0022 0s - loss: 15.7104 - acc: 0.\n",
      "Epoch 64/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.4571 - acc: 0.0020\n",
      "Epoch 65/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.5028 - acc: 0.0020\n",
      "Epoch 66/100\n",
      "4014/4014 [==============================] - 0s 81us/step - loss: 15.4173 - acc: 0.0015\n",
      "Epoch 67/100\n",
      "4014/4014 [==============================] - 0s 78us/step - loss: 15.4618 - acc: 0.0020\n",
      "Epoch 68/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4498 - acc: 0.0020\n",
      "Epoch 69/100\n",
      "4014/4014 [==============================] - 0s 80us/step - loss: 15.4736 - acc: 0.0022\n",
      "Epoch 70/100\n",
      "4014/4014 [==============================] - 0s 76us/step - loss: 15.4354 - acc: 0.0022\n",
      "Epoch 71/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.3987 - acc: 0.0027\n",
      "Epoch 72/100\n",
      "4014/4014 [==============================] - 0s 77us/step - loss: 15.4344 - acc: 0.0020\n",
      "Epoch 73/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.5092 - acc: 0.0025\n",
      "Epoch 74/100\n",
      "4014/4014 [==============================] - 0s 76us/step - loss: 15.4564 - acc: 0.0022\n",
      "Epoch 75/100\n",
      "4014/4014 [==============================] - 0s 75us/step - loss: 15.3904 - acc: 0.0017\n",
      "Epoch 76/100\n",
      "4014/4014 [==============================] - 0s 77us/step - loss: 15.3658 - acc: 0.0025\n",
      "Epoch 77/100\n",
      "4014/4014 [==============================] - 0s 77us/step - loss: 15.4996 - acc: 0.0022\n",
      "Epoch 78/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.3976 - acc: 0.0022\n",
      "Epoch 79/100\n",
      "4014/4014 [==============================] - 0s 76us/step - loss: 15.3965 - acc: 0.0017\n",
      "Epoch 80/100\n",
      "4014/4014 [==============================] - 0s 76us/step - loss: 15.4092 - acc: 0.0022\n",
      "Epoch 81/100\n",
      "4014/4014 [==============================] - 0s 76us/step - loss: 15.4149 - acc: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.4314 - acc: 0.0017\n",
      "Epoch 83/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.3948 - acc: 0.0017\n",
      "Epoch 84/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.3674 - acc: 0.0020\n",
      "Epoch 85/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4063 - acc: 0.0012\n",
      "Epoch 86/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.4462 - acc: 0.0025\n",
      "Epoch 87/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.4047 - acc: 0.0027\n",
      "Epoch 88/100\n",
      "4014/4014 [==============================] - 0s 69us/step - loss: 15.3299 - acc: 0.0022\n",
      "Epoch 89/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.4440 - acc: 0.0025\n",
      "Epoch 90/100\n",
      "4014/4014 [==============================] - 0s 70us/step - loss: 15.4161 - acc: 0.0017\n",
      "Epoch 91/100\n",
      "4014/4014 [==============================] - 0s 69us/step - loss: 15.3883 - acc: 0.0015\n",
      "Epoch 92/100\n",
      "4014/4014 [==============================] - 0s 71us/step - loss: 15.3992 - acc: 0.0027\n",
      "Epoch 93/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.3989 - acc: 9.9651e-04\n",
      "Epoch 94/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.4228 - acc: 0.0025\n",
      "Epoch 95/100\n",
      "4014/4014 [==============================] - 0s 69us/step - loss: 15.3882 - acc: 0.0015\n",
      "Epoch 96/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4242 - acc: 0.0020\n",
      "Epoch 97/100\n",
      "4014/4014 [==============================] - 0s 74us/step - loss: 15.3828 - acc: 0.0017\n",
      "Epoch 98/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4383 - acc: 0.0022\n",
      "Epoch 99/100\n",
      "4014/4014 [==============================] - 0s 72us/step - loss: 15.4867 - acc: 0.0017\n",
      "Epoch 100/100\n",
      "4014/4014 [==============================] - 0s 73us/step - loss: 15.4716 - acc: 0.0027\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2040/4186 [=============>................] - ETA: 0s - loss: 15.4574 - acc: 4.9020e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.6136 - acc: 0.0017\n",
      "Epoch 2/100\n",
      "4186/4186 [==============================] - 0s 70us/step - loss: 15.6608 - acc: 0.0017\n",
      "Epoch 3/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.5670 - acc: 0.0022\n",
      "Epoch 4/100\n",
      "4186/4186 [==============================] - 0s 69us/step - loss: 15.5305 - acc: 0.0022\n",
      "Epoch 5/100\n",
      "4186/4186 [==============================] - 0s 70us/step - loss: 15.5511 - acc: 0.0019\n",
      "Epoch 6/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.5165 - acc: 0.0014\n",
      "Epoch 7/100\n",
      "4186/4186 [==============================] - 0s 70us/step - loss: 15.5547 - acc: 0.0026\n",
      "Epoch 8/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.5524 - acc: 0.0029 0s - loss: 15.9598 - acc: 0.\n",
      "Epoch 9/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.5822 - acc: 0.0014\n",
      "Epoch 10/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.5757 - acc: 7.1667e-04\n",
      "Epoch 11/100\n",
      "4186/4186 [==============================] - 0s 74us/step - loss: 15.5295 - acc: 0.0017\n",
      "Epoch 12/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.5584 - acc: 0.0024\n",
      "Epoch 13/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.5164 - acc: 0.0014\n",
      "Epoch 14/100\n",
      "4186/4186 [==============================] - 0s 75us/step - loss: 15.5105 - acc: 0.0014\n",
      "Epoch 15/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.4837 - acc: 0.0014\n",
      "Epoch 16/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4611 - acc: 0.0012\n",
      "Epoch 17/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.5021 - acc: 0.0019\n",
      "Epoch 18/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.5364 - acc: 0.0019\n",
      "Epoch 19/100\n",
      "4186/4186 [==============================] - 0s 74us/step - loss: 15.4890 - acc: 0.0019\n",
      "Epoch 20/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.5671 - acc: 0.0029\n",
      "Epoch 21/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.4751 - acc: 0.0024\n",
      "Epoch 22/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.4986 - acc: 0.0017\n",
      "Epoch 23/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.5630 - acc: 0.0019\n",
      "Epoch 24/100\n",
      "4186/4186 [==============================] - 0s 74us/step - loss: 15.5374 - acc: 0.0012\n",
      "Epoch 25/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4487 - acc: 0.0022\n",
      "Epoch 26/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4640 - acc: 0.0022\n",
      "Epoch 27/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.5452 - acc: 0.0019\n",
      "Epoch 28/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.4378 - acc: 0.0012\n",
      "Epoch 29/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.4301 - acc: 0.0019\n",
      "Epoch 30/100\n",
      "4186/4186 [==============================] - 0s 86us/step - loss: 15.4573 - acc: 0.0017\n",
      "Epoch 31/100\n",
      "4186/4186 [==============================] - 0s 107us/step - loss: 15.4892 - acc: 0.0022\n",
      "Epoch 32/100\n",
      "4186/4186 [==============================] - 0s 97us/step - loss: 15.4521 - acc: 0.0014\n",
      "Epoch 33/100\n",
      "4186/4186 [==============================] - 0s 80us/step - loss: 15.4893 - acc: 0.0022\n",
      "Epoch 34/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.4946 - acc: 0.0026\n",
      "Epoch 35/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.4792 - acc: 0.0019\n",
      "Epoch 36/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.4533 - acc: 0.0014\n",
      "Epoch 37/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4584 - acc: 0.0012\n",
      "Epoch 38/100\n",
      "4186/4186 [==============================] - 0s 75us/step - loss: 15.4797 - acc: 0.0022\n",
      "Epoch 39/100\n",
      "4186/4186 [==============================] - 0s 79us/step - loss: 15.4256 - acc: 0.0017\n",
      "Epoch 40/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.4676 - acc: 0.0014\n",
      "Epoch 41/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.4324 - acc: 0.0017\n",
      "Epoch 42/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.4129 - acc: 0.0019\n",
      "Epoch 43/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.4792 - acc: 0.0014\n",
      "Epoch 44/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.5064 - acc: 0.0017\n",
      "Epoch 45/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.4494 - acc: 0.0019\n",
      "Epoch 46/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.4673 - acc: 0.0012\n",
      "Epoch 47/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4777 - acc: 0.0019\n",
      "Epoch 48/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.4299 - acc: 0.0022\n",
      "Epoch 49/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.4538 - acc: 0.0029\n",
      "Epoch 50/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4162 - acc: 0.0012\n",
      "Epoch 51/100\n",
      "4186/4186 [==============================] - 0s 74us/step - loss: 15.4264 - acc: 0.0017\n",
      "Epoch 52/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.4573 - acc: 0.0017\n",
      "Epoch 53/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.4227 - acc: 0.0026\n",
      "Epoch 54/100\n",
      "4186/4186 [==============================] - 0s 75us/step - loss: 15.4450 - acc: 0.0014\n",
      "Epoch 55/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.5821 - acc: 0.0022\n",
      "Epoch 56/100\n",
      "4186/4186 [==============================] - 0s 74us/step - loss: 15.4747 - acc: 0.0022\n",
      "Epoch 57/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.4966 - acc: 0.0026\n",
      "Epoch 58/100\n",
      "4186/4186 [==============================] - 0s 75us/step - loss: 15.4550 - acc: 0.0022\n",
      "Epoch 59/100\n",
      "4186/4186 [==============================] - 0s 74us/step - loss: 15.4067 - acc: 0.0014\n",
      "Epoch 60/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.4197 - acc: 0.0022\n",
      "Epoch 61/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.4251 - acc: 0.0022\n",
      "Epoch 62/100\n",
      "4186/4186 [==============================] - 0s 89us/step - loss: 15.4124 - acc: 0.0012\n",
      "Epoch 63/100\n",
      "4186/4186 [==============================] - 0s 78us/step - loss: 15.4647 - acc: 0.0019\n",
      "Epoch 64/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.4381 - acc: 0.0014\n",
      "Epoch 65/100\n",
      "4186/4186 [==============================] - 0s 78us/step - loss: 15.3936 - acc: 0.0026\n",
      "Epoch 66/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.4512 - acc: 0.0019\n",
      "Epoch 67/100\n",
      "4186/4186 [==============================] - 0s 75us/step - loss: 15.3933 - acc: 0.0022\n",
      "Epoch 68/100\n",
      "4186/4186 [==============================] - 0s 79us/step - loss: 15.4070 - acc: 0.0019\n",
      "Epoch 69/100\n",
      "4186/4186 [==============================] - 0s 75us/step - loss: 15.4311 - acc: 0.0019\n",
      "Epoch 70/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.3916 - acc: 0.0014\n",
      "Epoch 71/100\n",
      "4186/4186 [==============================] - 0s 80us/step - loss: 15.4742 - acc: 0.0019\n",
      "Epoch 72/100\n",
      "4186/4186 [==============================] - 0s 74us/step - loss: 15.4171 - acc: 9.5557e-04\n",
      "Epoch 73/100\n",
      "4186/4186 [==============================] - 0s 78us/step - loss: 15.3936 - acc: 0.0022\n",
      "Epoch 74/100\n",
      "4186/4186 [==============================] - 0s 78us/step - loss: 15.3929 - acc: 0.0017\n",
      "Epoch 75/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.4366 - acc: 0.0022\n",
      "Epoch 76/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.3745 - acc: 0.0014\n",
      "Epoch 77/100\n",
      "4186/4186 [==============================] - 0s 78us/step - loss: 15.4164 - acc: 0.0014\n",
      "Epoch 78/100\n",
      "4186/4186 [==============================] - 0s 77us/step - loss: 15.3811 - acc: 0.0019\n",
      "Epoch 79/100\n",
      "4186/4186 [==============================] - 0s 81us/step - loss: 15.3952 - acc: 0.0017\n",
      "Epoch 80/100\n",
      "4186/4186 [==============================] - 0s 79us/step - loss: 15.4013 - acc: 0.0014\n",
      "Epoch 81/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.3228 - acc: 2.3889e-04\n",
      "Epoch 82/100\n",
      "4186/4186 [==============================] - 0s 74us/step - loss: 15.3880 - acc: 0.0019\n",
      "Epoch 83/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.3978 - acc: 0.0017\n",
      "Epoch 84/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.4088 - acc: 0.0019\n",
      "Epoch 85/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4347 - acc: 0.0019\n",
      "Epoch 86/100\n",
      "4186/4186 [==============================] - 0s 70us/step - loss: 15.4177 - acc: 0.0014\n",
      "Epoch 87/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4381 - acc: 0.0022\n",
      "Epoch 88/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.4615 - acc: 0.0014\n",
      "Epoch 89/100\n",
      "4186/4186 [==============================] - 0s 69us/step - loss: 15.4411 - acc: 0.0024\n",
      "Epoch 90/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4220 - acc: 0.0017\n",
      "Epoch 91/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.3826 - acc: 0.0022\n",
      "Epoch 92/100\n",
      "4186/4186 [==============================] - 0s 72us/step - loss: 15.4609 - acc: 9.5557e-04\n",
      "Epoch 93/100\n",
      "4186/4186 [==============================] - 0s 70us/step - loss: 15.4147 - acc: 0.0017\n",
      "Epoch 94/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.3809 - acc: 0.0024\n",
      "Epoch 95/100\n",
      "4186/4186 [==============================] - 0s 76us/step - loss: 15.3632 - acc: 0.0019\n",
      "Epoch 96/100\n",
      "4186/4186 [==============================] - 0s 71us/step - loss: 15.4094 - acc: 0.0012\n",
      "Epoch 97/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.3353 - acc: 0.0019\n",
      "Epoch 98/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.3814 - acc: 0.0019\n",
      "Epoch 99/100\n",
      "4186/4186 [==============================] - 0s 69us/step - loss: 15.3741 - acc: 0.0019\n",
      "Epoch 100/100\n",
      "4186/4186 [==============================] - 0s 73us/step - loss: 15.3972 - acc: 0.0024\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2250/4358 [==============>...............] - ETA: 0s - loss: 15.0640 - acc: 4.4444e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3836 - acc: 0.0018\n",
      "Epoch 2/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.3979 - acc: 0.0023\n",
      "Epoch 3/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.3463 - acc: 0.0025\n",
      "Epoch 4/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.3313 - acc: 0.0018\n",
      "Epoch 5/100\n",
      "4358/4358 [==============================] - 0s 69us/step - loss: 15.3819 - acc: 0.0023\n",
      "Epoch 6/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.2948 - acc: 9.1785e-04\n",
      "Epoch 7/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.4440 - acc: 0.0021\n",
      "Epoch 8/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.3805 - acc: 0.0025\n",
      "Epoch 9/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.3913 - acc: 9.1785e-04\n",
      "Epoch 10/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.3241 - acc: 0.0014\n",
      "Epoch 11/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3725 - acc: 0.0025\n",
      "Epoch 12/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.3418 - acc: 0.0018\n",
      "Epoch 13/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.2955 - acc: 0.0018\n",
      "Epoch 14/100\n",
      "4358/4358 [==============================] - 0s 73us/step - loss: 15.3951 - acc: 0.0018\n",
      "Epoch 15/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.3051 - acc: 0.0018\n",
      "Epoch 16/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3253 - acc: 0.0025\n",
      "Epoch 17/100\n",
      "4358/4358 [==============================] - 0s 73us/step - loss: 15.3325 - acc: 0.0016\n",
      "Epoch 18/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.2908 - acc: 0.0018\n",
      "Epoch 19/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3332 - acc: 9.1785e-04\n",
      "Epoch 20/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.4429 - acc: 0.0018\n",
      "Epoch 21/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.2553 - acc: 0.0014\n",
      "Epoch 22/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.3292 - acc: 0.0018\n",
      "Epoch 23/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3317 - acc: 0.0023\n",
      "Epoch 24/100\n",
      "4358/4358 [==============================] - 0s 73us/step - loss: 15.2437 - acc: 0.0014\n",
      "Epoch 25/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3625 - acc: 0.0021\n",
      "Epoch 26/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.4108 - acc: 0.0021\n",
      "Epoch 27/100\n",
      "4358/4358 [==============================] - 0s 79us/step - loss: 15.2618 - acc: 0.0014\n",
      "Epoch 28/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3665 - acc: 0.0021\n",
      "Epoch 29/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.3028 - acc: 0.0016\n",
      "Epoch 30/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.3879 - acc: 0.0016\n",
      "Epoch 31/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.2660 - acc: 9.1785e-04\n",
      "Epoch 32/100\n",
      "4358/4358 [==============================] - 0s 85us/step - loss: 15.3029 - acc: 0.0021\n",
      "Epoch 33/100\n",
      "4358/4358 [==============================] - 0s 77us/step - loss: 15.3700 - acc: 0.0016\n",
      "Epoch 34/100\n",
      "4358/4358 [==============================] - 0s 73us/step - loss: 15.3127 - acc: 0.0018\n",
      "Epoch 35/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.3366 - acc: 0.0018\n",
      "Epoch 36/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3210 - acc: 0.0011\n",
      "Epoch 37/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.3306 - acc: 0.0025\n",
      "Epoch 38/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3638 - acc: 0.0021\n",
      "Epoch 39/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3803 - acc: 0.0021\n",
      "Epoch 40/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.2733 - acc: 6.8839e-04\n",
      "Epoch 41/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.2938 - acc: 0.0018\n",
      "Epoch 42/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3135 - acc: 0.0021\n",
      "Epoch 43/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3407 - acc: 0.0018\n",
      "Epoch 44/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3326 - acc: 0.0011\n",
      "Epoch 45/100\n",
      "4358/4358 [==============================] - 0s 83us/step - loss: 15.3383 - acc: 0.0018\n",
      "Epoch 46/100\n",
      "4358/4358 [==============================] - 0s 77us/step - loss: 15.3257 - acc: 0.0016\n",
      "Epoch 47/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3475 - acc: 0.0018\n",
      "Epoch 48/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.2583 - acc: 0.0021\n",
      "Epoch 49/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.3316 - acc: 0.0023\n",
      "Epoch 50/100\n",
      "4358/4358 [==============================] - 0s 73us/step - loss: 15.2991 - acc: 0.0018\n",
      "Epoch 51/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.3061 - acc: 6.8839e-04\n",
      "Epoch 52/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.2661 - acc: 0.0018\n",
      "Epoch 53/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3252 - acc: 0.0016\n",
      "Epoch 54/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.3154 - acc: 0.0025\n",
      "Epoch 55/100\n",
      "4358/4358 [==============================] - 0s 78us/step - loss: 15.3221 - acc: 0.0014\n",
      "Epoch 56/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.2711 - acc: 0.0016\n",
      "Epoch 57/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3030 - acc: 0.0016\n",
      "Epoch 58/100\n",
      "4358/4358 [==============================] - 0s 78us/step - loss: 15.3075 - acc: 0.0014\n",
      "Epoch 59/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3279 - acc: 0.0014\n",
      "Epoch 60/100\n",
      "4358/4358 [==============================] - 0s 79us/step - loss: 15.3238 - acc: 0.0023\n",
      "Epoch 61/100\n",
      "4358/4358 [==============================] - 0s 77us/step - loss: 15.2891 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.3442 - acc: 0.0023\n",
      "Epoch 63/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3124 - acc: 0.0018\n",
      "Epoch 64/100\n",
      "4358/4358 [==============================] - 0s 78us/step - loss: 15.3381 - acc: 0.0016\n",
      "Epoch 65/100\n",
      "4358/4358 [==============================] - 0s 76us/step - loss: 15.2471 - acc: 0.0018\n",
      "Epoch 66/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3097 - acc: 0.0023\n",
      "Epoch 67/100\n",
      "4358/4358 [==============================] - 0s 77us/step - loss: 15.2939 - acc: 0.0011\n",
      "Epoch 68/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.3789 - acc: 0.0014\n",
      "Epoch 69/100\n",
      "4358/4358 [==============================] - 0s 76us/step - loss: 15.3542 - acc: 0.0016\n",
      "Epoch 70/100\n",
      "4358/4358 [==============================] - 0s 81us/step - loss: 15.3268 - acc: 0.0018\n",
      "Epoch 71/100\n",
      "4358/4358 [==============================] - 0s 76us/step - loss: 15.3141 - acc: 9.1785e-04\n",
      "Epoch 72/100\n",
      "4358/4358 [==============================] - 0s 76us/step - loss: 15.2899 - acc: 0.0016\n",
      "Epoch 73/100\n",
      "4358/4358 [==============================] - 0s 78us/step - loss: 15.3445 - acc: 0.0018\n",
      "Epoch 74/100\n",
      "4358/4358 [==============================] - 0s 76us/step - loss: 15.2669 - acc: 9.1785e-04\n",
      "Epoch 75/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.2604 - acc: 0.0011\n",
      "Epoch 76/100\n",
      "4358/4358 [==============================] - 0s 79us/step - loss: 15.2771 - acc: 0.0018\n",
      "Epoch 77/100\n",
      "4358/4358 [==============================] - 0s 78us/step - loss: 15.3159 - acc: 0.0016\n",
      "Epoch 78/100\n",
      "4358/4358 [==============================] - 0s 74us/step - loss: 15.3174 - acc: 0.0025\n",
      "Epoch 79/100\n",
      "4358/4358 [==============================] - 0s 79us/step - loss: 15.2884 - acc: 0.0021\n",
      "Epoch 80/100\n",
      "4358/4358 [==============================] - 0s 78us/step - loss: 15.3450 - acc: 0.0018\n",
      "Epoch 81/100\n",
      "4358/4358 [==============================] - 0s 75us/step - loss: 15.2846 - acc: 0.0021\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4358/4358 [==============================] - 0s 76us/step - loss: 15.3541 - acc: 0.0014\n",
      "Epoch 83/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.2184 - acc: 0.0016\n",
      "Epoch 84/100\n",
      "4358/4358 [==============================] - 0s 69us/step - loss: 15.2939 - acc: 0.0016\n",
      "Epoch 85/100\n",
      "4358/4358 [==============================] - 0s 73us/step - loss: 15.3327 - acc: 0.0018\n",
      "Epoch 86/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.3118 - acc: 0.0016\n",
      "Epoch 87/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.2611 - acc: 9.1785e-04\n",
      "Epoch 88/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.3769 - acc: 0.0014\n",
      "Epoch 89/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.3030 - acc: 0.0023\n",
      "Epoch 90/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.3084 - acc: 0.0014\n",
      "Epoch 91/100\n",
      "4358/4358 [==============================] - 0s 71us/step - loss: 15.2564 - acc: 0.0016\n",
      "Epoch 92/100\n",
      "4358/4358 [==============================] - 0s 73us/step - loss: 15.2818 - acc: 0.0016\n",
      "Epoch 93/100\n",
      "4358/4358 [==============================] - 0s 70us/step - loss: 15.3155 - acc: 0.0025\n",
      "Epoch 94/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.2862 - acc: 0.0025\n",
      "Epoch 95/100\n",
      "4358/4358 [==============================] - 0s 78us/step - loss: 15.3579 - acc: 0.0014\n",
      "Epoch 96/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3432 - acc: 0.0011\n",
      "Epoch 97/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3500 - acc: 0.0014\n",
      "Epoch 98/100\n",
      "4358/4358 [==============================] - 0s 72us/step - loss: 15.3296 - acc: 0.0018\n",
      "Epoch 99/100\n",
      "4358/4358 [==============================] - 0s 73us/step - loss: 15.3832 - acc: 0.0021\n",
      "Epoch 100/100\n",
      "4358/4358 [==============================] - 0s 69us/step - loss: 15.2731 - acc: 0.0021\n",
      "172/172 [==============================] - 0s 41us/step\n",
      "Epoch 1/100\n",
      "2840/4530 [=================>............] - ETA: 0s - loss: 15.4739 - acc: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4530/4530 [==============================] - 0s 75us/step - loss: 15.3564 - acc: 0.0013\n",
      "Epoch 2/100\n",
      "4530/4530 [==============================] - 0s 73us/step - loss: 15.3372 - acc: 0.0013\n",
      "Epoch 3/100\n",
      "4530/4530 [==============================] - 0s 70us/step - loss: 15.3549 - acc: 0.0020\n",
      "Epoch 4/100\n",
      "4530/4530 [==============================] - 0s 69us/step - loss: 15.3271 - acc: 0.0015\n",
      "Epoch 5/100\n",
      "4530/4530 [==============================] - 0s 71us/step - loss: 15.3122 - acc: 0.0020\n",
      "Epoch 6/100\n",
      "4530/4530 [==============================] - 0s 69us/step - loss: 15.3528 - acc: 0.0018\n",
      "Epoch 7/100\n",
      "4530/4530 [==============================] - 0s 70us/step - loss: 15.3364 - acc: 0.0013\n",
      "Epoch 8/100\n",
      "4530/4530 [==============================] - 0s 73us/step - loss: 15.3546 - acc: 0.0013\n",
      "Epoch 9/100\n",
      "4530/4530 [==============================] - 0s 75us/step - loss: 15.3229 - acc: 0.0011\n",
      "Epoch 10/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.3341 - acc: 0.0018\n",
      "Epoch 11/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.4134 - acc: 0.0024\n",
      "Epoch 12/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.2898 - acc: 0.0018\n",
      "Epoch 13/100\n",
      "4530/4530 [==============================] - 0s 73us/step - loss: 15.3113 - acc: 0.0015\n",
      "Epoch 14/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.2752 - acc: 0.0020\n",
      "Epoch 15/100\n",
      "4530/4530 [==============================] - 0s 74us/step - loss: 15.3372 - acc: 0.0026\n",
      "Epoch 16/100\n",
      "4530/4530 [==============================] - 0s 75us/step - loss: 15.3374 - acc: 0.0013\n",
      "Epoch 17/100\n",
      "4530/4530 [==============================] - 0s 80us/step - loss: 15.3839 - acc: 0.0015\n",
      "Epoch 18/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3287 - acc: 0.0020\n",
      "Epoch 19/100\n",
      "4530/4530 [==============================] - 0s 80us/step - loss: 15.3798 - acc: 0.0020\n",
      "Epoch 20/100\n",
      "4530/4530 [==============================] - 0s 82us/step - loss: 15.2706 - acc: 0.0018\n",
      "Epoch 21/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3874 - acc: 0.0022\n",
      "Epoch 22/100\n",
      "4530/4530 [==============================] - 0s 79us/step - loss: 15.4066 - acc: 0.0022\n",
      "Epoch 23/100\n",
      "4530/4530 [==============================] - 0s 104us/step - loss: 15.3055 - acc: 0.0020\n",
      "Epoch 24/100\n",
      "4530/4530 [==============================] - 0s 89us/step - loss: 15.3074 - acc: 0.0015\n",
      "Epoch 25/100\n",
      "4530/4530 [==============================] - 0s 81us/step - loss: 15.3154 - acc: 0.0020\n",
      "Epoch 26/100\n",
      "4530/4530 [==============================] - 0s 74us/step - loss: 15.3658 - acc: 0.0020\n",
      "Epoch 27/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.3432 - acc: 0.0015\n",
      "Epoch 28/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.2957 - acc: 0.0020\n",
      "Epoch 29/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.3152 - acc: 0.0022\n",
      "Epoch 30/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3252 - acc: 0.0018\n",
      "Epoch 31/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.3224 - acc: 0.0020\n",
      "Epoch 32/100\n",
      "4530/4530 [==============================] - 0s 75us/step - loss: 15.3801 - acc: 0.0020\n",
      "Epoch 33/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.2980 - acc: 0.0013\n",
      "Epoch 34/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.3295 - acc: 0.0018\n",
      "Epoch 35/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.3110 - acc: 0.0018\n",
      "Epoch 36/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.2759 - acc: 0.0020\n",
      "Epoch 37/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.4113 - acc: 0.0020\n",
      "Epoch 38/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.3826 - acc: 0.0022\n",
      "Epoch 39/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3126 - acc: 0.0015\n",
      "Epoch 40/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3371 - acc: 0.0015\n",
      "Epoch 41/100\n",
      "4530/4530 [==============================] - 0s 74us/step - loss: 15.3277 - acc: 0.0011\n",
      "Epoch 42/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.2923 - acc: 0.0024\n",
      "Epoch 43/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.3734 - acc: 0.0015\n",
      "Epoch 44/100\n",
      "4530/4530 [==============================] - 0s 74us/step - loss: 15.3292 - acc: 0.0020\n",
      "Epoch 45/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.2866 - acc: 0.0020\n",
      "Epoch 46/100\n",
      "4530/4530 [==============================] - 0s 81us/step - loss: 15.3017 - acc: 0.0022\n",
      "Epoch 47/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3881 - acc: 0.0022\n",
      "Epoch 48/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.3325 - acc: 0.0022\n",
      "Epoch 49/100\n",
      "4530/4530 [==============================] - 0s 80us/step - loss: 15.3128 - acc: 0.0011\n",
      "Epoch 50/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.3175 - acc: 0.0020\n",
      "Epoch 51/100\n",
      "4530/4530 [==============================] - 0s 81us/step - loss: 15.4027 - acc: 0.0011\n",
      "Epoch 52/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.2893 - acc: 0.0018\n",
      "Epoch 53/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.4037 - acc: 0.0013\n",
      "Epoch 54/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3183 - acc: 8.8300e-04\n",
      "Epoch 55/100\n",
      "4530/4530 [==============================] - 0s 80us/step - loss: 15.3613 - acc: 0.0011\n",
      "Epoch 56/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3393 - acc: 0.0022\n",
      "Epoch 57/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.2799 - acc: 0.0022\n",
      "Epoch 58/100\n",
      "4530/4530 [==============================] - 0s 79us/step - loss: 15.3360 - acc: 0.0020\n",
      "Epoch 59/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.2811 - acc: 0.0015\n",
      "Epoch 60/100\n",
      "4530/4530 [==============================] - 0s 81us/step - loss: 15.3049 - acc: 0.0022\n",
      "Epoch 61/100\n",
      "4530/4530 [==============================] - 0s 78us/step - loss: 15.3184 - acc: 0.0020\n",
      "Epoch 62/100\n",
      "4530/4530 [==============================] - 0s 80us/step - loss: 15.2660 - acc: 0.0015\n",
      "Epoch 63/100\n",
      "4530/4530 [==============================] - 0s 81us/step - loss: 15.3064 - acc: 0.0026\n",
      "Epoch 64/100\n",
      "4530/4530 [==============================] - 0s 79us/step - loss: 15.3539 - acc: 0.0013\n",
      "Epoch 65/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.3251 - acc: 0.0015\n",
      "Epoch 66/100\n",
      "4530/4530 [==============================] - 0s 84us/step - loss: 15.3092 - acc: 0.0015\n",
      "Epoch 67/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3122 - acc: 0.0020\n",
      "Epoch 68/100\n",
      "4530/4530 [==============================] - 0s 82us/step - loss: 15.3512 - acc: 0.0015\n",
      "Epoch 69/100\n",
      "4530/4530 [==============================] - 0s 80us/step - loss: 15.2796 - acc: 0.0018\n",
      "Epoch 70/100\n",
      "4530/4530 [==============================] - 0s 79us/step - loss: 15.3826 - acc: 0.0018 0s - loss: 15.3982 - acc: \n",
      "Epoch 71/100\n",
      "4530/4530 [==============================] - 0s 81us/step - loss: 15.3187 - acc: 0.0015\n",
      "Epoch 72/100\n",
      "4530/4530 [==============================] - 0s 79us/step - loss: 15.2915 - acc: 0.0020\n",
      "Epoch 73/100\n",
      "4530/4530 [==============================] - 0s 85us/step - loss: 15.3259 - acc: 8.8300e-04\n",
      "Epoch 74/100\n",
      "4530/4530 [==============================] - 0s 82us/step - loss: 15.3303 - acc: 0.0013\n",
      "Epoch 75/100\n",
      "4530/4530 [==============================] - 0s 84us/step - loss: 15.2624 - acc: 0.0020\n",
      "Epoch 76/100\n",
      "4530/4530 [==============================] - 0s 81us/step - loss: 15.2561 - acc: 0.0011\n",
      "Epoch 77/100\n",
      "4530/4530 [==============================] - 0s 82us/step - loss: 15.4167 - acc: 0.0018\n",
      "Epoch 78/100\n",
      "4530/4530 [==============================] - 0s 79us/step - loss: 15.2719 - acc: 0.0026\n",
      "Epoch 79/100\n",
      "4530/4530 [==============================] - 0s 84us/step - loss: 15.3553 - acc: 0.0018\n",
      "Epoch 80/100\n",
      "4530/4530 [==============================] - 0s 81us/step - loss: 15.3257 - acc: 0.0015\n",
      "Epoch 81/100\n",
      "4530/4530 [==============================] - 0s 76us/step - loss: 15.3009 - acc: 0.0018\n",
      "Epoch 82/100\n",
      "4530/4530 [==============================] - 0s 70us/step - loss: 15.3487 - acc: 0.0015\n",
      "Epoch 83/100\n",
      "4530/4530 [==============================] - 0s 73us/step - loss: 15.3798 - acc: 0.0022\n",
      "Epoch 84/100\n",
      "4530/4530 [==============================] - 0s 69us/step - loss: 15.3089 - acc: 0.0013\n",
      "Epoch 85/100\n",
      "4530/4530 [==============================] - 0s 72us/step - loss: 15.3065 - acc: 0.0018\n",
      "Epoch 86/100\n",
      "4530/4530 [==============================] - 0s 72us/step - loss: 15.3351 - acc: 0.0018\n",
      "Epoch 87/100\n",
      "4530/4530 [==============================] - 0s 69us/step - loss: 15.3497 - acc: 0.0020\n",
      "Epoch 88/100\n",
      "4530/4530 [==============================] - 0s 69us/step - loss: 15.3696 - acc: 0.0015\n",
      "Epoch 89/100\n",
      "4530/4530 [==============================] - 0s 75us/step - loss: 15.3134 - acc: 0.0020\n",
      "Epoch 90/100\n",
      "4530/4530 [==============================] - 0s 72us/step - loss: 15.3310 - acc: 0.0013\n",
      "Epoch 91/100\n",
      "4530/4530 [==============================] - 0s 72us/step - loss: 15.2596 - acc: 0.0020\n",
      "Epoch 92/100\n",
      "4530/4530 [==============================] - 0s 72us/step - loss: 15.3075 - acc: 0.0013\n",
      "Epoch 93/100\n",
      "4530/4530 [==============================] - 0s 71us/step - loss: 15.3584 - acc: 0.0020\n",
      "Epoch 94/100\n",
      "4530/4530 [==============================] - 0s 70us/step - loss: 15.2660 - acc: 0.0020\n",
      "Epoch 95/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3077 - acc: 0.0018\n",
      "Epoch 96/100\n",
      "4530/4530 [==============================] - 0s 70us/step - loss: 15.3735 - acc: 0.0020\n",
      "Epoch 97/100\n",
      "4530/4530 [==============================] - 0s 72us/step - loss: 15.3121 - acc: 0.0015\n",
      "Epoch 98/100\n",
      "4530/4530 [==============================] - 0s 77us/step - loss: 15.3184 - acc: 0.0020\n",
      "Epoch 99/100\n",
      "4530/4530 [==============================] - 0s 69us/step - loss: 15.3152 - acc: 0.0020\n",
      "Epoch 100/100\n",
      "4530/4530 [==============================] - 0s 73us/step - loss: 15.3319 - acc: 0.0024\n",
      "172/172 [==============================] - 0s 46us/step\n",
      "Epoch 1/100\n",
      "2710/4702 [================>.............] - ETA: 0s - loss: 16.0474 - acc: 0.0011  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.5927 - acc: 0.0013\n",
      "Epoch 2/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.6772 - acc: 0.0023\n",
      "Epoch 3/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.6371 - acc: 0.0019\n",
      "Epoch 4/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.6997 - acc: 0.0019\n",
      "Epoch 5/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.6223 - acc: 0.0013\n",
      "Epoch 6/100\n",
      "4702/4702 [==============================] - 0s 69us/step - loss: 15.6187 - acc: 0.0015\n",
      "Epoch 7/100\n",
      "4702/4702 [==============================] - 0s 71us/step - loss: 15.6198 - acc: 0.0023\n",
      "Epoch 8/100\n",
      "4702/4702 [==============================] - 0s 71us/step - loss: 15.6764 - acc: 0.0017\n",
      "Epoch 9/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.6664 - acc: 0.0017\n",
      "Epoch 10/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.5735 - acc: 0.0021\n",
      "Epoch 11/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.5970 - acc: 0.0019\n",
      "Epoch 12/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.6292 - acc: 0.0013\n",
      "Epoch 13/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.6022 - acc: 0.0021\n",
      "Epoch 14/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.6611 - acc: 0.0021\n",
      "Epoch 15/100\n",
      "4702/4702 [==============================] - 0s 66us/step - loss: 15.6554 - acc: 0.0021\n",
      "Epoch 16/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.6489 - acc: 0.0021\n",
      "Epoch 17/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.6387 - acc: 0.0015\n",
      "Epoch 18/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.6030 - acc: 0.0015\n",
      "Epoch 19/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.5871 - acc: 0.0017\n",
      "Epoch 20/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.6024 - acc: 0.0017\n",
      "Epoch 21/100\n",
      "4702/4702 [==============================] - 0s 69us/step - loss: 15.5904 - acc: 0.0021\n",
      "Epoch 22/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5777 - acc: 0.0017\n",
      "Epoch 23/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.5828 - acc: 0.0019\n",
      "Epoch 24/100\n",
      "4702/4702 [==============================] - 0s 71us/step - loss: 15.6449 - acc: 0.0017\n",
      "Epoch 25/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.6759 - acc: 0.0017\n",
      "Epoch 26/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.6486 - acc: 0.0021\n",
      "Epoch 27/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.6027 - acc: 0.0015\n",
      "Epoch 28/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.5830 - acc: 0.0013\n",
      "Epoch 29/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.6656 - acc: 0.0015\n",
      "Epoch 30/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.6080 - acc: 0.0017\n",
      "Epoch 31/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5786 - acc: 0.0017\n",
      "Epoch 32/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.6349 - acc: 0.0021\n",
      "Epoch 33/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.6506 - acc: 0.0015\n",
      "Epoch 34/100\n",
      "4702/4702 [==============================] - 0s 80us/step - loss: 15.6036 - acc: 0.0019\n",
      "Epoch 35/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.6902 - acc: 0.0017\n",
      "Epoch 36/100\n",
      "4702/4702 [==============================] - 0s 77us/step - loss: 15.6459 - acc: 0.0017\n",
      "Epoch 37/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5959 - acc: 0.0015\n",
      "Epoch 38/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.6447 - acc: 0.0019\n",
      "Epoch 39/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.6143 - acc: 0.0021\n",
      "Epoch 40/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.6298 - acc: 0.0017\n",
      "Epoch 41/100\n",
      "4702/4702 [==============================] - 0s 71us/step - loss: 15.5802 - acc: 0.0019\n",
      "Epoch 42/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.6187 - acc: 0.0030\n",
      "Epoch 43/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.6303 - acc: 0.0017\n",
      "Epoch 44/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.6160 - acc: 0.0019\n",
      "Epoch 45/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.6232 - acc: 0.0019\n",
      "Epoch 46/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.6025 - acc: 0.0017\n",
      "Epoch 47/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.5953 - acc: 0.0015\n",
      "Epoch 48/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.6173 - acc: 0.0019\n",
      "Epoch 49/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.5755 - acc: 0.0021\n",
      "Epoch 50/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.6659 - acc: 0.0026\n",
      "Epoch 51/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.5672 - acc: 8.5070e-04\n",
      "Epoch 52/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5500 - acc: 0.0019\n",
      "Epoch 53/100\n",
      "4702/4702 [==============================] - 0s 79us/step - loss: 15.6000 - acc: 0.0021\n",
      "Epoch 54/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.5944 - acc: 0.0028\n",
      "Epoch 55/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.6181 - acc: 0.0021\n",
      "Epoch 56/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5722 - acc: 0.0019\n",
      "Epoch 57/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.5453 - acc: 0.0026\n",
      "Epoch 58/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.5427 - acc: 0.0019\n",
      "Epoch 59/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.6168 - acc: 0.0023\n",
      "Epoch 60/100\n",
      "4702/4702 [==============================] - 0s 80us/step - loss: 15.5812 - acc: 0.0019\n",
      "Epoch 61/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.6207 - acc: 0.0021\n",
      "Epoch 62/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.6265 - acc: 0.0019\n",
      "Epoch 63/100\n",
      "4702/4702 [==============================] - 0s 78us/step - loss: 15.5660 - acc: 0.0019\n",
      "Epoch 64/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5520 - acc: 0.0019\n",
      "Epoch 65/100\n",
      "4702/4702 [==============================] - 0s 79us/step - loss: 15.5869 - acc: 0.0023\n",
      "Epoch 66/100\n",
      "4702/4702 [==============================] - 0s 78us/step - loss: 15.6507 - acc: 0.0015\n",
      "Epoch 67/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5854 - acc: 0.0021\n",
      "Epoch 68/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5961 - acc: 0.0023\n",
      "Epoch 69/100\n",
      "4702/4702 [==============================] - 0s 79us/step - loss: 15.5466 - acc: 0.0013\n",
      "Epoch 70/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.6830 - acc: 0.0021\n",
      "Epoch 71/100\n",
      "4702/4702 [==============================] - 0s 78us/step - loss: 15.5426 - acc: 0.0023\n",
      "Epoch 72/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.5733 - acc: 0.0013\n",
      "Epoch 73/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.5855 - acc: 0.0019\n",
      "Epoch 74/100\n",
      "4702/4702 [==============================] - 0s 79us/step - loss: 15.6162 - acc: 0.0019\n",
      "Epoch 75/100\n",
      "4702/4702 [==============================] - 0s 83us/step - loss: 15.6807 - acc: 0.0021\n",
      "Epoch 76/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.5858 - acc: 0.0019\n",
      "Epoch 77/100\n",
      "4702/4702 [==============================] - 0s 77us/step - loss: 15.5565 - acc: 0.0019\n",
      "Epoch 78/100\n",
      "4702/4702 [==============================] - 0s 78us/step - loss: 15.6307 - acc: 0.0026\n",
      "Epoch 79/100\n",
      "4702/4702 [==============================] - 0s 75us/step - loss: 15.6072 - acc: 0.0017\n",
      "Epoch 80/100\n",
      "4702/4702 [==============================] - 0s 79us/step - loss: 15.5833 - acc: 0.0011\n",
      "Epoch 81/100\n",
      "4702/4702 [==============================] - 0s 78us/step - loss: 15.6075 - acc: 0.0021\n",
      "Epoch 82/100\n",
      "4702/4702 [==============================] - 0s 76us/step - loss: 15.5494 - acc: 0.0019\n",
      "Epoch 83/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.5729 - acc: 0.0021\n",
      "Epoch 84/100\n",
      "4702/4702 [==============================] - 0s 65us/step - loss: 15.5645 - acc: 0.0019\n",
      "Epoch 85/100\n",
      "4702/4702 [==============================] - 0s 74us/step - loss: 15.6183 - acc: 0.0019\n",
      "Epoch 86/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.5128 - acc: 0.0017\n",
      "Epoch 87/100\n",
      "4702/4702 [==============================] - 0s 68us/step - loss: 15.5793 - acc: 0.0023\n",
      "Epoch 88/100\n",
      "4702/4702 [==============================] - 0s 71us/step - loss: 15.5895 - acc: 0.0021\n",
      "Epoch 89/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.5613 - acc: 0.0021\n",
      "Epoch 90/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.5782 - acc: 0.0017\n",
      "Epoch 91/100\n",
      "4702/4702 [==============================] - 0s 70us/step - loss: 15.5771 - acc: 0.0019\n",
      "Epoch 92/100\n",
      "4702/4702 [==============================] - 0s 78us/step - loss: 15.5296 - acc: 0.0026\n",
      "Epoch 93/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.5656 - acc: 0.0015\n",
      "Epoch 94/100\n",
      "4702/4702 [==============================] - 0s 77us/step - loss: 15.5655 - acc: 0.0017\n",
      "Epoch 95/100\n",
      "4702/4702 [==============================] - 0s 71us/step - loss: 15.5956 - acc: 0.0026\n",
      "Epoch 96/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.5154 - acc: 0.0017\n",
      "Epoch 97/100\n",
      "4702/4702 [==============================] - 0s 78us/step - loss: 15.5270 - acc: 0.0028\n",
      "Epoch 98/100\n",
      "4702/4702 [==============================] - 0s 73us/step - loss: 15.5990 - acc: 0.0021\n",
      "Epoch 99/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.5584 - acc: 0.0021\n",
      "Epoch 100/100\n",
      "4702/4702 [==============================] - 0s 72us/step - loss: 15.5808 - acc: 0.0021\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2070/4874 [===========>..................] - ETA: 0s - loss: 15.8182 - acc: 0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.7545 - acc: 0.0018\n",
      "Epoch 2/100\n",
      "4874/4874 [==============================] - 0s 70us/step - loss: 15.7793 - acc: 0.0023\n",
      "Epoch 3/100\n",
      "4874/4874 [==============================] - 0s 69us/step - loss: 15.7505 - acc: 0.0029\n",
      "Epoch 4/100\n",
      "4874/4874 [==============================] - 0s 70us/step - loss: 15.7556 - acc: 0.0029\n",
      "Epoch 5/100\n",
      "4874/4874 [==============================] - 0s 70us/step - loss: 15.7555 - acc: 0.0027\n",
      "Epoch 6/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6795 - acc: 0.0016\n",
      "Epoch 7/100\n",
      "4874/4874 [==============================] - 0s 70us/step - loss: 15.6943 - acc: 0.0014\n",
      "Epoch 8/100\n",
      "4874/4874 [==============================] - 0s 65us/step - loss: 15.7072 - acc: 0.0018\n",
      "Epoch 9/100\n",
      "4874/4874 [==============================] - 0s 75us/step - loss: 15.6977 - acc: 0.0031\n",
      "Epoch 10/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6518 - acc: 0.0023\n",
      "Epoch 11/100\n",
      "4874/4874 [==============================] - 0s 70us/step - loss: 15.6872 - acc: 0.0018\n",
      "Epoch 12/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6874 - acc: 0.0014\n",
      "Epoch 13/100\n",
      "4874/4874 [==============================] - 0s 71us/step - loss: 15.6954 - acc: 0.0014\n",
      "Epoch 14/100\n",
      "4874/4874 [==============================] - 0s 69us/step - loss: 15.7523 - acc: 0.0018\n",
      "Epoch 15/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.7039 - acc: 0.0021\n",
      "Epoch 16/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.7043 - acc: 0.0016\n",
      "Epoch 17/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6709 - acc: 0.0021\n",
      "Epoch 18/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6670 - acc: 0.0021\n",
      "Epoch 19/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.6301 - acc: 0.0018\n",
      "Epoch 20/100\n",
      "4874/4874 [==============================] - 0s 71us/step - loss: 15.7640 - acc: 0.0021\n",
      "Epoch 21/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6091 - acc: 0.0014\n",
      "Epoch 22/100\n",
      "4874/4874 [==============================] - 0s 74us/step - loss: 15.7263 - acc: 0.0018\n",
      "Epoch 23/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6783 - acc: 0.0023\n",
      "Epoch 24/100\n",
      "4874/4874 [==============================] - 0s 74us/step - loss: 15.7179 - acc: 0.0018\n",
      "Epoch 25/100\n",
      "4874/4874 [==============================] - 0s 77us/step - loss: 15.6099 - acc: 0.0016\n",
      "Epoch 26/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6340 - acc: 0.0018\n",
      "Epoch 27/100\n",
      "4874/4874 [==============================] - 0s 85us/step - loss: 15.7022 - acc: 0.0021\n",
      "Epoch 28/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6288 - acc: 0.0018\n",
      "Epoch 29/100\n",
      "4874/4874 [==============================] - 0s 75us/step - loss: 15.5527 - acc: 0.0027\n",
      "Epoch 30/100\n",
      "4874/4874 [==============================] - 0s 82us/step - loss: 15.6545 - acc: 0.0021\n",
      "Epoch 31/100\n",
      "4874/4874 [==============================] - 0s 78us/step - loss: 15.6504 - acc: 0.0018\n",
      "Epoch 32/100\n",
      "4874/4874 [==============================] - 0s 80us/step - loss: 15.6039 - acc: 0.0021\n",
      "Epoch 33/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6391 - acc: 0.0027\n",
      "Epoch 34/100\n",
      "4874/4874 [==============================] - 0s 80us/step - loss: 15.5993 - acc: 0.0021\n",
      "Epoch 35/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6356 - acc: 0.0025\n",
      "Epoch 36/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6311 - acc: 0.0021\n",
      "Epoch 37/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6673 - acc: 0.0018\n",
      "Epoch 38/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6191 - acc: 0.0023\n",
      "Epoch 39/100\n",
      "4874/4874 [==============================] - 0s 78us/step - loss: 15.5449 - acc: 0.0014\n",
      "Epoch 40/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6366 - acc: 0.0021\n",
      "Epoch 41/100\n",
      "4874/4874 [==============================] - 0s 82us/step - loss: 15.6268 - acc: 0.0025\n",
      "Epoch 42/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6480 - acc: 0.0014\n",
      "Epoch 43/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6388 - acc: 0.0025\n",
      "Epoch 44/100\n",
      "4874/4874 [==============================] - 0s 81us/step - loss: 15.6861 - acc: 0.0021\n",
      "Epoch 45/100\n",
      "4874/4874 [==============================] - 0s 83us/step - loss: 15.6334 - acc: 0.0014\n",
      "Epoch 46/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6701 - acc: 0.0025\n",
      "Epoch 47/100\n",
      "4874/4874 [==============================] - 0s 81us/step - loss: 15.6307 - acc: 0.0025\n",
      "Epoch 48/100\n",
      "4874/4874 [==============================] - 0s 80us/step - loss: 15.6040 - acc: 0.0021\n",
      "Epoch 49/100\n",
      "4874/4874 [==============================] - 0s 75us/step - loss: 15.6331 - acc: 0.0014\n",
      "Epoch 50/100\n",
      "4874/4874 [==============================] - 0s 87us/step - loss: 15.6211 - acc: 0.0016\n",
      "Epoch 51/100\n",
      "4874/4874 [==============================] - 0s 90us/step - loss: 15.6635 - acc: 0.0018\n",
      "Epoch 52/100\n",
      "4874/4874 [==============================] - 0s 94us/step - loss: 15.6268 - acc: 0.0014\n",
      "Epoch 53/100\n",
      "4874/4874 [==============================] - 0s 89us/step - loss: 15.6900 - acc: 0.0018\n",
      "Epoch 54/100\n",
      "4874/4874 [==============================] - 0s 89us/step - loss: 15.6304 - acc: 0.0021\n",
      "Epoch 55/100\n",
      "4874/4874 [==============================] - 0s 84us/step - loss: 15.6173 - acc: 0.0023\n",
      "Epoch 56/100\n",
      "4874/4874 [==============================] - 0s 89us/step - loss: 15.6278 - acc: 0.0018\n",
      "Epoch 57/100\n",
      "4874/4874 [==============================] - 0s 80us/step - loss: 15.6234 - acc: 0.0014\n",
      "Epoch 58/100\n",
      "4874/4874 [==============================] - 0s 78us/step - loss: 15.5849 - acc: 0.0021\n",
      "Epoch 59/100\n",
      "4874/4874 [==============================] - 0s 77us/step - loss: 15.6108 - acc: 0.0016\n",
      "Epoch 60/100\n",
      "4874/4874 [==============================] - 0s 80us/step - loss: 15.6429 - acc: 0.0021\n",
      "Epoch 61/100\n",
      "4874/4874 [==============================] - 0s 76us/step - loss: 15.6480 - acc: 0.0027\n",
      "Epoch 62/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6188 - acc: 0.0012\n",
      "Epoch 63/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6370 - acc: 0.0023\n",
      "Epoch 64/100\n",
      "4874/4874 [==============================] - 0s 80us/step - loss: 15.6436 - acc: 0.0027\n",
      "Epoch 65/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.5768 - acc: 0.0018\n",
      "Epoch 66/100\n",
      "4874/4874 [==============================] - 0s 78us/step - loss: 15.6332 - acc: 0.0023\n",
      "Epoch 67/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6378 - acc: 0.0014\n",
      "Epoch 68/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6241 - acc: 0.0016\n",
      "Epoch 69/100\n",
      "4874/4874 [==============================] - 0s 81us/step - loss: 15.6218 - acc: 0.0016\n",
      "Epoch 70/100\n",
      "4874/4874 [==============================] - 0s 78us/step - loss: 15.6148 - acc: 0.0021\n",
      "Epoch 71/100\n",
      "4874/4874 [==============================] - 0s 77us/step - loss: 15.5696 - acc: 0.0018\n",
      "Epoch 72/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.5928 - acc: 0.0021\n",
      "Epoch 73/100\n",
      "4874/4874 [==============================] - 0s 81us/step - loss: 15.6042 - acc: 0.0018\n",
      "Epoch 74/100\n",
      "4874/4874 [==============================] - 0s 78us/step - loss: 15.6279 - acc: 0.0016\n",
      "Epoch 75/100\n",
      "4874/4874 [==============================] - 0s 78us/step - loss: 15.6497 - acc: 0.0014\n",
      "Epoch 76/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6030 - acc: 0.0027\n",
      "Epoch 77/100\n",
      "4874/4874 [==============================] - 0s 78us/step - loss: 15.6248 - acc: 0.0021\n",
      "Epoch 78/100\n",
      "4874/4874 [==============================] - 0s 81us/step - loss: 15.6283 - acc: 0.0018\n",
      "Epoch 79/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.7092 - acc: 0.0023\n",
      "Epoch 80/100\n",
      "4874/4874 [==============================] - 0s 79us/step - loss: 15.6210 - acc: 0.0021\n",
      "Epoch 81/100\n",
      "4874/4874 [==============================] - 0s 80us/step - loss: 15.5879 - acc: 0.0010\n",
      "Epoch 82/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6188 - acc: 0.0025\n",
      "Epoch 83/100\n",
      "4874/4874 [==============================] - 0s 73us/step - loss: 15.6369 - acc: 0.0016\n",
      "Epoch 84/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.6432 - acc: 0.0025\n",
      "Epoch 85/100\n",
      "4874/4874 [==============================] - 0s 68us/step - loss: 15.6209 - acc: 0.0023\n",
      "Epoch 86/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.6694 - acc: 0.0021\n",
      "Epoch 87/100\n",
      "4874/4874 [==============================] - 0s 69us/step - loss: 15.6436 - acc: 0.0021\n",
      "Epoch 88/100\n",
      "4874/4874 [==============================] - 0s 69us/step - loss: 15.6191 - acc: 0.0023\n",
      "Epoch 89/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.5715 - acc: 0.0021\n",
      "Epoch 90/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.6845 - acc: 0.0021\n",
      "Epoch 91/100\n",
      "4874/4874 [==============================] - 0s 71us/step - loss: 15.6579 - acc: 0.0023\n",
      "Epoch 92/100\n",
      "4874/4874 [==============================] - 0s 68us/step - loss: 15.6116 - acc: 0.0025\n",
      "Epoch 93/100\n",
      "4874/4874 [==============================] - 0s 71us/step - loss: 15.6093 - acc: 0.0025\n",
      "Epoch 94/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.6369 - acc: 0.0016\n",
      "Epoch 95/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.6580 - acc: 0.0014\n",
      "Epoch 96/100\n",
      "4874/4874 [==============================] - 0s 71us/step - loss: 15.6231 - acc: 0.0018\n",
      "Epoch 97/100\n",
      "4874/4874 [==============================] - 0s 70us/step - loss: 15.5769 - acc: 0.0018\n",
      "Epoch 98/100\n",
      "4874/4874 [==============================] - 0s 74us/step - loss: 15.6355 - acc: 0.0023\n",
      "Epoch 99/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.5956 - acc: 0.0025\n",
      "Epoch 100/100\n",
      "4874/4874 [==============================] - 0s 72us/step - loss: 15.7149 - acc: 0.0016\n",
      "172/172 [==============================] - 0s 46us/step\n",
      "Epoch 1/100\n",
      "2040/5046 [===========>..................] - ETA: 0s - loss: 15.9738 - acc: 0.0029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046/5046 [==============================] - 0s 75us/step - loss: 16.2408 - acc: 0.0026\n",
      "Epoch 2/100\n",
      "5046/5046 [==============================] - 0s 66us/step - loss: 16.1609 - acc: 0.0020\n",
      "Epoch 3/100\n",
      "5046/5046 [==============================] - 0s 69us/step - loss: 16.1630 - acc: 0.0020\n",
      "Epoch 4/100\n",
      "5046/5046 [==============================] - 0s 69us/step - loss: 16.1372 - acc: 0.0014\n",
      "Epoch 5/100\n",
      "5046/5046 [==============================] - 0s 69us/step - loss: 16.1653 - acc: 0.0012\n",
      "Epoch 6/100\n",
      "5046/5046 [==============================] - 0s 70us/step - loss: 16.1363 - acc: 7.9271e-04\n",
      "Epoch 7/100\n",
      "5046/5046 [==============================] - 0s 70us/step - loss: 16.0764 - acc: 0.0022\n",
      "Epoch 8/100\n",
      "5046/5046 [==============================] - 0s 71us/step - loss: 16.0877 - acc: 0.0020\n",
      "Epoch 9/100\n",
      "5046/5046 [==============================] - 0s 72us/step - loss: 16.0540 - acc: 0.0012\n",
      "Epoch 10/100\n",
      "5046/5046 [==============================] - 0s 72us/step - loss: 16.0525 - acc: 0.0014\n",
      "Epoch 11/100\n",
      "5046/5046 [==============================] - 0s 69us/step - loss: 16.0831 - acc: 0.0018\n",
      "Epoch 12/100\n",
      "5046/5046 [==============================] - 0s 73us/step - loss: 16.0523 - acc: 0.0014\n",
      "Epoch 13/100\n",
      "5046/5046 [==============================] - 0s 71us/step - loss: 16.0704 - acc: 0.0016\n",
      "Epoch 14/100\n",
      "5046/5046 [==============================] - 0s 70us/step - loss: 16.0864 - acc: 0.0016\n",
      "Epoch 15/100\n",
      "5046/5046 [==============================] - 0s 72us/step - loss: 16.0352 - acc: 0.0016\n",
      "Epoch 16/100\n",
      "5046/5046 [==============================] - 0s 70us/step - loss: 16.0131 - acc: 0.0020\n",
      "Epoch 17/100\n",
      "5046/5046 [==============================] - 0s 70us/step - loss: 16.0824 - acc: 0.0020\n",
      "Epoch 18/100\n",
      "5046/5046 [==============================] - 0s 73us/step - loss: 16.0084 - acc: 0.0016\n",
      "Epoch 19/100\n",
      "5046/5046 [==============================] - 0s 72us/step - loss: 16.0773 - acc: 0.0020\n",
      "Epoch 20/100\n",
      "5046/5046 [==============================] - 0s 71us/step - loss: 16.0108 - acc: 0.0018\n",
      "Epoch 21/100\n",
      "5046/5046 [==============================] - 0s 74us/step - loss: 15.9741 - acc: 0.0012\n",
      "Epoch 22/100\n",
      "5046/5046 [==============================] - 0s 72us/step - loss: 15.9712 - acc: 0.0014\n",
      "Epoch 23/100\n",
      "5046/5046 [==============================] - 0s 72us/step - loss: 15.9655 - acc: 0.0018\n",
      "Epoch 24/100\n",
      "5046/5046 [==============================] - 0s 73us/step - loss: 16.0465 - acc: 9.9088e-04\n",
      "Epoch 25/100\n",
      "5046/5046 [==============================] - 0s 73us/step - loss: 16.0572 - acc: 9.9088e-04\n",
      "Epoch 26/100\n",
      "5046/5046 [==============================] - 0s 72us/step - loss: 15.9534 - acc: 0.0020\n",
      "Epoch 27/100\n",
      "5046/5046 [==============================] - 0s 75us/step - loss: 15.9875 - acc: 0.0016\n",
      "Epoch 28/100\n",
      "5046/5046 [==============================] - 0s 84us/step - loss: 16.0148 - acc: 0.0016\n",
      "Epoch 29/100\n",
      "5046/5046 [==============================] - 0s 79us/step - loss: 15.9611 - acc: 0.0016\n",
      "Epoch 30/100\n",
      "5046/5046 [==============================] - 0s 90us/step - loss: 15.9858 - acc: 0.0016\n",
      "Epoch 31/100\n",
      "5046/5046 [==============================] - 0s 96us/step - loss: 15.9510 - acc: 0.0012\n",
      "Epoch 32/100\n",
      "5046/5046 [==============================] - 1s 132us/step - loss: 16.0420 - acc: 0.0022\n",
      "Epoch 33/100\n",
      "5046/5046 [==============================] - 1s 126us/step - loss: 15.9324 - acc: 0.0016\n",
      "Epoch 34/100\n",
      "5046/5046 [==============================] - 0s 90us/step - loss: 15.9635 - acc: 0.0020\n",
      "Epoch 35/100\n",
      "5046/5046 [==============================] - 0s 76us/step - loss: 15.9131 - acc: 0.0016\n",
      "Epoch 36/100\n",
      "5046/5046 [==============================] - 0s 74us/step - loss: 16.0082 - acc: 0.0016\n",
      "Epoch 37/100\n",
      "5046/5046 [==============================] - 0s 63us/step - loss: 15.9287 - acc: 0.0022\n",
      "Epoch 38/100\n",
      "5046/5046 [==============================] - 0s 91us/step - loss: 16.0091 - acc: 0.0014\n",
      "Epoch 39/100\n",
      "5046/5046 [==============================] - 1s 107us/step - loss: 15.9895 - acc: 0.0014\n",
      "Epoch 40/100\n",
      "5046/5046 [==============================] - 1s 119us/step - loss: 15.9580 - acc: 0.0020\n",
      "Epoch 41/100\n",
      "5046/5046 [==============================] - 1s 106us/step - loss: 15.9987 - acc: 0.0020\n",
      "Epoch 42/100\n",
      "5046/5046 [==============================] - 0s 97us/step - loss: 15.9808 - acc: 0.0012\n",
      "Epoch 43/100\n",
      "5046/5046 [==============================] - 1s 118us/step - loss: 15.9795 - acc: 0.0020\n",
      "Epoch 44/100\n",
      "5046/5046 [==============================] - 0s 79us/step - loss: 16.0029 - acc: 0.0014\n",
      "Epoch 45/100\n",
      "5046/5046 [==============================] - 0s 60us/step - loss: 15.9881 - acc: 0.0016\n",
      "Epoch 46/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 16.0052 - acc: 0.0014\n",
      "Epoch 47/100\n",
      "5046/5046 [==============================] - 0s 59us/step - loss: 16.0061 - acc: 0.0012\n",
      "Epoch 48/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 15.9958 - acc: 0.0022\n",
      "Epoch 49/100\n",
      "5046/5046 [==============================] - 0s 55us/step - loss: 15.9595 - acc: 0.0016\n",
      "Epoch 50/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 15.9198 - acc: 0.0014\n",
      "Epoch 51/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9552 - acc: 0.0018\n",
      "Epoch 52/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9659 - acc: 0.0024\n",
      "Epoch 53/100\n",
      "5046/5046 [==============================] - 0s 59us/step - loss: 15.9362 - acc: 0.0016\n",
      "Epoch 54/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9687 - acc: 9.9088e-04\n",
      "Epoch 55/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9105 - acc: 0.0018\n",
      "Epoch 56/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9101 - acc: 0.0012\n",
      "Epoch 57/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 16.0167 - acc: 0.0030\n",
      "Epoch 58/100\n",
      "5046/5046 [==============================] - 0s 62us/step - loss: 16.0056 - acc: 0.0022\n",
      "Epoch 59/100\n",
      "5046/5046 [==============================] - 0s 59us/step - loss: 15.9738 - acc: 0.0016\n",
      "Epoch 60/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9049 - acc: 0.0020\n",
      "Epoch 61/100\n",
      "5046/5046 [==============================] - 0s 60us/step - loss: 15.9589 - acc: 0.0016\n",
      "Epoch 62/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 15.9970 - acc: 0.0022\n",
      "Epoch 63/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9770 - acc: 9.9088e-04\n",
      "Epoch 64/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 15.9516 - acc: 0.0016\n",
      "Epoch 65/100\n",
      "5046/5046 [==============================] - 0s 57us/step - loss: 15.9126 - acc: 0.0016\n",
      "Epoch 66/100\n",
      "5046/5046 [==============================] - 0s 59us/step - loss: 15.9396 - acc: 0.0016\n",
      "Epoch 67/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9280 - acc: 0.0018\n",
      "Epoch 68/100\n",
      "5046/5046 [==============================] - 0s 59us/step - loss: 15.9335 - acc: 0.0020\n",
      "Epoch 69/100\n",
      "5046/5046 [==============================] - 0s 54us/step - loss: 15.9771 - acc: 0.0020\n",
      "Epoch 70/100\n",
      "5046/5046 [==============================] - 0s 59us/step - loss: 15.9498 - acc: 0.0012\n",
      "Epoch 71/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9246 - acc: 0.0018\n",
      "Epoch 72/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 15.9602 - acc: 0.0030\n",
      "Epoch 73/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 15.9470 - acc: 0.0018\n",
      "Epoch 74/100\n",
      "5046/5046 [==============================] - 0s 59us/step - loss: 15.9325 - acc: 0.0014\n",
      "Epoch 75/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.8901 - acc: 0.0020\n",
      "Epoch 76/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9226 - acc: 0.0018\n",
      "Epoch 77/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9094 - acc: 0.0030\n",
      "Epoch 78/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 15.9387 - acc: 0.0016\n",
      "Epoch 79/100\n",
      "5046/5046 [==============================] - 0s 57us/step - loss: 15.9329 - acc: 0.0024\n",
      "Epoch 80/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9220 - acc: 0.0030\n",
      "Epoch 81/100\n",
      "5046/5046 [==============================] - 0s 57us/step - loss: 15.9547 - acc: 0.0022\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046/5046 [==============================] - 0s 54us/step - loss: 15.8882 - acc: 0.0018\n",
      "Epoch 83/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 16.0030 - acc: 0.0024\n",
      "Epoch 84/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9233 - acc: 0.0020\n",
      "Epoch 85/100\n",
      "5046/5046 [==============================] - 0s 60us/step - loss: 15.9121 - acc: 0.0022\n",
      "Epoch 86/100\n",
      "5046/5046 [==============================] - 0s 57us/step - loss: 15.9918 - acc: 0.0016\n",
      "Epoch 87/100\n",
      "5046/5046 [==============================] - 0s 53us/step - loss: 15.9664 - acc: 0.0016\n",
      "Epoch 88/100\n",
      "5046/5046 [==============================] - 0s 60us/step - loss: 15.9243 - acc: 0.0020\n",
      "Epoch 89/100\n",
      "5046/5046 [==============================] - 0s 57us/step - loss: 15.9277 - acc: 0.0022\n",
      "Epoch 90/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 16.0353 - acc: 0.0024\n",
      "Epoch 91/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.8870 - acc: 0.0012\n",
      "Epoch 92/100\n",
      "5046/5046 [==============================] - 0s 57us/step - loss: 15.9430 - acc: 0.0022\n",
      "Epoch 93/100\n",
      "5046/5046 [==============================] - 0s 57us/step - loss: 15.9063 - acc: 0.0012\n",
      "Epoch 94/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9382 - acc: 0.0028\n",
      "Epoch 95/100\n",
      "5046/5046 [==============================] - 0s 58us/step - loss: 15.9279 - acc: 0.0022\n",
      "Epoch 96/100\n",
      "5046/5046 [==============================] - 0s 57us/step - loss: 15.9447 - acc: 0.0022\n",
      "Epoch 97/100\n",
      "5046/5046 [==============================] - 0s 53us/step - loss: 15.9395 - acc: 0.0014\n",
      "Epoch 98/100\n",
      "5046/5046 [==============================] - 0s 56us/step - loss: 15.9039 - acc: 0.0020\n",
      "Epoch 99/100\n",
      "5046/5046 [==============================] - 0s 63us/step - loss: 16.0003 - acc: 0.0016\n",
      "Epoch 100/100\n",
      "5046/5046 [==============================] - 0s 54us/step - loss: 15.9273 - acc: 0.0020\n",
      "172/172 [==============================] - 0s 0us/step\n",
      "Epoch 1/100\n",
      "3120/5218 [================>.............] - ETA: 0s - loss: 16.3927 - acc: 6.4103e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5218/5218 [==============================] - 0s 59us/step - loss: 16.0724 - acc: 9.5822e-04\n",
      "Epoch 2/100\n",
      "5218/5218 [==============================] - 0s 61us/step - loss: 16.1163 - acc: 0.0011\n",
      "Epoch 3/100\n",
      "5218/5218 [==============================] - 0s 55us/step - loss: 16.0877 - acc: 0.0021\n",
      "Epoch 4/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.1480 - acc: 0.0023\n",
      "Epoch 5/100\n",
      "5218/5218 [==============================] - 0s 55us/step - loss: 16.0509 - acc: 0.0021\n",
      "Epoch 6/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 16.0402 - acc: 0.0019\n",
      "Epoch 7/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.1030 - acc: 0.0011\n",
      "Epoch 8/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9978 - acc: 0.0013\n",
      "Epoch 9/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 16.1471 - acc: 0.0023\n",
      "Epoch 10/100\n",
      "5218/5218 [==============================] - 0s 55us/step - loss: 16.0028 - acc: 0.0023\n",
      "Epoch 11/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 16.0366 - acc: 0.0015\n",
      "Epoch 12/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 16.0084 - acc: 0.0023\n",
      "Epoch 13/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0372 - acc: 0.0019\n",
      "Epoch 14/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 16.0194 - acc: 0.0017\n",
      "Epoch 15/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9899 - acc: 0.0017\n",
      "Epoch 16/100\n",
      "5218/5218 [==============================] - 0s 60us/step - loss: 15.9705 - acc: 0.0021\n",
      "Epoch 17/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0222 - acc: 0.0023\n",
      "Epoch 18/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9103 - acc: 0.0019\n",
      "Epoch 19/100\n",
      "5218/5218 [==============================] - 0s 56us/step - loss: 16.0124 - acc: 0.0015\n",
      "Epoch 20/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0865 - acc: 0.0021\n",
      "Epoch 21/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0062 - acc: 0.0025\n",
      "Epoch 22/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0329 - acc: 0.0015\n",
      "Epoch 23/100\n",
      "5218/5218 [==============================] - 0s 55us/step - loss: 15.9876 - acc: 0.0015\n",
      "Epoch 24/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9941 - acc: 0.0023\n",
      "Epoch 25/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9618 - acc: 0.0021\n",
      "Epoch 26/100\n",
      "5218/5218 [==============================] - 0s 60us/step - loss: 16.0444 - acc: 0.0021\n",
      "Epoch 27/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0032 - acc: 0.0017\n",
      "Epoch 28/100\n",
      "5218/5218 [==============================] - 0s 55us/step - loss: 16.0389 - acc: 0.0017\n",
      "Epoch 29/100\n",
      "5218/5218 [==============================] - 0s 56us/step - loss: 16.0835 - acc: 0.0017\n",
      "Epoch 30/100\n",
      "5218/5218 [==============================] - 0s 59us/step - loss: 15.9435 - acc: 0.0019\n",
      "Epoch 31/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9728 - acc: 0.0021\n",
      "Epoch 32/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9678 - acc: 0.0019\n",
      "Epoch 33/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 16.0398 - acc: 0.0019\n",
      "Epoch 34/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9965 - acc: 0.0019\n",
      "Epoch 35/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 16.0313 - acc: 0.0013\n",
      "Epoch 36/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9800 - acc: 0.0021\n",
      "Epoch 37/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 16.0192 - acc: 0.0027\n",
      "Epoch 38/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9505 - acc: 0.0017\n",
      "Epoch 39/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 16.0464 - acc: 0.0013\n",
      "Epoch 40/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9564 - acc: 0.0027\n",
      "Epoch 41/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9861 - acc: 0.0015\n",
      "Epoch 42/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0144 - acc: 0.0015\n",
      "Epoch 43/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0154 - acc: 0.0019\n",
      "Epoch 44/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9736 - acc: 0.0023\n",
      "Epoch 45/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9593 - acc: 0.0027\n",
      "Epoch 46/100\n",
      "5218/5218 [==============================] - 0s 56us/step - loss: 16.0330 - acc: 0.0015\n",
      "Epoch 47/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0643 - acc: 0.0025\n",
      "Epoch 48/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0077 - acc: 0.0027\n",
      "Epoch 49/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9476 - acc: 0.0021\n",
      "Epoch 50/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0159 - acc: 0.0019\n",
      "Epoch 51/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9592 - acc: 0.0017\n",
      "Epoch 52/100\n",
      "5218/5218 [==============================] - 0s 56us/step - loss: 15.8927 - acc: 0.0027\n",
      "Epoch 53/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9758 - acc: 0.0021\n",
      "Epoch 54/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 16.0097 - acc: 0.0023\n",
      "Epoch 55/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0178 - acc: 0.0027\n",
      "Epoch 56/100\n",
      "5218/5218 [==============================] - 0s 56us/step - loss: 15.9584 - acc: 0.0019\n",
      "Epoch 57/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9441 - acc: 0.0023\n",
      "Epoch 58/100\n",
      "5218/5218 [==============================] - 0s 60us/step - loss: 16.0649 - acc: 0.0021\n",
      "Epoch 59/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0501 - acc: 0.0023\n",
      "Epoch 60/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9564 - acc: 0.0011\n",
      "Epoch 61/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9510 - acc: 0.0027\n",
      "Epoch 62/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9497 - acc: 0.0013\n",
      "Epoch 63/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9931 - acc: 0.0019\n",
      "Epoch 64/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9670 - acc: 9.5822e-04\n",
      "Epoch 65/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9724 - acc: 0.0021\n",
      "Epoch 66/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9427 - acc: 0.0021\n",
      "Epoch 67/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9415 - acc: 0.0021\n",
      "Epoch 68/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 16.0233 - acc: 0.0019\n",
      "Epoch 69/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9757 - acc: 0.0023\n",
      "Epoch 70/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 16.0145 - acc: 0.0021\n",
      "Epoch 71/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9537 - acc: 0.0025\n",
      "Epoch 72/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9521 - acc: 0.0019\n",
      "Epoch 73/100\n",
      "5218/5218 [==============================] - 0s 56us/step - loss: 15.9588 - acc: 0.0021\n",
      "Epoch 74/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9648 - acc: 0.0025\n",
      "Epoch 75/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 16.0273 - acc: 0.0019\n",
      "Epoch 76/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9419 - acc: 0.0019\n",
      "Epoch 77/100\n",
      "5218/5218 [==============================] - 0s 60us/step - loss: 15.9573 - acc: 0.0021\n",
      "Epoch 78/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9728 - acc: 0.0021\n",
      "Epoch 79/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9138 - acc: 0.0013\n",
      "Epoch 80/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9617 - acc: 0.0017\n",
      "Epoch 81/100\n",
      "5218/5218 [==============================] - 0s 59us/step - loss: 16.0219 - acc: 0.0021\n",
      "Epoch 82/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 15.9109 - acc: 0.0025\n",
      "Epoch 83/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9755 - acc: 0.0015\n",
      "Epoch 84/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9940 - acc: 0.0025\n",
      "Epoch 85/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9594 - acc: 0.0017\n",
      "Epoch 86/100\n",
      "5218/5218 [==============================] - 0s 55us/step - loss: 15.9989 - acc: 0.0029\n",
      "Epoch 87/100\n",
      "5218/5218 [==============================] - 0s 56us/step - loss: 16.0012 - acc: 0.0023\n",
      "Epoch 88/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9979 - acc: 0.0023\n",
      "Epoch 89/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9152 - acc: 0.0019\n",
      "Epoch 90/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 16.0131 - acc: 0.0019\n",
      "Epoch 91/100\n",
      "5218/5218 [==============================] - 0s 55us/step - loss: 15.9929 - acc: 0.0025\n",
      "Epoch 92/100\n",
      "5218/5218 [==============================] - 0s 59us/step - loss: 15.9756 - acc: 0.0017\n",
      "Epoch 93/100\n",
      "5218/5218 [==============================] - 0s 54us/step - loss: 16.0040 - acc: 0.0017\n",
      "Epoch 94/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9433 - acc: 0.0023\n",
      "Epoch 95/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9693 - acc: 0.0019\n",
      "Epoch 96/100\n",
      "5218/5218 [==============================] - 0s 56us/step - loss: 16.0615 - acc: 0.0015\n",
      "Epoch 97/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.9785 - acc: 0.0017\n",
      "Epoch 98/100\n",
      "5218/5218 [==============================] - 0s 57us/step - loss: 15.8994 - acc: 0.0029\n",
      "Epoch 99/100\n",
      "5218/5218 [==============================] - 0s 55us/step - loss: 15.9995 - acc: 0.0023\n",
      "Epoch 100/100\n",
      "5218/5218 [==============================] - 0s 58us/step - loss: 15.9728 - acc: 0.0021\n",
      "172/172 [==============================] - 0s 0us/step\n",
      "Epoch 1/100\n",
      "3080/5390 [================>.............] - ETA: 0s - loss: 16.4339 - acc: 0.0023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.1257 - acc: 0.0017\n",
      "Epoch 2/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0966 - acc: 0.0022\n",
      "Epoch 3/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.1222 - acc: 0.0026\n",
      "Epoch 4/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0350 - acc: 0.0019\n",
      "Epoch 5/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0379 - acc: 0.0013\n",
      "Epoch 6/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0351 - acc: 0.0024\n",
      "Epoch 7/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0958 - acc: 0.0024\n",
      "Epoch 8/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0720 - acc: 0.0020\n",
      "Epoch 9/100\n",
      "5390/5390 [==============================] - 0s 54us/step - loss: 16.0810 - acc: 0.0020\n",
      "Epoch 10/100\n",
      "5390/5390 [==============================] - 0s 59us/step - loss: 16.0713 - acc: 0.0024\n",
      "Epoch 11/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0685 - acc: 0.0026\n",
      "Epoch 12/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0389 - acc: 0.0017\n",
      "Epoch 13/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.1045 - acc: 0.0022\n",
      "Epoch 14/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0509 - acc: 0.0019\n",
      "Epoch 15/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0410 - acc: 0.0024\n",
      "Epoch 16/100\n",
      "5390/5390 [==============================] - 0s 60us/step - loss: 16.0154 - acc: 0.0026\n",
      "Epoch 17/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0537 - acc: 0.0017\n",
      "Epoch 18/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0990 - acc: 0.0019\n",
      "Epoch 19/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0094 - acc: 0.0020\n",
      "Epoch 20/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0985 - acc: 0.0019\n",
      "Epoch 21/100\n",
      "5390/5390 [==============================] - 0s 59us/step - loss: 16.0955 - acc: 0.0020\n",
      "Epoch 22/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0667 - acc: 0.0028\n",
      "Epoch 23/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0481 - acc: 0.0024\n",
      "Epoch 24/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0565 - acc: 0.0022\n",
      "Epoch 25/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0425 - acc: 0.0026\n",
      "Epoch 26/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 15.9908 - acc: 0.0017\n",
      "Epoch 27/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0222 - acc: 0.0024\n",
      "Epoch 28/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0392 - acc: 0.0019\n",
      "Epoch 29/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 15.9422 - acc: 0.0024\n",
      "Epoch 30/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0950 - acc: 0.0019\n",
      "Epoch 31/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0301 - acc: 0.0024\n",
      "Epoch 32/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0336 - acc: 0.0024\n",
      "Epoch 33/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0948 - acc: 0.0020\n",
      "Epoch 34/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0359 - acc: 0.0030\n",
      "Epoch 35/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0992 - acc: 0.0022\n",
      "Epoch 36/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0330 - acc: 0.0022\n",
      "Epoch 37/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 15.9843 - acc: 0.0024\n",
      "Epoch 38/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0310 - acc: 0.0015\n",
      "Epoch 39/100\n",
      "5390/5390 [==============================] - 0s 53us/step - loss: 16.0362 - acc: 0.0020\n",
      "Epoch 40/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0484 - acc: 0.0019\n",
      "Epoch 41/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0988 - acc: 0.0024\n",
      "Epoch 42/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 15.9482 - acc: 0.0022\n",
      "Epoch 43/100\n",
      "5390/5390 [==============================] - 0s 59us/step - loss: 16.0284 - acc: 0.0017\n",
      "Epoch 44/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0640 - acc: 0.0024\n",
      "Epoch 45/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0359 - acc: 0.0024\n",
      "Epoch 46/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 15.9965 - acc: 0.0020\n",
      "Epoch 47/100\n",
      "5390/5390 [==============================] - 0s 59us/step - loss: 16.0160 - acc: 0.0022\n",
      "Epoch 48/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0692 - acc: 0.0020\n",
      "Epoch 49/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0158 - acc: 0.0017\n",
      "Epoch 50/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0674 - acc: 0.0024\n",
      "Epoch 51/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0818 - acc: 0.0015\n",
      "Epoch 52/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0771 - acc: 0.0020\n",
      "Epoch 53/100\n",
      "5390/5390 [==============================] - 0s 64us/step - loss: 16.0672 - acc: 0.0011\n",
      "Epoch 54/100\n",
      "5390/5390 [==============================] - 0s 61us/step - loss: 15.9805 - acc: 0.0015\n",
      "Epoch 55/100\n",
      "5390/5390 [==============================] - 0s 54us/step - loss: 16.0569 - acc: 0.0024\n",
      "Epoch 56/100\n",
      "5390/5390 [==============================] - 0s 61us/step - loss: 16.0219 - acc: 0.0017\n",
      "Epoch 57/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0457 - acc: 0.0020\n",
      "Epoch 58/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0523 - acc: 0.0024\n",
      "Epoch 59/100\n",
      "5390/5390 [==============================] - 0s 60us/step - loss: 16.0326 - acc: 0.0026\n",
      "Epoch 60/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0615 - acc: 0.0020\n",
      "Epoch 61/100\n",
      "5390/5390 [==============================] - 0s 59us/step - loss: 16.0360 - acc: 0.0013\n",
      "Epoch 62/100\n",
      "5390/5390 [==============================] - 0s 54us/step - loss: 16.0131 - acc: 0.0024\n",
      "Epoch 63/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0167 - acc: 0.0024\n",
      "Epoch 64/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0050 - acc: 0.0022\n",
      "Epoch 65/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0067 - acc: 0.0024\n",
      "Epoch 66/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0169 - acc: 0.0032\n",
      "Epoch 67/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0557 - acc: 0.0019\n",
      "Epoch 68/100\n",
      "5390/5390 [==============================] - 0s 54us/step - loss: 16.0432 - acc: 0.0022\n",
      "Epoch 69/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 15.9827 - acc: 0.0017\n",
      "Epoch 70/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0191 - acc: 0.0019\n",
      "Epoch 71/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0281 - acc: 0.0013\n",
      "Epoch 72/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0554 - acc: 0.0013\n",
      "Epoch 73/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 15.9777 - acc: 0.0024\n",
      "Epoch 74/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0560 - acc: 0.0017\n",
      "Epoch 75/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 16.0607 - acc: 0.0028\n",
      "Epoch 76/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 15.9591 - acc: 0.0024\n",
      "Epoch 77/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0105 - acc: 0.0013\n",
      "Epoch 78/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0613 - acc: 0.0028\n",
      "Epoch 79/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 15.9972 - acc: 0.0017\n",
      "Epoch 80/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0360 - acc: 0.0022\n",
      "Epoch 81/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 15.9938 - acc: 0.0020\n",
      "Epoch 82/100\n",
      "5390/5390 [==============================] - 0s 59us/step - loss: 16.0885 - acc: 0.0013\n",
      "Epoch 83/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0373 - acc: 0.0019\n",
      "Epoch 84/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0743 - acc: 0.0022\n",
      "Epoch 85/100\n",
      "5390/5390 [==============================] - 0s 59us/step - loss: 15.9800 - acc: 0.0020\n",
      "Epoch 86/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 15.9726 - acc: 0.0019\n",
      "Epoch 87/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0122 - acc: 0.0019\n",
      "Epoch 88/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.1050 - acc: 0.0022\n",
      "Epoch 89/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0220 - acc: 0.0020\n",
      "Epoch 90/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0294 - acc: 0.0017\n",
      "Epoch 91/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0591 - acc: 0.0028\n",
      "Epoch 92/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 15.9878 - acc: 0.0022\n",
      "Epoch 93/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0530 - acc: 0.0015\n",
      "Epoch 94/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0418 - acc: 0.0024\n",
      "Epoch 95/100\n",
      "5390/5390 [==============================] - 0s 56us/step - loss: 15.9851 - acc: 0.0022\n",
      "Epoch 96/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0201 - acc: 0.0019\n",
      "Epoch 97/100\n",
      "5390/5390 [==============================] - 0s 57us/step - loss: 16.0422 - acc: 0.0019\n",
      "Epoch 98/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 16.0783 - acc: 0.0024\n",
      "Epoch 99/100\n",
      "5390/5390 [==============================] - 0s 58us/step - loss: 16.0511 - acc: 0.0020\n",
      "Epoch 100/100\n",
      "5390/5390 [==============================] - 0s 55us/step - loss: 15.9858 - acc: 0.0013\n",
      "172/172 [==============================] - 0s 91us/step\n",
      "Epoch 1/100\n",
      "3330/5562 [================>.............] - ETA: 0s - loss: 16.2424 - acc: 0.0030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1560 - acc: 0.0023\n",
      "Epoch 2/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.2072 - acc: 0.0027\n",
      "Epoch 3/100\n",
      "5562/5562 [==============================] - 0s 53us/step - loss: 16.1946 - acc: 0.0020\n",
      "Epoch 4/100\n",
      "5562/5562 [==============================] - 0s 59us/step - loss: 16.2103 - acc: 0.0020\n",
      "Epoch 5/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1555 - acc: 0.0029\n",
      "Epoch 6/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1618 - acc: 0.0022\n",
      "Epoch 7/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1819 - acc: 0.0023\n",
      "Epoch 8/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1680 - acc: 0.0022\n",
      "Epoch 9/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.0896 - acc: 0.0023\n",
      "Epoch 10/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.1966 - acc: 0.0020\n",
      "Epoch 11/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.1777 - acc: 0.0027\n",
      "Epoch 12/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1114 - acc: 0.0023\n",
      "Epoch 13/100\n",
      "5562/5562 [==============================] - 0s 55us/step - loss: 16.1957 - acc: 0.0018\n",
      "Epoch 14/100\n",
      "5562/5562 [==============================] - 0s 59us/step - loss: 16.1282 - acc: 0.0023\n",
      "Epoch 15/100\n",
      "5562/5562 [==============================] - 0s 59us/step - loss: 16.1607 - acc: 0.0023\n",
      "Epoch 16/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1449 - acc: 0.0025\n",
      "Epoch 17/100\n",
      "5562/5562 [==============================] - 0s 55us/step - loss: 16.1215 - acc: 0.0020\n",
      "Epoch 18/100\n",
      "5562/5562 [==============================] - 0s 59us/step - loss: 16.1344 - acc: 0.0018\n",
      "Epoch 19/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1937 - acc: 0.0023\n",
      "Epoch 20/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.2035 - acc: 0.0022\n",
      "Epoch 21/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1567 - acc: 0.0018\n",
      "Epoch 22/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1201 - acc: 0.0020\n",
      "Epoch 23/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1074 - acc: 0.0025\n",
      "Epoch 24/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1856 - acc: 0.0020\n",
      "Epoch 25/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1340 - acc: 0.0022\n",
      "Epoch 26/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.1783 - acc: 0.0025\n",
      "Epoch 27/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1169 - acc: 0.0020\n",
      "Epoch 28/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1722 - acc: 0.0016\n",
      "Epoch 29/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0799 - acc: 0.0025\n",
      "Epoch 30/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1414 - acc: 0.0027\n",
      "Epoch 31/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1404 - acc: 0.0022\n",
      "Epoch 32/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1779 - acc: 0.0023\n",
      "Epoch 33/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1058 - acc: 0.0023\n",
      "Epoch 34/100\n",
      "5562/5562 [==============================] - 0s 53us/step - loss: 16.1556 - acc: 0.0020\n",
      "Epoch 35/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1838 - acc: 0.0023\n",
      "Epoch 36/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1289 - acc: 0.0018\n",
      "Epoch 37/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1311 - acc: 0.0025\n",
      "Epoch 38/100\n",
      "5562/5562 [==============================] - 0s 53us/step - loss: 16.1464 - acc: 0.0032\n",
      "Epoch 39/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.1708 - acc: 0.0018\n",
      "Epoch 40/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1174 - acc: 0.0025\n",
      "Epoch 41/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.0926 - acc: 0.0029\n",
      "Epoch 42/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.1873 - acc: 0.0022\n",
      "Epoch 43/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1477 - acc: 0.0025\n",
      "Epoch 44/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1149 - acc: 0.0025\n",
      "Epoch 45/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1561 - acc: 0.0022\n",
      "Epoch 46/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1287 - acc: 0.0029\n",
      "Epoch 47/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0632 - acc: 0.0023\n",
      "Epoch 48/100\n",
      "5562/5562 [==============================] - 0s 55us/step - loss: 16.1563 - acc: 0.0023\n",
      "Epoch 49/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1477 - acc: 0.0029\n",
      "Epoch 50/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1034 - acc: 0.0031\n",
      "Epoch 51/100\n",
      "5562/5562 [==============================] - 0s 59us/step - loss: 16.1224 - acc: 0.0025\n",
      "Epoch 52/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1337 - acc: 0.0023\n",
      "Epoch 53/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1978 - acc: 0.0023\n",
      "Epoch 54/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.1260 - acc: 0.0023\n",
      "Epoch 55/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1394 - acc: 0.0020\n",
      "Epoch 56/100\n",
      "5562/5562 [==============================] - 0s 53us/step - loss: 16.0865 - acc: 0.0018\n",
      "Epoch 57/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1160 - acc: 0.0018\n",
      "Epoch 58/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1407 - acc: 0.0025\n",
      "Epoch 59/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0340 - acc: 0.0027\n",
      "Epoch 60/100\n",
      "5562/5562 [==============================] - 0s 54us/step - loss: 16.1735 - acc: 0.0022\n",
      "Epoch 61/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0664 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1072 - acc: 0.0025\n",
      "Epoch 63/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.0711 - acc: 0.0013\n",
      "Epoch 64/100\n",
      "5562/5562 [==============================] - 0s 59us/step - loss: 16.1983 - acc: 0.0031\n",
      "Epoch 65/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0934 - acc: 0.0018\n",
      "Epoch 66/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1351 - acc: 0.0022\n",
      "Epoch 67/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1248 - acc: 0.0020\n",
      "Epoch 68/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1240 - acc: 0.0027\n",
      "Epoch 69/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1143 - acc: 0.0022\n",
      "Epoch 70/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1171 - acc: 0.0027\n",
      "Epoch 71/100\n",
      "5562/5562 [==============================] - 0s 59us/step - loss: 16.0851 - acc: 0.0029\n",
      "Epoch 72/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1414 - acc: 0.0023\n",
      "Epoch 73/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1053 - acc: 0.0023\n",
      "Epoch 74/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1393 - acc: 0.0018\n",
      "Epoch 75/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1624 - acc: 0.0022\n",
      "Epoch 76/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.2161 - acc: 0.0014\n",
      "Epoch 77/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1119 - acc: 0.0022\n",
      "Epoch 78/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1954 - acc: 0.0020\n",
      "Epoch 79/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1523 - acc: 0.0022\n",
      "Epoch 80/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1131 - acc: 0.0029\n",
      "Epoch 81/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.0989 - acc: 0.0029\n",
      "Epoch 82/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1236 - acc: 0.0023\n",
      "Epoch 83/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0999 - acc: 0.0018\n",
      "Epoch 84/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.0540 - acc: 0.0025\n",
      "Epoch 85/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.2367 - acc: 0.0020\n",
      "Epoch 86/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0734 - acc: 0.0027\n",
      "Epoch 87/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1244 - acc: 0.0018\n",
      "Epoch 88/100\n",
      "5562/5562 [==============================] - 0s 54us/step - loss: 16.1292 - acc: 0.0027\n",
      "Epoch 89/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0682 - acc: 0.0022\n",
      "Epoch 90/100\n",
      "5562/5562 [==============================] - 0s 59us/step - loss: 16.1340 - acc: 0.0025\n",
      "Epoch 91/100\n",
      "5562/5562 [==============================] - 0s 53us/step - loss: 16.1128 - acc: 0.0025\n",
      "Epoch 92/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.1331 - acc: 0.0023\n",
      "Epoch 93/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.1277 - acc: 0.0011\n",
      "Epoch 94/100\n",
      "5562/5562 [==============================] - 0s 56us/step - loss: 16.0725 - acc: 0.0018\n",
      "Epoch 95/100\n",
      "5562/5562 [==============================] - 0s 54us/step - loss: 16.0991 - acc: 0.0020\n",
      "Epoch 96/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1342 - acc: 0.0027\n",
      "Epoch 97/100\n",
      "5562/5562 [==============================] - 0s 58us/step - loss: 16.1959 - acc: 0.0023\n",
      "Epoch 98/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1135 - acc: 0.0023\n",
      "Epoch 99/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.1933 - acc: 0.0018\n",
      "Epoch 100/100\n",
      "5562/5562 [==============================] - 0s 57us/step - loss: 16.0864 - acc: 0.0023\n",
      "172/172 [==============================] - 0s 0us/step\n",
      "Epoch 1/100\n",
      "3350/5734 [================>.............] - ETA: 0s - loss: 16.5775 - acc: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5734/5734 [==============================] - 0s 55us/step - loss: 16.1367 - acc: 0.0024\n",
      "Epoch 2/100\n",
      "5734/5734 [==============================] - 0s 55us/step - loss: 16.1345 - acc: 0.0019\n",
      "Epoch 3/100\n",
      "5734/5734 [==============================] - 0s 58us/step - loss: 16.1234 - acc: 0.0019\n",
      "Epoch 4/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0954 - acc: 0.0014\n",
      "Epoch 5/100\n",
      "5734/5734 [==============================] - 0s 53us/step - loss: 16.1070 - acc: 0.0010\n",
      "Epoch 6/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.1589 - acc: 0.0017\n",
      "Epoch 7/100\n",
      "5734/5734 [==============================] - 0s 54us/step - loss: 16.0994 - acc: 0.0031\n",
      "Epoch 8/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0846 - acc: 0.0026\n",
      "Epoch 9/100\n",
      "5734/5734 [==============================] - 0s 56us/step - loss: 16.1161 - acc: 0.0016\n",
      "Epoch 10/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0481 - acc: 0.0019\n",
      "Epoch 11/100\n",
      "5734/5734 [==============================] - 0s 56us/step - loss: 16.0875 - acc: 0.0010\n",
      "Epoch 12/100\n",
      "5734/5734 [==============================] - 0s 58us/step - loss: 16.1002 - acc: 0.0021\n",
      "Epoch 13/100\n",
      "5734/5734 [==============================] - 0s 54us/step - loss: 16.0528 - acc: 0.0017\n",
      "Epoch 14/100\n",
      "5734/5734 [==============================] - 0s 56us/step - loss: 16.0602 - acc: 0.0023\n",
      "Epoch 15/100\n",
      "5734/5734 [==============================] - 0s 59us/step - loss: 16.1229 - acc: 0.0010\n",
      "Epoch 16/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.1186 - acc: 0.0026\n",
      "Epoch 17/100\n",
      "5734/5734 [==============================] - 0s 56us/step - loss: 16.1011 - acc: 0.0014\n",
      "Epoch 18/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.1205 - acc: 0.0023\n",
      "Epoch 19/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.1113 - acc: 0.0017\n",
      "Epoch 20/100\n",
      "5734/5734 [==============================] - 0s 55us/step - loss: 16.0677 - acc: 0.0017\n",
      "Epoch 21/100\n",
      "5734/5734 [==============================] - 0s 58us/step - loss: 16.1178 - acc: 0.0021\n",
      "Epoch 22/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.1018 - acc: 0.0021\n",
      "Epoch 23/100\n",
      "5734/5734 [==============================] - 0s 56us/step - loss: 16.0713 - acc: 0.0019\n",
      "Epoch 24/100\n",
      "5734/5734 [==============================] - 0s 56us/step - loss: 16.0884 - acc: 0.0023\n",
      "Epoch 25/100\n",
      "5734/5734 [==============================] - 0s 54us/step - loss: 16.0676 - acc: 0.0010\n",
      "Epoch 26/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0623 - acc: 0.0019\n",
      "Epoch 27/100\n",
      "5734/5734 [==============================] - 0s 56us/step - loss: 16.1283 - acc: 0.0021\n",
      "Epoch 28/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0426 - acc: 0.0026\n",
      "Epoch 29/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0879 - acc: 0.0016\n",
      "Epoch 30/100\n",
      "5734/5734 [==============================] - 0s 54us/step - loss: 16.1025 - acc: 0.0023\n",
      "Epoch 31/100\n",
      "5734/5734 [==============================] - 0s 59us/step - loss: 16.0839 - acc: 0.0021\n",
      "Epoch 32/100\n",
      "5734/5734 [==============================] - 0s 54us/step - loss: 16.0672 - acc: 0.0019\n",
      "Epoch 33/100\n",
      "5734/5734 [==============================] - 0s 55us/step - loss: 16.0641 - acc: 0.0017\n",
      "Epoch 34/100\n",
      "5734/5734 [==============================] - 0s 60us/step - loss: 16.1010 - acc: 0.0024\n",
      "Epoch 35/100\n",
      "5734/5734 [==============================] - 0s 54us/step - loss: 16.1012 - acc: 0.0017\n",
      "Epoch 36/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.1314 - acc: 0.0021\n",
      "Epoch 37/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0830 - acc: 0.0021\n",
      "Epoch 38/100\n",
      "5734/5734 [==============================] - 0s 68us/step - loss: 16.0859 - acc: 0.0021\n",
      "Epoch 39/100\n",
      "5734/5734 [==============================] - 0s 85us/step - loss: 16.1503 - acc: 0.0023\n",
      "Epoch 40/100\n",
      "5734/5734 [==============================] - 0s 72us/step - loss: 16.1118 - acc: 0.0024\n",
      "Epoch 41/100\n",
      "5734/5734 [==============================] - 0s 58us/step - loss: 16.0629 - acc: 0.0017\n",
      "Epoch 42/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0961 - acc: 0.0016\n",
      "Epoch 43/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0142 - acc: 0.0019\n",
      "Epoch 44/100\n",
      "5734/5734 [==============================] - 0s 54us/step - loss: 16.0855 - acc: 0.0017\n",
      "Epoch 45/100\n",
      "5734/5734 [==============================] - 0s 59us/step - loss: 16.0554 - acc: 0.0023\n",
      "Epoch 46/100\n",
      "5734/5734 [==============================] - 0s 59us/step - loss: 16.0672 - acc: 0.0023\n",
      "Epoch 47/100\n",
      "5734/5734 [==============================] - 0s 55us/step - loss: 16.0505 - acc: 0.0017\n",
      "Epoch 48/100\n",
      "5734/5734 [==============================] - 0s 58us/step - loss: 16.0940 - acc: 0.0026\n",
      "Epoch 49/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.1097 - acc: 0.0021\n",
      "Epoch 50/100\n",
      "5734/5734 [==============================] - 0s 57us/step - loss: 16.0644 - acc: 0.0017\n",
      "Epoch 51/100\n",
      "5734/5734 [==============================] - 0s 63us/step - loss: 16.0728 - acc: 0.0023\n",
      "Epoch 52/100\n",
      "5734/5734 [==============================] - 0s 79us/step - loss: 16.0701 - acc: 0.0016\n",
      "Epoch 53/100\n",
      "5734/5734 [==============================] - 0s 81us/step - loss: 16.0611 - acc: 0.0028\n",
      "Epoch 54/100\n",
      "5734/5734 [==============================] - 0s 78us/step - loss: 16.0779 - acc: 0.0026\n",
      "Epoch 55/100\n",
      "5734/5734 [==============================] - 0s 70us/step - loss: 16.1260 - acc: 0.0024\n",
      "Epoch 56/100\n",
      "5734/5734 [==============================] - 0s 75us/step - loss: 16.1687 - acc: 0.0021\n",
      "Epoch 57/100\n",
      "5734/5734 [==============================] - 0s 80us/step - loss: 16.0540 - acc: 0.0012\n",
      "Epoch 58/100\n",
      "5734/5734 [==============================] - 1s 94us/step - loss: 16.0419 - acc: 0.0033\n",
      "Epoch 59/100\n",
      "5734/5734 [==============================] - 0s 79us/step - loss: 16.1458 - acc: 0.0023\n",
      "Epoch 60/100\n",
      "5734/5734 [==============================] - 0s 78us/step - loss: 16.0194 - acc: 0.0019\n",
      "Epoch 61/100\n",
      "5734/5734 [==============================] - 0s 75us/step - loss: 16.0660 - acc: 0.0016\n",
      "Epoch 62/100\n",
      "5734/5734 [==============================] - 0s 77us/step - loss: 16.0766 - acc: 0.0028\n",
      "Epoch 63/100\n",
      "5734/5734 [==============================] - 0s 76us/step - loss: 16.0737 - acc: 0.0021\n",
      "Epoch 64/100\n",
      "5734/5734 [==============================] - 0s 76us/step - loss: 16.0854 - acc: 0.0019\n",
      "Epoch 65/100\n",
      "5734/5734 [==============================] - 0s 77us/step - loss: 16.0174 - acc: 0.0019\n",
      "Epoch 66/100\n",
      "5734/5734 [==============================] - 0s 79us/step - loss: 16.0047 - acc: 0.0026\n",
      "Epoch 67/100\n",
      "5734/5734 [==============================] - 1s 90us/step - loss: 16.0795 - acc: 0.0024\n",
      "Epoch 68/100\n",
      "5734/5734 [==============================] - 0s 73us/step - loss: 16.0548 - acc: 0.0021\n",
      "Epoch 69/100\n",
      "5734/5734 [==============================] - 0s 78us/step - loss: 16.0691 - acc: 0.0023\n",
      "Epoch 70/100\n",
      "5734/5734 [==============================] - 0s 75us/step - loss: 16.0618 - acc: 0.0019\n",
      "Epoch 71/100\n",
      "5734/5734 [==============================] - 0s 76us/step - loss: 16.0141 - acc: 0.0023\n",
      "Epoch 72/100\n",
      "5734/5734 [==============================] - 0s 77us/step - loss: 16.0150 - acc: 0.0028\n",
      "Epoch 73/100\n",
      "5734/5734 [==============================] - 0s 76us/step - loss: 16.0783 - acc: 0.0026\n",
      "Epoch 74/100\n",
      "5734/5734 [==============================] - 0s 76us/step - loss: 16.0585 - acc: 0.0024\n",
      "Epoch 75/100\n",
      "5734/5734 [==============================] - 0s 74us/step - loss: 16.0571 - acc: 0.0023\n",
      "Epoch 76/100\n",
      "5734/5734 [==============================] - 0s 77us/step - loss: 16.0573 - acc: 0.0023\n",
      "Epoch 77/100\n",
      "5734/5734 [==============================] - 0s 74us/step - loss: 16.0264 - acc: 0.0016\n",
      "Epoch 78/100\n",
      "5734/5734 [==============================] - 0s 77us/step - loss: 16.0829 - acc: 0.0024\n",
      "Epoch 79/100\n",
      "5734/5734 [==============================] - 0s 80us/step - loss: 16.0621 - acc: 0.0026\n",
      "Epoch 80/100\n",
      "5734/5734 [==============================] - 0s 76us/step - loss: 16.0643 - acc: 0.0028\n",
      "Epoch 81/100\n",
      "5734/5734 [==============================] - 0s 78us/step - loss: 16.0820 - acc: 0.0010\n",
      "Epoch 82/100\n",
      "5734/5734 [==============================] - 0s 73us/step - loss: 16.0481 - acc: 0.0024\n",
      "Epoch 83/100\n",
      "5734/5734 [==============================] - 0s 70us/step - loss: 16.0561 - acc: 0.0021\n",
      "Epoch 84/100\n",
      "5734/5734 [==============================] - 0s 69us/step - loss: 16.0589 - acc: 0.0021\n",
      "Epoch 85/100\n",
      "5734/5734 [==============================] - 0s 71us/step - loss: 16.0313 - acc: 0.0024\n",
      "Epoch 86/100\n",
      "5734/5734 [==============================] - 0s 70us/step - loss: 16.0271 - acc: 0.0019\n",
      "Epoch 87/100\n",
      "5734/5734 [==============================] - 0s 69us/step - loss: 16.0299 - acc: 0.0021\n",
      "Epoch 88/100\n",
      "5734/5734 [==============================] - 0s 75us/step - loss: 16.1032 - acc: 0.0019\n",
      "Epoch 89/100\n",
      "5734/5734 [==============================] - 0s 70us/step - loss: 16.0747 - acc: 0.0021\n",
      "Epoch 90/100\n",
      "5734/5734 [==============================] - 0s 71us/step - loss: 16.0715 - acc: 0.0026\n",
      "Epoch 91/100\n",
      "5734/5734 [==============================] - 0s 72us/step - loss: 16.0027 - acc: 0.0014\n",
      "Epoch 92/100\n",
      "5734/5734 [==============================] - 0s 73us/step - loss: 16.0092 - acc: 0.0024\n",
      "Epoch 93/100\n",
      "5734/5734 [==============================] - 0s 71us/step - loss: 16.0925 - acc: 0.0023\n",
      "Epoch 94/100\n",
      "5734/5734 [==============================] - 0s 70us/step - loss: 16.0434 - acc: 0.0012\n",
      "Epoch 95/100\n",
      "5734/5734 [==============================] - 0s 73us/step - loss: 16.0421 - acc: 0.0021\n",
      "Epoch 96/100\n",
      "5734/5734 [==============================] - 0s 70us/step - loss: 16.0459 - acc: 0.0024\n",
      "Epoch 97/100\n",
      "5734/5734 [==============================] - 0s 71us/step - loss: 16.0978 - acc: 0.0017\n",
      "Epoch 98/100\n",
      "5734/5734 [==============================] - 0s 72us/step - loss: 16.0239 - acc: 0.0031\n",
      "Epoch 99/100\n",
      "5734/5734 [==============================] - 0s 71us/step - loss: 16.0355 - acc: 0.0030\n",
      "Epoch 100/100\n",
      "5734/5734 [==============================] - 0s 73us/step - loss: 16.0672 - acc: 0.0023\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "1930/5906 [========>.....................] - ETA: 0s - loss: 16.5945 - acc: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5906/5906 [==============================] - 1s 89us/step - loss: 16.3860 - acc: 0.0019\n",
      "Epoch 2/100\n",
      "5906/5906 [==============================] - 1s 86us/step - loss: 16.4060 - acc: 0.0025\n",
      "Epoch 3/100\n",
      "5906/5906 [==============================] - 0s 77us/step - loss: 16.4044 - acc: 0.0012\n",
      "Epoch 4/100\n",
      "5906/5906 [==============================] - 0s 77us/step - loss: 16.4076 - acc: 0.0019\n",
      "Epoch 5/100\n",
      "5906/5906 [==============================] - 0s 74us/step - loss: 16.4066 - acc: 0.0020\n",
      "Epoch 6/100\n",
      "5906/5906 [==============================] - 1s 89us/step - loss: 16.3908 - acc: 0.0020\n",
      "Epoch 7/100\n",
      "5906/5906 [==============================] - 0s 83us/step - loss: 16.4149 - acc: 0.0015\n",
      "Epoch 8/100\n",
      "5906/5906 [==============================] - 1s 89us/step - loss: 16.3841 - acc: 0.0022\n",
      "Epoch 9/100\n",
      "5906/5906 [==============================] - 0s 70us/step - loss: 16.4229 - acc: 0.0019\n",
      "Epoch 10/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.4154 - acc: 0.0024\n",
      "Epoch 11/100\n",
      "5906/5906 [==============================] - 0s 69us/step - loss: 16.3331 - acc: 0.0025\n",
      "Epoch 12/100\n",
      "5906/5906 [==============================] - 0s 70us/step - loss: 16.4035 - acc: 0.0019\n",
      "Epoch 13/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3311 - acc: 0.0019\n",
      "Epoch 14/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.4122 - acc: 0.0019\n",
      "Epoch 15/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.4210 - acc: 0.0024\n",
      "Epoch 16/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.3755 - acc: 0.0015\n",
      "Epoch 17/100\n",
      "5906/5906 [==============================] - 1s 93us/step - loss: 16.4371 - acc: 0.0015ETA: 0s - loss: 16.32\n",
      "Epoch 18/100\n",
      "5906/5906 [==============================] - 1s 90us/step - loss: 16.3197 - acc: 0.0029\n",
      "Epoch 19/100\n",
      "5906/5906 [==============================] - 0s 81us/step - loss: 16.3296 - acc: 0.0027\n",
      "Epoch 20/100\n",
      "5906/5906 [==============================] - 0s 84us/step - loss: 16.4099 - acc: 0.0022\n",
      "Epoch 21/100\n",
      "5906/5906 [==============================] - 1s 92us/step - loss: 16.3528 - acc: 0.0020\n",
      "Epoch 22/100\n",
      "5906/5906 [==============================] - 1s 95us/step - loss: 16.2810 - acc: 0.0024\n",
      "Epoch 23/100\n",
      "5906/5906 [==============================] - 0s 81us/step - loss: 16.4119 - acc: 0.0015\n",
      "Epoch 24/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3361 - acc: 0.0027\n",
      "Epoch 25/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.3796 - acc: 0.0029\n",
      "Epoch 26/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3630 - acc: 0.0019\n",
      "Epoch 27/100\n",
      "5906/5906 [==============================] - 0s 81us/step - loss: 16.3769 - acc: 0.0029\n",
      "Epoch 28/100\n",
      "5906/5906 [==============================] - 0s 74us/step - loss: 16.3386 - acc: 0.0022\n",
      "Epoch 29/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3409 - acc: 0.0025\n",
      "Epoch 30/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.3800 - acc: 0.0020\n",
      "Epoch 31/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3186 - acc: 0.0017\n",
      "Epoch 32/100\n",
      "5906/5906 [==============================] - 1s 91us/step - loss: 16.3859 - acc: 0.0022\n",
      "Epoch 33/100\n",
      "5906/5906 [==============================] - 0s 77us/step - loss: 16.3184 - acc: 0.0019\n",
      "Epoch 34/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.4015 - acc: 0.0025\n",
      "Epoch 35/100\n",
      "5906/5906 [==============================] - 1s 88us/step - loss: 16.3417 - acc: 0.0022\n",
      "Epoch 36/100\n",
      "5906/5906 [==============================] - 0s 83us/step - loss: 16.3704 - acc: 0.0015\n",
      "Epoch 37/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.3984 - acc: 0.0022\n",
      "Epoch 38/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.3561 - acc: 0.0017\n",
      "Epoch 39/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.4118 - acc: 0.0019\n",
      "Epoch 40/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.4036 - acc: 0.0022\n",
      "Epoch 41/100\n",
      "5906/5906 [==============================] - 0s 74us/step - loss: 16.3408 - acc: 0.0027\n",
      "Epoch 42/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.3506 - acc: 0.0017\n",
      "Epoch 43/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.3948 - acc: 0.0017\n",
      "Epoch 44/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.2969 - acc: 0.0024\n",
      "Epoch 45/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.3288 - acc: 0.0032\n",
      "Epoch 46/100\n",
      "5906/5906 [==============================] - 0s 74us/step - loss: 16.3595 - acc: 0.0020\n",
      "Epoch 47/100\n",
      "5906/5906 [==============================] - 1s 88us/step - loss: 16.3743 - acc: 0.0022\n",
      "Epoch 48/100\n",
      "5906/5906 [==============================] - 1s 85us/step - loss: 16.3359 - acc: 0.0025\n",
      "Epoch 49/100\n",
      "5906/5906 [==============================] - 0s 84us/step - loss: 16.3444 - acc: 0.0017\n",
      "Epoch 50/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3233 - acc: 0.0020\n",
      "Epoch 51/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.3281 - acc: 0.0022\n",
      "Epoch 52/100\n",
      "5906/5906 [==============================] - 0s 76us/step - loss: 16.3679 - acc: 0.0019\n",
      "Epoch 53/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3718 - acc: 0.0020\n",
      "Epoch 54/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.2798 - acc: 0.0017\n",
      "Epoch 55/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.3287 - acc: 0.0019\n",
      "Epoch 56/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.3158 - acc: 0.0017\n",
      "Epoch 57/100\n",
      "5906/5906 [==============================] - 0s 76us/step - loss: 16.3575 - acc: 0.0022 0s - loss: 16.6786 - a\n",
      "Epoch 58/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.3774 - acc: 0.0024\n",
      "Epoch 59/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.3714 - acc: 0.0014\n",
      "Epoch 60/100\n",
      "5906/5906 [==============================] - 0s 74us/step - loss: 16.2910 - acc: 0.0017\n",
      "Epoch 61/100\n",
      "5906/5906 [==============================] - 0s 80us/step - loss: 16.3354 - acc: 0.0027\n",
      "Epoch 62/100\n",
      "5906/5906 [==============================] - 0s 74us/step - loss: 16.3042 - acc: 0.0022\n",
      "Epoch 63/100\n",
      "5906/5906 [==============================] - 0s 76us/step - loss: 16.3520 - acc: 0.0020\n",
      "Epoch 64/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.3017 - acc: 0.0015\n",
      "Epoch 65/100\n",
      "5906/5906 [==============================] - 0s 79us/step - loss: 16.3294 - acc: 0.0020\n",
      "Epoch 66/100\n",
      "5906/5906 [==============================] - 0s 74us/step - loss: 16.3477 - acc: 0.0024\n",
      "Epoch 67/100\n",
      "5906/5906 [==============================] - 0s 77us/step - loss: 16.3524 - acc: 0.0020\n",
      "Epoch 68/100\n",
      "5906/5906 [==============================] - 0s 79us/step - loss: 16.2895 - acc: 0.0022\n",
      "Epoch 69/100\n",
      "5906/5906 [==============================] - 0s 76us/step - loss: 16.3707 - acc: 0.0024\n",
      "Epoch 70/100\n",
      "5906/5906 [==============================] - 0s 77us/step - loss: 16.3157 - acc: 0.0017\n",
      "Epoch 71/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.3029 - acc: 0.0020\n",
      "Epoch 72/100\n",
      "5906/5906 [==============================] - 0s 77us/step - loss: 16.3606 - acc: 0.0017\n",
      "Epoch 73/100\n",
      "5906/5906 [==============================] - 0s 75us/step - loss: 16.3803 - acc: 0.0024\n",
      "Epoch 74/100\n",
      "5906/5906 [==============================] - 0s 77us/step - loss: 16.3990 - acc: 0.0029\n",
      "Epoch 75/100\n",
      "5906/5906 [==============================] - 0s 74us/step - loss: 16.4183 - acc: 0.0019\n",
      "Epoch 76/100\n",
      "5906/5906 [==============================] - 0s 78us/step - loss: 16.3375 - acc: 0.0020\n",
      "Epoch 77/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.3424 - acc: 0.0024\n",
      "Epoch 78/100\n",
      "5906/5906 [==============================] - 0s 78us/step - loss: 16.2823 - acc: 0.0020\n",
      "Epoch 79/100\n",
      "5906/5906 [==============================] - 0s 81us/step - loss: 16.3162 - acc: 0.0019\n",
      "Epoch 80/100\n",
      "5906/5906 [==============================] - 1s 97us/step - loss: 16.3042 - acc: 0.0019\n",
      "Epoch 81/100\n",
      "5906/5906 [==============================] - 1s 122us/step - loss: 16.3558 - acc: 0.0020\n",
      "Epoch 82/100\n",
      "5906/5906 [==============================] - 1s 89us/step - loss: 16.3218 - acc: 0.0022\n",
      "Epoch 83/100\n",
      "5906/5906 [==============================] - 0s 78us/step - loss: 16.3869 - acc: 0.0029\n",
      "Epoch 84/100\n",
      "5906/5906 [==============================] - 0s 73us/step - loss: 16.3454 - acc: 0.0030\n",
      "Epoch 85/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.3126 - acc: 0.0020\n",
      "Epoch 86/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3785 - acc: 0.0024\n",
      "Epoch 87/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.3112 - acc: 0.0025\n",
      "Epoch 88/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3557 - acc: 0.0022\n",
      "Epoch 89/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.3305 - acc: 0.0024\n",
      "Epoch 90/100\n",
      "5906/5906 [==============================] - 0s 70us/step - loss: 16.3386 - acc: 0.0027\n",
      "Epoch 91/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.3923 - acc: 0.0022\n",
      "Epoch 92/100\n",
      "5906/5906 [==============================] - 0s 70us/step - loss: 16.3539 - acc: 0.0020\n",
      "Epoch 93/100\n",
      "5906/5906 [==============================] - 0s 71us/step - loss: 16.3515 - acc: 0.0015\n",
      "Epoch 94/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3379 - acc: 0.0015\n",
      "Epoch 95/100\n",
      "5906/5906 [==============================] - 0s 70us/step - loss: 16.3151 - acc: 0.0020\n",
      "Epoch 96/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.4192 - acc: 0.0017\n",
      "Epoch 97/100\n",
      "5906/5906 [==============================] - 0s 69us/step - loss: 16.3690 - acc: 0.0017\n",
      "Epoch 98/100\n",
      "5906/5906 [==============================] - 0s 77us/step - loss: 16.3588 - acc: 0.0019\n",
      "Epoch 99/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.3937 - acc: 0.0017\n",
      "Epoch 100/100\n",
      "5906/5906 [==============================] - 0s 72us/step - loss: 16.2684 - acc: 0.0024\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2760/6078 [============>.................] - ETA: 0s - loss: 16.6002 - acc: 7.2464e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6078/6078 [==============================] - 0s 76us/step - loss: 16.5539 - acc: 0.0018\n",
      "Epoch 2/100\n",
      "6078/6078 [==============================] - 0s 68us/step - loss: 16.5221 - acc: 0.0018\n",
      "Epoch 3/100\n",
      "6078/6078 [==============================] - 0s 77us/step - loss: 16.5304 - acc: 0.0026\n",
      "Epoch 4/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.4531 - acc: 0.0020\n",
      "Epoch 5/100\n",
      "6078/6078 [==============================] - 0s 70us/step - loss: 16.5169 - acc: 0.0031\n",
      "Epoch 6/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.4569 - acc: 0.0021\n",
      "Epoch 7/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.4785 - acc: 0.0021\n",
      "Epoch 8/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.4490 - acc: 0.0023\n",
      "Epoch 9/100\n",
      "6078/6078 [==============================] - 0s 70us/step - loss: 16.4780 - acc: 0.0021\n",
      "Epoch 10/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.4576 - acc: 0.0023\n",
      "Epoch 11/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.4155 - acc: 0.0023\n",
      "Epoch 12/100\n",
      "6078/6078 [==============================] - 0s 70us/step - loss: 16.4530 - acc: 0.0023\n",
      "Epoch 13/100\n",
      "6078/6078 [==============================] - 0s 70us/step - loss: 16.4341 - acc: 0.0015\n",
      "Epoch 14/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.4076 - acc: 0.0013\n",
      "Epoch 15/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3352 - acc: 0.0028\n",
      "Epoch 16/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.4614 - acc: 0.0025\n",
      "Epoch 17/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.4034 - acc: 0.0020\n",
      "Epoch 18/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.3795 - acc: 0.0021\n",
      "Epoch 19/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.4260 - acc: 0.0028\n",
      "Epoch 20/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3882 - acc: 0.0025\n",
      "Epoch 21/100\n",
      "6078/6078 [==============================] - 0s 80us/step - loss: 16.4517 - acc: 0.0023\n",
      "Epoch 22/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3670 - acc: 0.0026\n",
      "Epoch 23/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3618 - acc: 0.0028\n",
      "Epoch 24/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.3672 - acc: 0.0015\n",
      "Epoch 25/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3657 - acc: 0.0021\n",
      "Epoch 26/100\n",
      "6078/6078 [==============================] - 0s 79us/step - loss: 16.3299 - acc: 0.0028\n",
      "Epoch 27/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.3725 - acc: 0.0021\n",
      "Epoch 28/100\n",
      "6078/6078 [==============================] - 0s 76us/step - loss: 16.3753 - acc: 0.0025\n",
      "Epoch 29/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3606 - acc: 0.0023\n",
      "Epoch 30/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3703 - acc: 0.0025\n",
      "Epoch 31/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3760 - acc: 0.0026\n",
      "Epoch 32/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.4413 - acc: 0.0031\n",
      "Epoch 33/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.4000 - acc: 0.0025\n",
      "Epoch 34/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.3072 - acc: 0.0028\n",
      "Epoch 35/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.3857 - acc: 0.0018\n",
      "Epoch 36/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.3657 - acc: 0.0018\n",
      "Epoch 37/100\n",
      "6078/6078 [==============================] - 0s 77us/step - loss: 16.3597 - acc: 0.0028\n",
      "Epoch 38/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.2977 - acc: 0.0026\n",
      "Epoch 39/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.3695 - acc: 0.0020\n",
      "Epoch 40/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.4040 - acc: 0.0020\n",
      "Epoch 41/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3231 - acc: 0.0020\n",
      "Epoch 42/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.4165 - acc: 0.0021\n",
      "Epoch 43/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.3650 - acc: 0.0026\n",
      "Epoch 44/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.3715 - acc: 0.0028\n",
      "Epoch 45/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.3814 - acc: 0.0026\n",
      "Epoch 46/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3687 - acc: 0.0026\n",
      "Epoch 47/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.3264 - acc: 0.0021\n",
      "Epoch 48/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3393 - acc: 0.0028\n",
      "Epoch 49/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.3812 - acc: 0.0023\n",
      "Epoch 50/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3328 - acc: 0.0025\n",
      "Epoch 51/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.3547 - acc: 0.0021\n",
      "Epoch 52/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.4024 - acc: 0.0023\n",
      "Epoch 53/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.3197 - acc: 0.0026\n",
      "Epoch 54/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3715 - acc: 0.0021\n",
      "Epoch 55/100\n",
      "6078/6078 [==============================] - 0s 76us/step - loss: 16.3763 - acc: 0.0028\n",
      "Epoch 56/100\n",
      "6078/6078 [==============================] - 0s 77us/step - loss: 16.3567 - acc: 0.0023\n",
      "Epoch 57/100\n",
      "6078/6078 [==============================] - 1s 83us/step - loss: 16.3963 - acc: 0.0026\n",
      "Epoch 58/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.4040 - acc: 0.0023\n",
      "Epoch 59/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.4014 - acc: 0.0016\n",
      "Epoch 60/100\n",
      "6078/6078 [==============================] - 0s 77us/step - loss: 16.3683 - acc: 0.0023\n",
      "Epoch 61/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3672 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3640 - acc: 0.0016\n",
      "Epoch 63/100\n",
      "6078/6078 [==============================] - 0s 78us/step - loss: 16.3416 - acc: 0.0030\n",
      "Epoch 64/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.3136 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.2946 - acc: 0.0026\n",
      "Epoch 66/100\n",
      "6078/6078 [==============================] - 0s 81us/step - loss: 16.3517 - acc: 0.0021\n",
      "Epoch 67/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.2885 - acc: 0.0016\n",
      "Epoch 68/100\n",
      "6078/6078 [==============================] - 0s 78us/step - loss: 16.2732 - acc: 0.0028\n",
      "Epoch 69/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3395 - acc: 0.0025\n",
      "Epoch 70/100\n",
      "6078/6078 [==============================] - 0s 76us/step - loss: 16.3084 - acc: 0.0020\n",
      "Epoch 71/100\n",
      "6078/6078 [==============================] - 0s 76us/step - loss: 16.3374 - acc: 0.0028\n",
      "Epoch 72/100\n",
      "6078/6078 [==============================] - 0s 78us/step - loss: 16.3247 - acc: 0.0021\n",
      "Epoch 73/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.3627 - acc: 0.0026\n",
      "Epoch 74/100\n",
      "6078/6078 [==============================] - 1s 94us/step - loss: 16.2990 - acc: 0.0025\n",
      "Epoch 75/100\n",
      "6078/6078 [==============================] - 1s 91us/step - loss: 16.3830 - acc: 0.0018\n",
      "Epoch 76/100\n",
      "6078/6078 [==============================] - 1s 96us/step - loss: 16.3046 - acc: 0.0025\n",
      "Epoch 77/100\n",
      "6078/6078 [==============================] - 1s 82us/step - loss: 16.3536 - acc: 0.0018\n",
      "Epoch 78/100\n",
      "6078/6078 [==============================] - 1s 98us/step - loss: 16.3594 - acc: 0.0030\n",
      "Epoch 79/100\n",
      "6078/6078 [==============================] - 0s 81us/step - loss: 16.3841 - acc: 0.0023\n",
      "Epoch 80/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3007 - acc: 0.0026\n",
      "Epoch 81/100\n",
      "6078/6078 [==============================] - 0s 75us/step - loss: 16.3548 - acc: 0.0025\n",
      "Epoch 82/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.3756 - acc: 0.0025\n",
      "Epoch 83/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.3048 - acc: 0.0025\n",
      "Epoch 84/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3188 - acc: 0.0028\n",
      "Epoch 85/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.3421 - acc: 0.0021\n",
      "Epoch 86/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.3672 - acc: 0.0026\n",
      "Epoch 87/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.3031 - acc: 0.0021\n",
      "Epoch 88/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.3098 - acc: 0.0030\n",
      "Epoch 89/100\n",
      "6078/6078 [==============================] - 0s 71us/step - loss: 16.2969 - acc: 0.0021\n",
      "Epoch 90/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.3020 - acc: 0.0021\n",
      "Epoch 91/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3236 - acc: 0.0023\n",
      "Epoch 92/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.3586 - acc: 0.0018\n",
      "Epoch 93/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.2836 - acc: 0.0023\n",
      "Epoch 94/100\n",
      "6078/6078 [==============================] - 0s 69us/step - loss: 16.3062 - acc: 0.0025\n",
      "Epoch 95/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3746 - acc: 0.0021\n",
      "Epoch 96/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3091 - acc: 0.0021\n",
      "Epoch 97/100\n",
      "6078/6078 [==============================] - 0s 70us/step - loss: 16.3568 - acc: 0.0026\n",
      "Epoch 98/100\n",
      "6078/6078 [==============================] - 0s 74us/step - loss: 16.3648 - acc: 0.0023\n",
      "Epoch 99/100\n",
      "6078/6078 [==============================] - 0s 72us/step - loss: 16.3072 - acc: 0.0021\n",
      "Epoch 100/100\n",
      "6078/6078 [==============================] - 0s 73us/step - loss: 16.3716 - acc: 0.0028\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2340/6250 [==========>...................] - ETA: 0s - loss: 17.3717 - acc: 0.0026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.6540 - acc: 0.0027\n",
      "Epoch 2/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.6183 - acc: 0.0019\n",
      "Epoch 3/100\n",
      "6250/6250 [==============================] - 0s 67us/step - loss: 16.6194 - acc: 0.0035\n",
      "Epoch 4/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5871 - acc: 0.0026\n",
      "Epoch 5/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.4923 - acc: 0.0022\n",
      "Epoch 6/100\n",
      "6250/6250 [==============================] - 0s 70us/step - loss: 16.5234 - acc: 0.0029\n",
      "Epoch 7/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.5563 - acc: 0.0024\n",
      "Epoch 8/100\n",
      "6250/6250 [==============================] - 0s 70us/step - loss: 16.5168 - acc: 0.0029\n",
      "Epoch 9/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5704 - acc: 0.0022\n",
      "Epoch 10/100\n",
      "6250/6250 [==============================] - 0s 69us/step - loss: 16.6444 - acc: 0.0021\n",
      "Epoch 11/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5542 - acc: 0.0030\n",
      "Epoch 12/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.5333 - acc: 0.0029\n",
      "Epoch 13/100\n",
      "6250/6250 [==============================] - 0s 70us/step - loss: 16.5206 - acc: 0.0027\n",
      "Epoch 14/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.5362 - acc: 0.0019\n",
      "Epoch 15/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5200 - acc: 0.0027\n",
      "Epoch 16/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5912 - acc: 0.0016\n",
      "Epoch 17/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.5758 - acc: 0.0027\n",
      "Epoch 18/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.5268 - acc: 0.0026\n",
      "Epoch 19/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5185 - acc: 0.0026\n",
      "Epoch 20/100\n",
      "6250/6250 [==============================] - 0s 70us/step - loss: 16.4616 - acc: 0.0030\n",
      "Epoch 21/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5202 - acc: 0.0022\n",
      "Epoch 22/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.5723 - acc: 0.0022\n",
      "Epoch 23/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.5236 - acc: 0.0027\n",
      "Epoch 24/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5691 - acc: 0.0013\n",
      "Epoch 25/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.4908 - acc: 0.0024\n",
      "Epoch 26/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5596 - acc: 0.0027\n",
      "Epoch 27/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.5396 - acc: 0.0018\n",
      "Epoch 28/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.4986 - acc: 0.0026\n",
      "Epoch 29/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.5028 - acc: 0.0018\n",
      "Epoch 30/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5200 - acc: 0.0019\n",
      "Epoch 31/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.4754 - acc: 0.0019\n",
      "Epoch 32/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.5037 - acc: 0.0029\n",
      "Epoch 33/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5012 - acc: 0.0021\n",
      "Epoch 34/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.5543 - acc: 0.0024\n",
      "Epoch 35/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.4993 - acc: 0.0024\n",
      "Epoch 36/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.5112 - acc: 0.0027\n",
      "Epoch 37/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.4596 - acc: 0.0021\n",
      "Epoch 38/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5087 - acc: 0.0024\n",
      "Epoch 39/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.5253 - acc: 0.0021\n",
      "Epoch 40/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5520 - acc: 0.0021\n",
      "Epoch 41/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5046 - acc: 0.0024\n",
      "Epoch 42/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.5269 - acc: 0.0018\n",
      "Epoch 43/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.4986 - acc: 0.0026\n",
      "Epoch 44/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.4834 - acc: 0.0021\n",
      "Epoch 45/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.4721 - acc: 0.0034\n",
      "Epoch 46/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.5534 - acc: 0.0019\n",
      "Epoch 47/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.5575 - acc: 0.0034\n",
      "Epoch 48/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.4888 - acc: 0.0022\n",
      "Epoch 49/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5231 - acc: 0.0018\n",
      "Epoch 50/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.4734 - acc: 0.0029\n",
      "Epoch 51/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5121 - acc: 0.0019\n",
      "Epoch 52/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.4358 - acc: 0.0026\n",
      "Epoch 53/100\n",
      "6250/6250 [==============================] - 0s 79us/step - loss: 16.5024 - acc: 0.0021\n",
      "Epoch 54/100\n",
      "6250/6250 [==============================] - 0s 73us/step - loss: 16.4669 - acc: 0.0030\n",
      "Epoch 55/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.5070 - acc: 0.0030\n",
      "Epoch 56/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.4970 - acc: 0.0019\n",
      "Epoch 57/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.4674 - acc: 0.0027\n",
      "Epoch 58/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.5460 - acc: 0.0021\n",
      "Epoch 59/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.5130 - acc: 0.0024\n",
      "Epoch 60/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.5002 - acc: 0.0022\n",
      "Epoch 61/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.5295 - acc: 0.0021\n",
      "Epoch 62/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.5071 - acc: 0.0030\n",
      "Epoch 63/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.4693 - acc: 0.0019\n",
      "Epoch 64/100\n",
      "6250/6250 [==============================] - 0s 77us/step - loss: 16.5397 - acc: 0.0024\n",
      "Epoch 65/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.5063 - acc: 0.0022\n",
      "Epoch 66/100\n",
      "6250/6250 [==============================] - 0s 78us/step - loss: 16.4056 - acc: 0.0014\n",
      "Epoch 67/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.5247 - acc: 0.0026\n",
      "Epoch 68/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.4792 - acc: 0.0029\n",
      "Epoch 69/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.5547 - acc: 0.0018\n",
      "Epoch 70/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.5219 - acc: 0.0026\n",
      "Epoch 71/100\n",
      "6250/6250 [==============================] - 0s 74us/step - loss: 16.4444 - acc: 0.0027\n",
      "Epoch 72/100\n",
      "6250/6250 [==============================] - 0s 78us/step - loss: 16.4546 - acc: 0.0026\n",
      "Epoch 73/100\n",
      "6250/6250 [==============================] - 0s 75us/step - loss: 16.4694 - acc: 0.0021\n",
      "Epoch 74/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.5184 - acc: 0.0024\n",
      "Epoch 75/100\n",
      "6250/6250 [==============================] - 0s 77us/step - loss: 16.5004 - acc: 0.0019\n",
      "Epoch 76/100\n",
      "6250/6250 [==============================] - 0s 77us/step - loss: 16.4696 - acc: 0.0019\n",
      "Epoch 77/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.4701 - acc: 0.0021\n",
      "Epoch 78/100\n",
      "6250/6250 [==============================] - 0s 77us/step - loss: 16.5191 - acc: 0.0021\n",
      "Epoch 79/100\n",
      "6250/6250 [==============================] - 0s 79us/step - loss: 16.5303 - acc: 0.0019\n",
      "Epoch 80/100\n",
      "6250/6250 [==============================] - 0s 77us/step - loss: 16.4894 - acc: 0.0022\n",
      "Epoch 81/100\n",
      "6250/6250 [==============================] - 0s 76us/step - loss: 16.4423 - acc: 0.0021\n",
      "Epoch 82/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.5059 - acc: 0.0026\n",
      "Epoch 83/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.4449 - acc: 0.0024\n",
      "Epoch 84/100\n",
      "6250/6250 [==============================] - 0s 70us/step - loss: 16.4805 - acc: 0.0027\n",
      "Epoch 85/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.4664 - acc: 0.0022\n",
      "Epoch 86/100\n",
      "6250/6250 [==============================] - 0s 69us/step - loss: 16.5189 - acc: 0.0018\n",
      "Epoch 87/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.4142 - acc: 0.0027\n",
      "Epoch 88/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.5316 - acc: 0.0022\n",
      "Epoch 89/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.4561 - acc: 0.0027\n",
      "Epoch 90/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.4897 - acc: 0.0030\n",
      "Epoch 91/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.4938 - acc: 0.0022ETA: 0s - loss: 15.9916 - a\n",
      "Epoch 92/100\n",
      "6250/6250 [==============================] - 0s 79us/step - loss: 16.4698 - acc: 0.0024\n",
      "Epoch 93/100\n",
      "6250/6250 [==============================] - 0s 79us/step - loss: 16.5021 - acc: 0.0014\n",
      "Epoch 94/100\n",
      "6250/6250 [==============================] - 1s 89us/step - loss: 16.4509 - acc: 0.0018\n",
      "Epoch 95/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.4708 - acc: 0.0021\n",
      "Epoch 96/100\n",
      "6250/6250 [==============================] - 0s 72us/step - loss: 16.4604 - acc: 0.0024\n",
      "Epoch 97/100\n",
      "6250/6250 [==============================] - 0s 71us/step - loss: 16.4978 - acc: 0.0026\n",
      "Epoch 98/100\n",
      "6250/6250 [==============================] - 1s 92us/step - loss: 16.4524 - acc: 0.0034\n",
      "Epoch 99/100\n",
      "6250/6250 [==============================] - 1s 90us/step - loss: 16.4915 - acc: 0.0026\n",
      "Epoch 100/100\n",
      "6250/6250 [==============================] - 1s 84us/step - loss: 16.5088 - acc: 0.0022\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2120/6422 [========>.....................] - ETA: 0s - loss: 17.1270 - acc: 0.0019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6422/6422 [==============================] - 1s 94us/step - loss: 16.6467 - acc: 0.0028\n",
      "Epoch 2/100\n",
      "6422/6422 [==============================] - 1s 90us/step - loss: 16.5888 - acc: 0.0019\n",
      "Epoch 3/100\n",
      "6422/6422 [==============================] - 1s 87us/step - loss: 16.5552 - acc: 0.0020\n",
      "Epoch 4/100\n",
      "6422/6422 [==============================] - 0s 74us/step - loss: 16.6115 - acc: 0.0019\n",
      "Epoch 5/100\n",
      "6422/6422 [==============================] - 1s 90us/step - loss: 16.5927 - acc: 0.0017\n",
      "Epoch 6/100\n",
      "6422/6422 [==============================] - 0s 71us/step - loss: 16.5693 - acc: 0.0017\n",
      "Epoch 7/100\n",
      "6422/6422 [==============================] - 0s 73us/step - loss: 16.5596 - acc: 0.0017\n",
      "Epoch 8/100\n",
      "6422/6422 [==============================] - 0s 72us/step - loss: 16.5261 - acc: 0.0025\n",
      "Epoch 9/100\n",
      "6422/6422 [==============================] - 0s 72us/step - loss: 16.6311 - acc: 0.0028\n",
      "Epoch 10/100\n",
      "6422/6422 [==============================] - 0s 66us/step - loss: 16.4708 - acc: 0.0020\n",
      "Epoch 11/100\n",
      "6422/6422 [==============================] - 0s 74us/step - loss: 16.5648 - acc: 0.0022\n",
      "Epoch 12/100\n",
      "6422/6422 [==============================] - 0s 71us/step - loss: 16.5990 - acc: 0.0025\n",
      "Epoch 13/100\n",
      "6422/6422 [==============================] - 0s 70us/step - loss: 16.5736 - acc: 0.0022\n",
      "Epoch 14/100\n",
      "6422/6422 [==============================] - 0s 70us/step - loss: 16.5420 - acc: 0.0023\n",
      "Epoch 15/100\n",
      "6422/6422 [==============================] - 0s 72us/step - loss: 16.5650 - acc: 0.0022\n",
      "Epoch 16/100\n",
      "6422/6422 [==============================] - 0s 72us/step - loss: 16.5318 - acc: 0.0023\n",
      "Epoch 17/100\n",
      "6422/6422 [==============================] - 0s 72us/step - loss: 16.5494 - acc: 0.0014\n",
      "Epoch 18/100\n",
      "6422/6422 [==============================] - 0s 74us/step - loss: 16.5426 - acc: 0.0025\n",
      "Epoch 19/100\n",
      "6422/6422 [==============================] - 0s 72us/step - loss: 16.5854 - acc: 0.0022\n",
      "Epoch 20/100\n",
      "6422/6422 [==============================] - 0s 78us/step - loss: 16.5205 - acc: 0.0017\n",
      "Epoch 21/100\n",
      "6422/6422 [==============================] - 1s 86us/step - loss: 16.4771 - acc: 0.0022\n",
      "Epoch 22/100\n",
      "6422/6422 [==============================] - 1s 85us/step - loss: 16.5064 - acc: 0.0022\n",
      "Epoch 23/100\n",
      "6422/6422 [==============================] - 1s 90us/step - loss: 16.5582 - acc: 0.0022\n",
      "Epoch 24/100\n",
      "6422/6422 [==============================] - 1s 85us/step - loss: 16.5847 - acc: 0.0022\n",
      "Epoch 25/100\n",
      "6422/6422 [==============================] - 1s 84us/step - loss: 16.5869 - acc: 0.0025\n",
      "Epoch 26/100\n",
      "6422/6422 [==============================] - 1s 89us/step - loss: 16.5512 - acc: 0.0022\n",
      "Epoch 27/100\n",
      "6422/6422 [==============================] - 1s 83us/step - loss: 16.5504 - acc: 0.0022\n",
      "Epoch 28/100\n",
      "6422/6422 [==============================] - 1s 90us/step - loss: 16.4811 - acc: 0.0016\n",
      "Epoch 29/100\n",
      "6422/6422 [==============================] - 1s 89us/step - loss: 16.5638 - acc: 0.0026\n",
      "Epoch 30/100\n",
      "6422/6422 [==============================] - 1s 79us/step - loss: 16.4841 - acc: 0.0026\n",
      "Epoch 31/100\n",
      "6422/6422 [==============================] - 0s 73us/step - loss: 16.5741 - acc: 0.0017\n",
      "Epoch 32/100\n",
      "6422/6422 [==============================] - 0s 75us/step - loss: 16.5655 - acc: 0.0019\n",
      "Epoch 33/100\n",
      "6422/6422 [==============================] - 1s 92us/step - loss: 16.5604 - acc: 0.0017\n",
      "Epoch 34/100\n",
      "6422/6422 [==============================] - 0s 77us/step - loss: 16.6188 - acc: 0.0022\n",
      "Epoch 35/100\n",
      "6422/6422 [==============================] - 1s 97us/step - loss: 16.5277 - acc: 0.0020\n",
      "Epoch 36/100\n",
      "6422/6422 [==============================] - 1s 81us/step - loss: 16.5362 - acc: 0.0023\n",
      "Epoch 37/100\n",
      "6422/6422 [==============================] - 1s 96us/step - loss: 16.5692 - acc: 0.0026\n",
      "Epoch 38/100\n",
      "6422/6422 [==============================] - 1s 92us/step - loss: 16.5278 - acc: 0.0028\n",
      "Epoch 39/100\n",
      "6422/6422 [==============================] - 1s 83us/step - loss: 16.5993 - acc: 0.0025\n",
      "Epoch 40/100\n",
      "6422/6422 [==============================] - 1s 81us/step - loss: 16.5333 - acc: 0.0031\n",
      "Epoch 41/100\n",
      "6422/6422 [==============================] - 1s 79us/step - loss: 16.5218 - acc: 0.0022\n",
      "Epoch 42/100\n",
      "6422/6422 [==============================] - 1s 79us/step - loss: 16.5115 - acc: 0.0025\n",
      "Epoch 43/100\n",
      "6422/6422 [==============================] - 0s 76us/step - loss: 16.5166 - acc: 0.0022\n",
      "Epoch 44/100\n",
      "6422/6422 [==============================] - 1s 91us/step - loss: 16.5360 - acc: 0.0022\n",
      "Epoch 45/100\n",
      "6422/6422 [==============================] - 0s 77us/step - loss: 16.5536 - acc: 0.0023\n",
      "Epoch 46/100\n",
      "6422/6422 [==============================] - 1s 93us/step - loss: 16.5937 - acc: 0.0030\n",
      "Epoch 47/100\n",
      "6422/6422 [==============================] - 1s 80us/step - loss: 16.5443 - acc: 0.0023\n",
      "Epoch 48/100\n",
      "6422/6422 [==============================] - 0s 77us/step - loss: 16.5528 - acc: 0.0025\n",
      "Epoch 49/100\n",
      "6422/6422 [==============================] - 0s 76us/step - loss: 16.5435 - acc: 0.0019\n",
      "Epoch 50/100\n",
      "6422/6422 [==============================] - 0s 78us/step - loss: 16.5393 - acc: 0.0016\n",
      "Epoch 51/100\n",
      "6422/6422 [==============================] - 0s 75us/step - loss: 16.5669 - acc: 0.0025\n",
      "Epoch 52/100\n",
      "6422/6422 [==============================] - 1s 82us/step - loss: 16.5085 - acc: 0.0016\n",
      "Epoch 53/100\n",
      "6422/6422 [==============================] - 1s 82us/step - loss: 16.5532 - acc: 0.0017\n",
      "Epoch 54/100\n",
      "6422/6422 [==============================] - 1s 80us/step - loss: 16.4810 - acc: 0.0014\n",
      "Epoch 55/100\n",
      "6422/6422 [==============================] - 0s 77us/step - loss: 16.5610 - acc: 0.0025\n",
      "Epoch 56/100\n",
      "6422/6422 [==============================] - 1s 81us/step - loss: 16.4944 - acc: 0.0020\n",
      "Epoch 57/100\n",
      "6422/6422 [==============================] - 0s 78us/step - loss: 16.5027 - acc: 0.0023\n",
      "Epoch 58/100\n",
      "6422/6422 [==============================] - 1s 81us/step - loss: 16.5101 - acc: 0.0030\n",
      "Epoch 59/100\n",
      "6422/6422 [==============================] - 0s 77us/step - loss: 16.5278 - acc: 0.0023\n",
      "Epoch 60/100\n",
      "6422/6422 [==============================] - 0s 78us/step - loss: 16.4911 - acc: 0.0030\n",
      "Epoch 61/100\n",
      "6422/6422 [==============================] - 0s 75us/step - loss: 16.5388 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "6422/6422 [==============================] - 1s 81us/step - loss: 16.5474 - acc: 0.0023\n",
      "Epoch 63/100\n",
      "6422/6422 [==============================] - 0s 77us/step - loss: 16.5091 - acc: 0.0025\n",
      "Epoch 64/100\n",
      "6422/6422 [==============================] - 1s 78us/step - loss: 16.4762 - acc: 0.0020\n",
      "Epoch 65/100\n",
      "6422/6422 [==============================] - 0s 78us/step - loss: 16.4912 - acc: 0.0017\n",
      "Epoch 66/100\n",
      "6422/6422 [==============================] - 1s 83us/step - loss: 16.4867 - acc: 0.0022\n",
      "Epoch 67/100\n",
      "6422/6422 [==============================] - 1s 78us/step - loss: 16.5427 - acc: 0.0020\n",
      "Epoch 68/100\n",
      "6422/6422 [==============================] - 0s 77us/step - loss: 16.5192 - acc: 0.0022\n",
      "Epoch 69/100\n",
      "6422/6422 [==============================] - 1s 89us/step - loss: 16.4848 - acc: 0.0023\n",
      "Epoch 70/100\n",
      "6422/6422 [==============================] - 1s 89us/step - loss: 16.5104 - acc: 0.0028\n",
      "Epoch 71/100\n",
      "6422/6422 [==============================] - 1s 93us/step - loss: 16.5292 - acc: 0.0030\n",
      "Epoch 72/100\n",
      "6422/6422 [==============================] - 1s 88us/step - loss: 16.5573 - acc: 0.0033\n",
      "Epoch 73/100\n",
      "6422/6422 [==============================] - 1s 88us/step - loss: 16.5480 - acc: 0.0022\n",
      "Epoch 74/100\n",
      "6422/6422 [==============================] - 1s 84us/step - loss: 16.5529 - acc: 0.0016\n",
      "Epoch 75/100\n",
      "6422/6422 [==============================] - 1s 87us/step - loss: 16.5324 - acc: 0.0025\n",
      "Epoch 76/100\n",
      "6422/6422 [==============================] - 1s 85us/step - loss: 16.5109 - acc: 0.0022\n",
      "Epoch 77/100\n",
      "6422/6422 [==============================] - 1s 85us/step - loss: 16.4952 - acc: 0.0012\n",
      "Epoch 78/100\n",
      "6422/6422 [==============================] - 1s 85us/step - loss: 16.5273 - acc: 0.0020\n",
      "Epoch 79/100\n",
      "6422/6422 [==============================] - 1s 83us/step - loss: 16.5230 - acc: 0.0023\n",
      "Epoch 80/100\n",
      "6422/6422 [==============================] - 1s 84us/step - loss: 16.5064 - acc: 0.0028\n",
      "Epoch 81/100\n",
      "6422/6422 [==============================] - 1s 90us/step - loss: 16.4946 - acc: 0.0020\n",
      "Epoch 82/100\n",
      "6422/6422 [==============================] - 1s 87us/step - loss: 16.5396 - acc: 0.0023\n",
      "Epoch 83/100\n",
      "6422/6422 [==============================] - 1s 80us/step - loss: 16.5127 - acc: 0.0017\n",
      "Epoch 84/100\n",
      "6422/6422 [==============================] - 1s 84us/step - loss: 16.5010 - acc: 0.0023\n",
      "Epoch 85/100\n",
      "6422/6422 [==============================] - 1s 82us/step - loss: 16.5556 - acc: 0.0028\n",
      "Epoch 86/100\n",
      "6422/6422 [==============================] - 1s 82us/step - loss: 16.5115 - acc: 0.0019\n",
      "Epoch 87/100\n",
      "6422/6422 [==============================] - 1s 83us/step - loss: 16.5289 - acc: 0.0022\n",
      "Epoch 88/100\n",
      "6422/6422 [==============================] - 1s 81us/step - loss: 16.4348 - acc: 0.0025\n",
      "Epoch 89/100\n",
      "6422/6422 [==============================] - 1s 82us/step - loss: 16.4988 - acc: 0.0033\n",
      "Epoch 90/100\n",
      "6422/6422 [==============================] - 1s 81us/step - loss: 16.5401 - acc: 0.0033\n",
      "Epoch 91/100\n",
      "6422/6422 [==============================] - 0s 74us/step - loss: 16.5076 - acc: 0.0019\n",
      "Epoch 92/100\n",
      "6422/6422 [==============================] - 0s 71us/step - loss: 16.4929 - acc: 0.0026\n",
      "Epoch 93/100\n",
      "6422/6422 [==============================] - 0s 73us/step - loss: 16.5494 - acc: 0.0025\n",
      "Epoch 94/100\n",
      "6422/6422 [==============================] - 0s 76us/step - loss: 16.5019 - acc: 0.0020\n",
      "Epoch 95/100\n",
      "6422/6422 [==============================] - 1s 98us/step - loss: 16.5448 - acc: 0.0026\n",
      "Epoch 96/100\n",
      "6422/6422 [==============================] - 1s 84us/step - loss: 16.4669 - acc: 0.0025\n",
      "Epoch 97/100\n",
      "6422/6422 [==============================] - 1s 89us/step - loss: 16.5513 - acc: 0.0025\n",
      "Epoch 98/100\n",
      "6422/6422 [==============================] - 1s 88us/step - loss: 16.5075 - acc: 0.0025\n",
      "Epoch 99/100\n",
      "6422/6422 [==============================] - 1s 82us/step - loss: 16.5473 - acc: 0.0025\n",
      "Epoch 100/100\n",
      "6422/6422 [==============================] - 1s 81us/step - loss: 16.5703 - acc: 0.0020\n",
      "172/172 [==============================] - 0s 63us/step\n",
      "Epoch 1/100\n",
      "1710/6594 [======>.......................] - ETA: 0s - loss: 16.5946 - acc: 0.0012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6594/6594 [==============================] - 1s 94us/step - loss: 17.1528 - acc: 0.0023\n",
      "Epoch 2/100\n",
      "6594/6594 [==============================] - 1s 81us/step - loss: 17.0973 - acc: 0.0032\n",
      "Epoch 3/100\n",
      "6594/6594 [==============================] - 1s 83us/step - loss: 17.0155 - acc: 0.0027 0s - loss: 16.8619 - acc: \n",
      "Epoch 4/100\n",
      "6594/6594 [==============================] - 1s 85us/step - loss: 17.0426 - acc: 0.0027\n",
      "Epoch 5/100\n",
      "6594/6594 [==============================] - 0s 73us/step - loss: 16.9892 - acc: 0.0027\n",
      "Epoch 6/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 17.0252 - acc: 0.0029\n",
      "Epoch 7/100\n",
      "6594/6594 [==============================] - 0s 73us/step - loss: 16.9272 - acc: 0.0027\n",
      "Epoch 8/100\n",
      "6594/6594 [==============================] - 0s 74us/step - loss: 16.9611 - acc: 0.0026\n",
      "Epoch 9/100\n",
      "6594/6594 [==============================] - 1s 93us/step - loss: 16.9205 - acc: 0.0017\n",
      "Epoch 10/100\n",
      "6594/6594 [==============================] - 1s 87us/step - loss: 16.9483 - acc: 0.0023\n",
      "Epoch 11/100\n",
      "6594/6594 [==============================] - 1s 82us/step - loss: 16.9448 - acc: 0.0027\n",
      "Epoch 12/100\n",
      "6594/6594 [==============================] - 1s 85us/step - loss: 16.9679 - acc: 0.0027\n",
      "Epoch 13/100\n",
      "6594/6594 [==============================] - 1s 86us/step - loss: 16.9692 - acc: 0.0023\n",
      "Epoch 14/100\n",
      "6594/6594 [==============================] - 1s 84us/step - loss: 17.0314 - acc: 0.0027\n",
      "Epoch 15/100\n",
      "6594/6594 [==============================] - 1s 85us/step - loss: 16.9288 - acc: 0.0029\n",
      "Epoch 16/100\n",
      "6594/6594 [==============================] - 0s 75us/step - loss: 16.9945 - acc: 0.0027\n",
      "Epoch 17/100\n",
      "6594/6594 [==============================] - 1s 76us/step - loss: 16.9032 - acc: 0.0024\n",
      "Epoch 18/100\n",
      "6594/6594 [==============================] - 0s 72us/step - loss: 16.8995 - acc: 0.0023\n",
      "Epoch 19/100\n",
      "6594/6594 [==============================] - 0s 76us/step - loss: 16.9792 - acc: 0.0026\n",
      "Epoch 20/100\n",
      "6594/6594 [==============================] - 0s 75us/step - loss: 16.9421 - acc: 0.0030\n",
      "Epoch 21/100\n",
      "6594/6594 [==============================] - 0s 73us/step - loss: 16.9390 - acc: 0.0033\n",
      "Epoch 22/100\n",
      "6594/6594 [==============================] - 0s 75us/step - loss: 16.9174 - acc: 0.0032\n",
      "Epoch 23/100\n",
      "6594/6594 [==============================] - 0s 74us/step - loss: 16.9278 - acc: 0.0030\n",
      "Epoch 24/100\n",
      "6594/6594 [==============================] - 0s 75us/step - loss: 16.8653 - acc: 0.0030\n",
      "Epoch 25/100\n",
      "6594/6594 [==============================] - 0s 75us/step - loss: 16.9383 - acc: 0.0032\n",
      "Epoch 26/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.9691 - acc: 0.0026\n",
      "Epoch 27/100\n",
      "6594/6594 [==============================] - 0s 76us/step - loss: 16.9074 - acc: 0.0027\n",
      "Epoch 28/100\n",
      "6594/6594 [==============================] - 1s 76us/step - loss: 16.9103 - acc: 0.0023\n",
      "Epoch 29/100\n",
      "6594/6594 [==============================] - 0s 75us/step - loss: 16.9007 - acc: 0.0023\n",
      "Epoch 30/100\n",
      "6594/6594 [==============================] - 1s 80us/step - loss: 16.9234 - acc: 0.0024\n",
      "Epoch 31/100\n",
      "6594/6594 [==============================] - 0s 73us/step - loss: 16.9324 - acc: 0.0027\n",
      "Epoch 32/100\n",
      "6594/6594 [==============================] - 0s 74us/step - loss: 16.9096 - acc: 0.0026\n",
      "Epoch 33/100\n",
      "6594/6594 [==============================] - 0s 74us/step - loss: 16.9034 - acc: 0.0018\n",
      "Epoch 34/100\n",
      "6594/6594 [==============================] - 1s 81us/step - loss: 16.9608 - acc: 0.0029\n",
      "Epoch 35/100\n",
      "6594/6594 [==============================] - 1s 76us/step - loss: 16.9021 - acc: 0.0026\n",
      "Epoch 36/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.9256 - acc: 0.0030\n",
      "Epoch 37/100\n",
      "6594/6594 [==============================] - 0s 76us/step - loss: 16.8799 - acc: 0.0030\n",
      "Epoch 38/100\n",
      "6594/6594 [==============================] - 1s 76us/step - loss: 16.9500 - acc: 0.0030\n",
      "Epoch 39/100\n",
      "6594/6594 [==============================] - 1s 76us/step - loss: 16.9460 - acc: 0.0029\n",
      "Epoch 40/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.9168 - acc: 0.0030\n",
      "Epoch 41/100\n",
      "6594/6594 [==============================] - 1s 76us/step - loss: 16.9092 - acc: 0.0033\n",
      "Epoch 42/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.9393 - acc: 0.0026\n",
      "Epoch 43/100\n",
      "6594/6594 [==============================] - 0s 75us/step - loss: 16.8839 - acc: 0.0024\n",
      "Epoch 44/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.9239 - acc: 0.0029\n",
      "Epoch 45/100\n",
      "6594/6594 [==============================] - 0s 75us/step - loss: 16.8527 - acc: 0.0027\n",
      "Epoch 46/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.8900 - acc: 0.0033\n",
      "Epoch 47/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.8722 - acc: 0.0032\n",
      "Epoch 48/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.9253 - acc: 0.0024\n",
      "Epoch 49/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.8763 - acc: 0.0027\n",
      "Epoch 50/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.8774 - acc: 0.0030\n",
      "Epoch 51/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.9647 - acc: 0.0030\n",
      "Epoch 52/100\n",
      "6594/6594 [==============================] - 1s 79us/step - loss: 16.9083 - acc: 0.0032\n",
      "Epoch 53/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.8808 - acc: 0.0030\n",
      "Epoch 54/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.8969 - acc: 0.0035\n",
      "Epoch 55/100\n",
      "6594/6594 [==============================] - 1s 81us/step - loss: 16.8377 - acc: 0.0029\n",
      "Epoch 56/100\n",
      "6594/6594 [==============================] - 1s 79us/step - loss: 16.9363 - acc: 0.0033\n",
      "Epoch 57/100\n",
      "6594/6594 [==============================] - 1s 79us/step - loss: 16.9102 - acc: 0.0021\n",
      "Epoch 58/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.9076 - acc: 0.0030\n",
      "Epoch 59/100\n",
      "6594/6594 [==============================] - 1s 81us/step - loss: 16.8477 - acc: 0.0024\n",
      "Epoch 60/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.8785 - acc: 0.0023\n",
      "Epoch 61/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.8612 - acc: 0.0030\n",
      "Epoch 62/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.9060 - acc: 0.0029\n",
      "Epoch 63/100\n",
      "6594/6594 [==============================] - 1s 80us/step - loss: 16.8916 - acc: 0.0032\n",
      "Epoch 64/100\n",
      "6594/6594 [==============================] - 1s 77us/step - loss: 16.8958 - acc: 0.0027\n",
      "Epoch 65/100\n",
      "6594/6594 [==============================] - 1s 79us/step - loss: 16.9346 - acc: 0.0030\n",
      "Epoch 66/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.9170 - acc: 0.0029\n",
      "Epoch 67/100\n",
      "6594/6594 [==============================] - 1s 80us/step - loss: 16.9465 - acc: 0.0026\n",
      "Epoch 68/100\n",
      "6594/6594 [==============================] - 1s 78us/step - loss: 16.9009 - acc: 0.0024\n",
      "Epoch 69/100\n",
      "6594/6594 [==============================] - 1s 80us/step - loss: 16.8871 - acc: 0.0033\n",
      "Epoch 70/100\n",
      "6594/6594 [==============================] - 1s 79us/step - loss: 16.9082 - acc: 0.0029\n",
      "Epoch 71/100\n",
      "6594/6594 [==============================] - 1s 82us/step - loss: 16.9100 - acc: 0.0030\n",
      "Epoch 72/100\n",
      "6594/6594 [==============================] - 1s 76us/step - loss: 16.8872 - acc: 0.0027\n",
      "Epoch 73/100\n",
      "6594/6594 [==============================] - 1s 81us/step - loss: 16.9265 - acc: 0.0032\n",
      "Epoch 74/100\n",
      "6594/6594 [==============================] - 1s 79us/step - loss: 16.9222 - acc: 0.0026\n",
      "Epoch 75/100\n",
      "6594/6594 [==============================] - 1s 80us/step - loss: 16.8827 - acc: 0.0030\n",
      "Epoch 76/100\n",
      "6594/6594 [==============================] - 1s 79us/step - loss: 16.9117 - acc: 0.0029\n",
      "Epoch 77/100\n",
      "6594/6594 [==============================] - 1s 81us/step - loss: 16.8928 - acc: 0.0032\n",
      "Epoch 78/100\n",
      "6594/6594 [==============================] - 1s 79us/step - loss: 16.9168 - acc: 0.0030\n",
      "Epoch 79/100\n",
      "6594/6594 [==============================] - 1s 80us/step - loss: 16.9499 - acc: 0.0029\n",
      "Epoch 80/100\n",
      "6594/6594 [==============================] - 1s 82us/step - loss: 16.8325 - acc: 0.0035\n",
      "Epoch 81/100\n",
      "6594/6594 [==============================] - 1s 80us/step - loss: 16.8993 - acc: 0.0027\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6594/6594 [==============================] - 0s 74us/step - loss: 16.8958 - acc: 0.0024\n",
      "Epoch 83/100\n",
      "6594/6594 [==============================] - 0s 70us/step - loss: 16.8932 - acc: 0.0030\n",
      "Epoch 84/100\n",
      "6594/6594 [==============================] - 0s 69us/step - loss: 16.8721 - acc: 0.0033\n",
      "Epoch 85/100\n",
      "6594/6594 [==============================] - 0s 71us/step - loss: 16.8973 - acc: 0.0027\n",
      "Epoch 86/100\n",
      "6594/6594 [==============================] - 0s 70us/step - loss: 16.9339 - acc: 0.0030\n",
      "Epoch 87/100\n",
      "6594/6594 [==============================] - 0s 69us/step - loss: 16.9446 - acc: 0.0036\n",
      "Epoch 88/100\n",
      "6594/6594 [==============================] - 0s 72us/step - loss: 16.8663 - acc: 0.0029\n",
      "Epoch 89/100\n",
      "6594/6594 [==============================] - 0s 73us/step - loss: 16.9186 - acc: 0.0029\n",
      "Epoch 90/100\n",
      "6594/6594 [==============================] - 0s 71us/step - loss: 16.8814 - acc: 0.0024\n",
      "Epoch 91/100\n",
      "6594/6594 [==============================] - 0s 70us/step - loss: 16.8885 - acc: 0.0027\n",
      "Epoch 92/100\n",
      "6594/6594 [==============================] - 0s 71us/step - loss: 16.8815 - acc: 0.0024\n",
      "Epoch 93/100\n",
      "6594/6594 [==============================] - 0s 71us/step - loss: 16.9204 - acc: 0.0035\n",
      "Epoch 94/100\n",
      "6594/6594 [==============================] - 0s 70us/step - loss: 16.9116 - acc: 0.0033\n",
      "Epoch 95/100\n",
      "6594/6594 [==============================] - 0s 71us/step - loss: 16.8579 - acc: 0.0023\n",
      "Epoch 96/100\n",
      "6594/6594 [==============================] - 0s 70us/step - loss: 16.8915 - acc: 0.0027\n",
      "Epoch 97/100\n",
      "6594/6594 [==============================] - 0s 71us/step - loss: 16.8975 - acc: 0.0038\n",
      "Epoch 98/100\n",
      "6594/6594 [==============================] - 0s 71us/step - loss: 16.8622 - acc: 0.0027\n",
      "Epoch 99/100\n",
      "6594/6594 [==============================] - 0s 73us/step - loss: 16.8813 - acc: 0.0030\n",
      "Epoch 100/100\n",
      "6594/6594 [==============================] - 0s 71us/step - loss: 16.8338 - acc: 0.0023\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2660/6766 [==========>...................] - ETA: 0s - loss: 17.1611 - acc: 0.0041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.8603 - acc: 0.0030\n",
      "Epoch 2/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8630 - acc: 0.0034\n",
      "Epoch 3/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.9059 - acc: 0.0031\n",
      "Epoch 4/100\n",
      "6766/6766 [==============================] - 0s 67us/step - loss: 16.8827 - acc: 0.0034\n",
      "Epoch 5/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.9091 - acc: 0.0027\n",
      "Epoch 6/100\n",
      "6766/6766 [==============================] - 0s 67us/step - loss: 16.8416 - acc: 0.0025\n",
      "Epoch 7/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.9130 - acc: 0.0025\n",
      "Epoch 8/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8696 - acc: 0.0027\n",
      "Epoch 9/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8884 - acc: 0.0031\n",
      "Epoch 10/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8867 - acc: 0.0028\n",
      "Epoch 11/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8522 - acc: 0.0030\n",
      "Epoch 12/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8124 - acc: 0.0028\n",
      "Epoch 13/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8322 - acc: 0.0022\n",
      "Epoch 14/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8197 - acc: 0.0034\n",
      "Epoch 15/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8760 - acc: 0.0031\n",
      "Epoch 16/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8644 - acc: 0.0031\n",
      "Epoch 17/100\n",
      "6766/6766 [==============================] - 0s 69us/step - loss: 16.9097 - acc: 0.0030\n",
      "Epoch 18/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8494 - acc: 0.0025\n",
      "Epoch 19/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8676 - acc: 0.0021\n",
      "Epoch 20/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.8450 - acc: 0.0024\n",
      "Epoch 21/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8304 - acc: 0.0024\n",
      "Epoch 22/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.8675 - acc: 0.0024\n",
      "Epoch 23/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8058 - acc: 0.0031\n",
      "Epoch 24/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.8306 - acc: 0.0034\n",
      "Epoch 25/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8520 - acc: 0.0030\n",
      "Epoch 26/100\n",
      "6766/6766 [==============================] - 0s 74us/step - loss: 16.8820 - acc: 0.0033\n",
      "Epoch 27/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8569 - acc: 0.0024\n",
      "Epoch 28/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8687 - acc: 0.0027\n",
      "Epoch 29/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.9028 - acc: 0.0030\n",
      "Epoch 30/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.9093 - acc: 0.0021\n",
      "Epoch 31/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8304 - acc: 0.0030\n",
      "Epoch 32/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8323 - acc: 0.0033\n",
      "Epoch 33/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8035 - acc: 0.0025\n",
      "Epoch 34/100\n",
      "6766/6766 [==============================] - 0s 74us/step - loss: 16.8267 - acc: 0.0024\n",
      "Epoch 35/100\n",
      "6766/6766 [==============================] - 0s 69us/step - loss: 16.8361 - acc: 0.0024\n",
      "Epoch 36/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.8734 - acc: 0.0028\n",
      "Epoch 37/100\n",
      "6766/6766 [==============================] - 0s 74us/step - loss: 16.8898 - acc: 0.0031\n",
      "Epoch 38/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8440 - acc: 0.0027\n",
      "Epoch 39/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.8154 - acc: 0.0027\n",
      "Epoch 40/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.8109 - acc: 0.0035\n",
      "Epoch 41/100\n",
      "6766/6766 [==============================] - 0s 74us/step - loss: 16.8447 - acc: 0.0025\n",
      "Epoch 42/100\n",
      "6766/6766 [==============================] - 1s 79us/step - loss: 16.8876 - acc: 0.0024\n",
      "Epoch 43/100\n",
      "6766/6766 [==============================] - 0s 74us/step - loss: 16.8745 - acc: 0.0030\n",
      "Epoch 44/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.8037 - acc: 0.0031\n",
      "Epoch 45/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8712 - acc: 0.0034\n",
      "Epoch 46/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.9003 - acc: 0.0033\n",
      "Epoch 47/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.8228 - acc: 0.0041\n",
      "Epoch 48/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8478 - acc: 0.0025\n",
      "Epoch 49/100\n",
      "6766/6766 [==============================] - 0s 74us/step - loss: 16.8212 - acc: 0.0031\n",
      "Epoch 50/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.8202 - acc: 0.0030\n",
      "Epoch 51/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.7944 - acc: 0.0031\n",
      "Epoch 52/100\n",
      "6766/6766 [==============================] - 1s 76us/step - loss: 16.8805 - acc: 0.0030\n",
      "Epoch 53/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.8245 - acc: 0.0034\n",
      "Epoch 54/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.8819 - acc: 0.0033\n",
      "Epoch 55/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.8352 - acc: 0.0027\n",
      "Epoch 56/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.8273 - acc: 0.0025\n",
      "Epoch 57/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.7906 - acc: 0.0028\n",
      "Epoch 58/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.8463 - acc: 0.0033\n",
      "Epoch 59/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.8104 - acc: 0.0025\n",
      "Epoch 60/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.8429 - acc: 0.0030\n",
      "Epoch 61/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.8859 - acc: 0.0027\n",
      "Epoch 62/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.9180 - acc: 0.0022\n",
      "Epoch 63/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.9011 - acc: 0.0027\n",
      "Epoch 64/100\n",
      "6766/6766 [==============================] - 1s 76us/step - loss: 16.8073 - acc: 0.0030\n",
      "Epoch 65/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.8413 - acc: 0.0019\n",
      "Epoch 66/100\n",
      "6766/6766 [==============================] - 1s 77us/step - loss: 16.7938 - acc: 0.0027\n",
      "Epoch 67/100\n",
      "6766/6766 [==============================] - 1s 78us/step - loss: 16.8337 - acc: 0.0035\n",
      "Epoch 68/100\n",
      "6766/6766 [==============================] - 1s 108us/step - loss: 16.7922 - acc: 0.0025\n",
      "Epoch 69/100\n",
      "6766/6766 [==============================] - 1s 107us/step - loss: 16.8370 - acc: 0.0022\n",
      "Epoch 70/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.7875 - acc: 0.0028\n",
      "Epoch 71/100\n",
      "6766/6766 [==============================] - 1s 78us/step - loss: 16.8092 - acc: 0.0022\n",
      "Epoch 72/100\n",
      "6766/6766 [==============================] - 1s 79us/step - loss: 16.8664 - acc: 0.0027\n",
      "Epoch 73/100\n",
      "6766/6766 [==============================] - 1s 77us/step - loss: 16.7902 - acc: 0.0025\n",
      "Epoch 74/100\n",
      "6766/6766 [==============================] - 1s 81us/step - loss: 16.8190 - acc: 0.0030\n",
      "Epoch 75/100\n",
      "6766/6766 [==============================] - 1s 77us/step - loss: 16.8240 - acc: 0.0035\n",
      "Epoch 76/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.8271 - acc: 0.0033\n",
      "Epoch 77/100\n",
      "6766/6766 [==============================] - 1s 77us/step - loss: 16.7953 - acc: 0.0025\n",
      "Epoch 78/100\n",
      "6766/6766 [==============================] - 1s 78us/step - loss: 16.8884 - acc: 0.0027\n",
      "Epoch 79/100\n",
      "6766/6766 [==============================] - 1s 77us/step - loss: 16.8635 - acc: 0.0024\n",
      "Epoch 80/100\n",
      "6766/6766 [==============================] - 1s 75us/step - loss: 16.8569 - acc: 0.0030\n",
      "Epoch 81/100\n",
      "6766/6766 [==============================] - 1s 77us/step - loss: 16.8367 - acc: 0.0027\n",
      "Epoch 82/100\n",
      "6766/6766 [==============================] - 0s 74us/step - loss: 16.8337 - acc: 0.0028\n",
      "Epoch 83/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8864 - acc: 0.0024\n",
      "Epoch 84/100\n",
      "6766/6766 [==============================] - 0s 69us/step - loss: 16.8145 - acc: 0.0033\n",
      "Epoch 85/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8446 - acc: 0.0021\n",
      "Epoch 86/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8694 - acc: 0.0028\n",
      "Epoch 87/100\n",
      "6766/6766 [==============================] - 0s 73us/step - loss: 16.8443 - acc: 0.0024\n",
      "Epoch 88/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8684 - acc: 0.0025\n",
      "Epoch 89/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8213 - acc: 0.0030\n",
      "Epoch 90/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8120 - acc: 0.0028\n",
      "Epoch 91/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8130 - acc: 0.0037\n",
      "Epoch 92/100\n",
      "6766/6766 [==============================] - 0s 70us/step - loss: 16.8362 - acc: 0.0033\n",
      "Epoch 93/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8120 - acc: 0.0025\n",
      "Epoch 94/100\n",
      "6766/6766 [==============================] - 1s 74us/step - loss: 16.8162 - acc: 0.0027\n",
      "Epoch 95/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8394 - acc: 0.0031\n",
      "Epoch 96/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8379 - acc: 0.0022\n",
      "Epoch 97/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8817 - acc: 0.0031\n",
      "Epoch 98/100\n",
      "6766/6766 [==============================] - 0s 71us/step - loss: 16.8194 - acc: 0.0025\n",
      "Epoch 99/100\n",
      "6766/6766 [==============================] - 0s 72us/step - loss: 16.8170 - acc: 0.0025\n",
      "Epoch 100/100\n",
      "6766/6766 [==============================] - 0s 74us/step - loss: 16.8090 - acc: 0.0025\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2070/6938 [=======>......................] - ETA: 0s - loss: 17.1856 - acc: 9.6618e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.5501 - acc: 0.0020\n",
      "Epoch 2/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.4676 - acc: 0.0029\n",
      "Epoch 3/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.4333 - acc: 0.0025\n",
      "Epoch 4/100\n",
      "6938/6938 [==============================] - 0s 69us/step - loss: 17.4271 - acc: 0.0027\n",
      "Epoch 5/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.4438 - acc: 0.0026\n",
      "Epoch 6/100\n",
      "6938/6938 [==============================] - 0s 69us/step - loss: 17.4762 - acc: 0.0019\n",
      "Epoch 7/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.4200 - acc: 0.0029\n",
      "Epoch 8/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.4300 - acc: 0.0027\n",
      "Epoch 9/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3878 - acc: 0.0030\n",
      "Epoch 10/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3559 - acc: 0.0026\n",
      "Epoch 11/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.4103 - acc: 0.0020\n",
      "Epoch 12/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.3736 - acc: 0.0025\n",
      "Epoch 13/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.3247 - acc: 0.0022\n",
      "Epoch 14/100\n",
      "6938/6938 [==============================] - 0s 69us/step - loss: 17.3475 - acc: 0.0029\n",
      "Epoch 15/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.4419 - acc: 0.0026\n",
      "Epoch 16/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3822 - acc: 0.0020\n",
      "Epoch 17/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.3950 - acc: 0.0030\n",
      "Epoch 18/100\n",
      "6938/6938 [==============================] - 1s 72us/step - loss: 17.3607 - acc: 0.0030\n",
      "Epoch 19/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3719 - acc: 0.0025\n",
      "Epoch 20/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3621 - acc: 0.0026\n",
      "Epoch 21/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.3627 - acc: 0.0022\n",
      "Epoch 22/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3876 - acc: 0.0030\n",
      "Epoch 23/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3907 - acc: 0.0020\n",
      "Epoch 24/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3745 - acc: 0.0022\n",
      "Epoch 25/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3688 - acc: 0.0023\n",
      "Epoch 26/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.3907 - acc: 0.0020\n",
      "Epoch 27/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.3720 - acc: 0.0026\n",
      "Epoch 28/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.4265 - acc: 0.0023\n",
      "Epoch 29/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3633 - acc: 0.0023\n",
      "Epoch 30/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3320 - acc: 0.0029\n",
      "Epoch 31/100\n",
      "6938/6938 [==============================] - 1s 72us/step - loss: 17.4282 - acc: 0.0025\n",
      "Epoch 32/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.3306 - acc: 0.0030\n",
      "Epoch 33/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3033 - acc: 0.0019\n",
      "Epoch 34/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3507 - acc: 0.0022\n",
      "Epoch 35/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.3041 - acc: 0.0027\n",
      "Epoch 36/100\n",
      "6938/6938 [==============================] - 1s 75us/step - loss: 17.3198 - acc: 0.0022\n",
      "Epoch 37/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.3905 - acc: 0.0022\n",
      "Epoch 38/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3013 - acc: 0.0030\n",
      "Epoch 39/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.3720 - acc: 0.0023\n",
      "Epoch 40/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.2924 - acc: 0.0025\n",
      "Epoch 41/100\n",
      "6938/6938 [==============================] - 1s 72us/step - loss: 17.3364 - acc: 0.0026\n",
      "Epoch 42/100\n",
      "6938/6938 [==============================] - 1s 75us/step - loss: 17.3711 - acc: 0.0029\n",
      "Epoch 43/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.3176 - acc: 0.0023\n",
      "Epoch 44/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.3094 - acc: 0.0027\n",
      "Epoch 45/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3141 - acc: 0.0026\n",
      "Epoch 46/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.3167 - acc: 0.0022\n",
      "Epoch 47/100\n",
      "6938/6938 [==============================] - 1s 72us/step - loss: 17.2979 - acc: 0.0029\n",
      "Epoch 48/100\n",
      "6938/6938 [==============================] - 1s 75us/step - loss: 17.3283 - acc: 0.0026\n",
      "Epoch 49/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.3042 - acc: 0.0030\n",
      "Epoch 50/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.2704 - acc: 0.0023\n",
      "Epoch 51/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.2957 - acc: 0.0023\n",
      "Epoch 52/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.3525 - acc: 0.0025\n",
      "Epoch 53/100\n",
      "6938/6938 [==============================] - 1s 76us/step - loss: 17.3563 - acc: 0.0023\n",
      "Epoch 54/100\n",
      "6938/6938 [==============================] - 1s 72us/step - loss: 17.2958 - acc: 0.0012\n",
      "Epoch 55/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.3259 - acc: 0.0026\n",
      "Epoch 56/100\n",
      "6938/6938 [==============================] - 1s 72us/step - loss: 17.3210 - acc: 0.0026\n",
      "Epoch 57/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.2960 - acc: 0.0017\n",
      "Epoch 58/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3660 - acc: 0.0023\n",
      "Epoch 59/100\n",
      "6938/6938 [==============================] - 1s 77us/step - loss: 17.3131 - acc: 0.0030\n",
      "Epoch 60/100\n",
      "6938/6938 [==============================] - 1s 72us/step - loss: 17.3251 - acc: 0.0027\n",
      "Epoch 61/100\n",
      "6938/6938 [==============================] - 1s 76us/step - loss: 17.3172 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.2765 - acc: 0.0019\n",
      "Epoch 63/100\n",
      "6938/6938 [==============================] - 1s 78us/step - loss: 17.2859 - acc: 0.0022\n",
      "Epoch 64/100\n",
      "6938/6938 [==============================] - 1s 72us/step - loss: 17.2771 - acc: 0.0029\n",
      "Epoch 65/100\n",
      "6938/6938 [==============================] - 1s 78us/step - loss: 17.2905 - acc: 0.0027\n",
      "Epoch 66/100\n",
      "6938/6938 [==============================] - 1s 75us/step - loss: 17.3267 - acc: 0.0022\n",
      "Epoch 67/100\n",
      "6938/6938 [==============================] - 1s 78us/step - loss: 17.2884 - acc: 0.0036\n",
      "Epoch 68/100\n",
      "6938/6938 [==============================] - 1s 74us/step - loss: 17.3095 - acc: 0.0029\n",
      "Epoch 69/100\n",
      "6938/6938 [==============================] - 1s 77us/step - loss: 17.3036 - acc: 0.0026\n",
      "Epoch 70/100\n",
      "6938/6938 [==============================] - 1s 75us/step - loss: 17.3310 - acc: 0.0023\n",
      "Epoch 71/100\n",
      "6938/6938 [==============================] - 1s 77us/step - loss: 17.2754 - acc: 0.0025\n",
      "Epoch 72/100\n",
      "6938/6938 [==============================] - 1s 77us/step - loss: 17.2651 - acc: 0.0019\n",
      "Epoch 73/100\n",
      "6938/6938 [==============================] - 1s 76us/step - loss: 17.3162 - acc: 0.0020\n",
      "Epoch 74/100\n",
      "6938/6938 [==============================] - 1s 75us/step - loss: 17.2850 - acc: 0.0022\n",
      "Epoch 75/100\n",
      "6938/6938 [==============================] - 1s 84us/step - loss: 17.2504 - acc: 0.0025\n",
      "Epoch 76/100\n",
      "6938/6938 [==============================] - 1s 77us/step - loss: 17.3042 - acc: 0.0022\n",
      "Epoch 77/100\n",
      "6938/6938 [==============================] - 1s 75us/step - loss: 17.2624 - acc: 0.0022\n",
      "Epoch 78/100\n",
      "6938/6938 [==============================] - 1s 78us/step - loss: 17.2626 - acc: 0.0022\n",
      "Epoch 79/100\n",
      "6938/6938 [==============================] - 1s 76us/step - loss: 17.2785 - acc: 0.0025\n",
      "Epoch 80/100\n",
      "6938/6938 [==============================] - 1s 78us/step - loss: 17.2635 - acc: 0.0023\n",
      "Epoch 81/100\n",
      "6938/6938 [==============================] - 1s 76us/step - loss: 17.2735 - acc: 0.0019\n",
      "Epoch 82/100\n",
      "6938/6938 [==============================] - 1s 73us/step - loss: 17.3165 - acc: 0.0027\n",
      "Epoch 83/100\n",
      "6938/6938 [==============================] - 0s 69us/step - loss: 17.2468 - acc: 0.0030\n",
      "Epoch 84/100\n",
      "6938/6938 [==============================] - 0s 69us/step - loss: 17.2466 - acc: 0.0020\n",
      "Epoch 85/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.2152 - acc: 0.0026\n",
      "Epoch 86/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.1762 - acc: 0.0022\n",
      "Epoch 87/100\n",
      "6938/6938 [==============================] - 0s 68us/step - loss: 17.2082 - acc: 0.0029\n",
      "Epoch 88/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.1956 - acc: 0.0025\n",
      "Epoch 89/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.1728 - acc: 0.0020\n",
      "Epoch 90/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.2044 - acc: 0.0026\n",
      "Epoch 91/100\n",
      "6938/6938 [==============================] - 0s 70us/step - loss: 17.1856 - acc: 0.0027\n",
      "Epoch 92/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.2235 - acc: 0.0017\n",
      "Epoch 93/100\n",
      "6938/6938 [==============================] - 0s 68us/step - loss: 17.2304 - acc: 0.0020\n",
      "Epoch 94/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.1861 - acc: 0.0030\n",
      "Epoch 95/100\n",
      "6938/6938 [==============================] - 0s 72us/step - loss: 17.1812 - acc: 0.0022\n",
      "Epoch 96/100\n",
      "6938/6938 [==============================] - 0s 71us/step - loss: 17.2005 - acc: 0.0020\n",
      "Epoch 97/100\n",
      "6938/6938 [==============================] - 0s 69us/step - loss: 17.1729 - acc: 0.0030\n",
      "Epoch 98/100\n",
      "6938/6938 [==============================] - 1s 83us/step - loss: 17.1537 - acc: 0.0026\n",
      "Epoch 99/100\n",
      "6938/6938 [==============================] - 1s 83us/step - loss: 17.1678 - acc: 0.0026\n",
      "Epoch 100/100\n",
      "6938/6938 [==============================] - 1s 81us/step - loss: 17.1352 - acc: 0.0027\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2430/7110 [=========>....................] - ETA: 0s - loss: 18.6310 - acc: 8.2305e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7110/7110 [==============================] - 1s 85us/step - loss: 18.4031 - acc: 0.0024\n",
      "Epoch 2/100\n",
      "7110/7110 [==============================] - 1s 86us/step - loss: 18.3354 - acc: 0.0024\n",
      "Epoch 3/100\n",
      "7110/7110 [==============================] - 1s 81us/step - loss: 18.2449 - acc: 0.0024\n",
      "Epoch 4/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 18.2568 - acc: 0.0027\n",
      "Epoch 5/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 18.1870 - acc: 0.0023\n",
      "Epoch 6/100\n",
      "7110/7110 [==============================] - 1s 81us/step - loss: 18.1648 - acc: 0.0020\n",
      "Epoch 7/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 18.1665 - acc: 0.0018\n",
      "Epoch 8/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 18.0779 - acc: 0.0024\n",
      "Epoch 9/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 18.1306 - acc: 0.0028\n",
      "Epoch 10/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 18.1209 - acc: 0.0020\n",
      "Epoch 11/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 18.0929 - acc: 0.0025\n",
      "Epoch 12/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 18.0864 - acc: 0.0025\n",
      "Epoch 13/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 18.1042 - acc: 0.0030\n",
      "Epoch 14/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 18.0916 - acc: 0.0018\n",
      "Epoch 15/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 18.0504 - acc: 0.0021\n",
      "Epoch 16/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.9992 - acc: 0.0021\n",
      "Epoch 17/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 18.0187 - acc: 0.0020\n",
      "Epoch 18/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.9538 - acc: 0.0023\n",
      "Epoch 19/100\n",
      "7110/7110 [==============================] - 1s 88us/step - loss: 18.0433 - acc: 0.0020\n",
      "Epoch 20/100\n",
      "7110/7110 [==============================] - 1s 88us/step - loss: 17.9590 - acc: 0.0030\n",
      "Epoch 21/100\n",
      "7110/7110 [==============================] - 1s 93us/step - loss: 17.9683 - acc: 0.0028\n",
      "Epoch 22/100\n",
      "7110/7110 [==============================] - 1s 89us/step - loss: 17.9511 - acc: 0.0031\n",
      "Epoch 23/100\n",
      "7110/7110 [==============================] - 1s 93us/step - loss: 17.9105 - acc: 0.0025\n",
      "Epoch 24/100\n",
      "7110/7110 [==============================] - 1s 87us/step - loss: 17.9512 - acc: 0.0020\n",
      "Epoch 25/100\n",
      "7110/7110 [==============================] - 1s 86us/step - loss: 17.9113 - acc: 0.0027\n",
      "Epoch 26/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.9933 - acc: 0.0021\n",
      "Epoch 27/100\n",
      "7110/7110 [==============================] - 1s 88us/step - loss: 17.9350 - acc: 0.0021\n",
      "Epoch 28/100\n",
      "7110/7110 [==============================] - 1s 89us/step - loss: 17.9199 - acc: 0.0015\n",
      "Epoch 29/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.8359 - acc: 0.0021\n",
      "Epoch 30/100\n",
      "7110/7110 [==============================] - 1s 73us/step - loss: 17.9239 - acc: 0.0020\n",
      "Epoch 31/100\n",
      "7110/7110 [==============================] - 1s 75us/step - loss: 17.9821 - acc: 0.0030\n",
      "Epoch 32/100\n",
      "7110/7110 [==============================] - 1s 75us/step - loss: 17.8392 - acc: 0.0024\n",
      "Epoch 33/100\n",
      "7110/7110 [==============================] - 1s 76us/step - loss: 17.8770 - acc: 0.0025\n",
      "Epoch 34/100\n",
      "7110/7110 [==============================] - 1s 75us/step - loss: 17.8858 - acc: 0.0024\n",
      "Epoch 35/100\n",
      "7110/7110 [==============================] - 1s 77us/step - loss: 17.8195 - acc: 0.0027\n",
      "Epoch 36/100\n",
      "7110/7110 [==============================] - 1s 72us/step - loss: 17.8537 - acc: 0.0030\n",
      "Epoch 37/100\n",
      "7110/7110 [==============================] - 1s 75us/step - loss: 17.8440 - acc: 0.0021\n",
      "Epoch 38/100\n",
      "7110/7110 [==============================] - 1s 71us/step - loss: 17.9259 - acc: 0.0014\n",
      "Epoch 39/100\n",
      "7110/7110 [==============================] - 1s 72us/step - loss: 17.8347 - acc: 0.0018\n",
      "Epoch 40/100\n",
      "7110/7110 [==============================] - 1s 72us/step - loss: 17.8148 - acc: 0.0024\n",
      "Epoch 41/100\n",
      "7110/7110 [==============================] - 1s 73us/step - loss: 17.7975 - acc: 0.0017\n",
      "Epoch 42/100\n",
      "7110/7110 [==============================] - 1s 73us/step - loss: 17.8734 - acc: 0.0023\n",
      "Epoch 43/100\n",
      "7110/7110 [==============================] - 1s 72us/step - loss: 17.8452 - acc: 0.0020\n",
      "Epoch 44/100\n",
      "7110/7110 [==============================] - 1s 75us/step - loss: 17.8978 - acc: 0.0023\n",
      "Epoch 45/100\n",
      "7110/7110 [==============================] - 1s 82us/step - loss: 17.8102 - acc: 0.0023\n",
      "Epoch 46/100\n",
      "7110/7110 [==============================] - 1s 80us/step - loss: 17.8390 - acc: 0.0028\n",
      "Epoch 47/100\n",
      "7110/7110 [==============================] - 1s 90us/step - loss: 17.8115 - acc: 0.0024\n",
      "Epoch 48/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.8750 - acc: 0.0028\n",
      "Epoch 49/100\n",
      "7110/7110 [==============================] - 1s 82us/step - loss: 17.8066 - acc: 0.0034\n",
      "Epoch 50/100\n",
      "7110/7110 [==============================] - 1s 86us/step - loss: 17.7924 - acc: 0.0027\n",
      "Epoch 51/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 17.8018 - acc: 0.0024\n",
      "Epoch 52/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.8318 - acc: 0.0020\n",
      "Epoch 53/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 17.7943 - acc: 0.0025\n",
      "Epoch 54/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.8398 - acc: 0.0023\n",
      "Epoch 55/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.8580 - acc: 0.0023\n",
      "Epoch 56/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.8123 - acc: 0.0024\n",
      "Epoch 57/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.8229 - acc: 0.0025\n",
      "Epoch 58/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.8112 - acc: 0.0021\n",
      "Epoch 59/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 17.7502 - acc: 0.0020\n",
      "Epoch 60/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.8428 - acc: 0.0020\n",
      "Epoch 61/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 17.8470 - acc: 0.0021\n",
      "Epoch 62/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.7295 - acc: 0.0018\n",
      "Epoch 63/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 17.7656 - acc: 0.0024\n",
      "Epoch 64/100\n",
      "7110/7110 [==============================] - 1s 82us/step - loss: 17.8299 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "7110/7110 [==============================] - 1s 84us/step - loss: 17.7427 - acc: 0.0023\n",
      "Epoch 66/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.8144 - acc: 0.0032\n",
      "Epoch 67/100\n",
      "7110/7110 [==============================] - 1s 83us/step - loss: 17.8258 - acc: 0.0018\n",
      "Epoch 68/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.8378 - acc: 0.0025\n",
      "Epoch 69/100\n",
      "7110/7110 [==============================] - 1s 87us/step - loss: 17.7643 - acc: 0.0024\n",
      "Epoch 70/100\n",
      "7110/7110 [==============================] - 1s 88us/step - loss: 17.7999 - acc: 0.0027\n",
      "Epoch 71/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.7655 - acc: 0.0021\n",
      "Epoch 72/100\n",
      "7110/7110 [==============================] - 1s 85us/step - loss: 17.7914 - acc: 0.0023\n",
      "Epoch 73/100\n",
      "7110/7110 [==============================] - 1s 87us/step - loss: 17.8000 - acc: 0.0024\n",
      "Epoch 74/100\n",
      "7110/7110 [==============================] - 1s 86us/step - loss: 17.7879 - acc: 0.0030\n",
      "Epoch 75/100\n",
      "7110/7110 [==============================] - 1s 82us/step - loss: 17.7444 - acc: 0.0021\n",
      "Epoch 76/100\n",
      "7110/7110 [==============================] - 1s 75us/step - loss: 17.7233 - acc: 0.0027\n",
      "Epoch 77/100\n",
      "7110/7110 [==============================] - 1s 75us/step - loss: 17.7969 - acc: 0.0024\n",
      "Epoch 78/100\n",
      "7110/7110 [==============================] - 1s 77us/step - loss: 17.7762 - acc: 0.0018\n",
      "Epoch 79/100\n",
      "7110/7110 [==============================] - 1s 76us/step - loss: 17.7309 - acc: 0.0024\n",
      "Epoch 80/100\n",
      "7110/7110 [==============================] - 1s 77us/step - loss: 17.8064 - acc: 0.0023\n",
      "Epoch 81/100\n",
      "7110/7110 [==============================] - 1s 76us/step - loss: 17.7590 - acc: 0.0020\n",
      "Epoch 82/100\n",
      "7110/7110 [==============================] - 1s 73us/step - loss: 17.8477 - acc: 0.0024\n",
      "Epoch 83/100\n",
      "7110/7110 [==============================] - 1s 71us/step - loss: 17.7999 - acc: 0.0023\n",
      "Epoch 84/100\n",
      "7110/7110 [==============================] - 1s 72us/step - loss: 17.7556 - acc: 0.0023\n",
      "Epoch 85/100\n",
      "7110/7110 [==============================] - 0s 69us/step - loss: 17.7631 - acc: 0.0017\n",
      "Epoch 86/100\n",
      "7110/7110 [==============================] - 1s 71us/step - loss: 17.7598 - acc: 0.0025\n",
      "Epoch 87/100\n",
      "7110/7110 [==============================] - 1s 72us/step - loss: 17.7346 - acc: 0.0028\n",
      "Epoch 88/100\n",
      "7110/7110 [==============================] - 1s 71us/step - loss: 17.7563 - acc: 0.0028\n",
      "Epoch 89/100\n",
      "7110/7110 [==============================] - 1s 71us/step - loss: 17.7928 - acc: 0.0024\n",
      "Epoch 90/100\n",
      "7110/7110 [==============================] - 1s 71us/step - loss: 17.7757 - acc: 0.0021\n",
      "Epoch 91/100\n",
      "7110/7110 [==============================] - 1s 71us/step - loss: 17.7584 - acc: 0.0023\n",
      "Epoch 92/100\n",
      "7110/7110 [==============================] - 0s 70us/step - loss: 17.7511 - acc: 0.0024\n",
      "Epoch 93/100\n",
      "7110/7110 [==============================] - 1s 71us/step - loss: 17.7412 - acc: 0.0034 0s - loss: 17.2799 -\n",
      "Epoch 94/100\n",
      "7110/7110 [==============================] - 0s 70us/step - loss: 17.7766 - acc: 0.0028\n",
      "Epoch 95/100\n",
      "7110/7110 [==============================] - 1s 73us/step - loss: 17.7403 - acc: 0.0020\n",
      "Epoch 96/100\n",
      "7110/7110 [==============================] - 1s 74us/step - loss: 17.7894 - acc: 0.0020\n",
      "Epoch 97/100\n",
      "7110/7110 [==============================] - 1s 73us/step - loss: 17.7792 - acc: 0.0021\n",
      "Epoch 98/100\n",
      "7110/7110 [==============================] - 1s 72us/step - loss: 17.7323 - acc: 0.0032\n",
      "Epoch 99/100\n",
      "7110/7110 [==============================] - 1s 74us/step - loss: 17.6844 - acc: 0.0021\n",
      "Epoch 100/100\n",
      "7110/7110 [==============================] - 1s 72us/step - loss: 17.7897 - acc: 0.0021\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2340/7282 [========>.....................] - ETA: 0s - loss: 17.2810 - acc: 0.0021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7282/7282 [==============================] - 1s 72us/step - loss: 18.0741 - acc: 0.0018\n",
      "Epoch 2/100\n",
      "7282/7282 [==============================] - 1s 69us/step - loss: 18.0388 - acc: 0.0022\n",
      "Epoch 3/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 18.0811 - acc: 0.0018\n",
      "Epoch 4/100\n",
      "7282/7282 [==============================] - 1s 77us/step - loss: 18.0015 - acc: 0.0019\n",
      "Epoch 5/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 18.0401 - acc: 0.0021\n",
      "Epoch 6/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 18.0144 - acc: 0.0018\n",
      "Epoch 7/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 17.9715 - acc: 9.6127e-04\n",
      "Epoch 8/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 18.0250 - acc: 0.0023\n",
      "Epoch 9/100\n",
      "7282/7282 [==============================] - 1s 69us/step - loss: 18.0064 - acc: 0.0026\n",
      "Epoch 10/100\n",
      "7282/7282 [==============================] - 1s 69us/step - loss: 17.9764 - acc: 0.0018\n",
      "Epoch 11/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 18.0378 - acc: 0.0014\n",
      "Epoch 12/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9982 - acc: 0.0025\n",
      "Epoch 13/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9639 - acc: 0.0016\n",
      "Epoch 14/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9553 - acc: 0.0019\n",
      "Epoch 15/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9500 - acc: 0.0018\n",
      "Epoch 16/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9501 - acc: 0.0021\n",
      "Epoch 17/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9548 - acc: 0.0016\n",
      "Epoch 18/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9499 - acc: 0.0025\n",
      "Epoch 19/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 18.0000 - acc: 0.0023\n",
      "Epoch 20/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9636 - acc: 0.0022\n",
      "Epoch 21/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9305 - acc: 0.0018 0s - loss: 18.0528\n",
      "Epoch 22/100\n",
      "7282/7282 [==============================] - 1s 73us/step - loss: 17.9403 - acc: 0.0023\n",
      "Epoch 23/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9617 - acc: 0.0022\n",
      "Epoch 24/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 17.9384 - acc: 0.0022\n",
      "Epoch 25/100\n",
      "7282/7282 [==============================] - 1s 73us/step - loss: 17.9345 - acc: 0.0019\n",
      "Epoch 26/100\n",
      "7282/7282 [==============================] - 1s 73us/step - loss: 18.0091 - acc: 0.0021\n",
      "Epoch 27/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 18.0411 - acc: 0.0015\n",
      "Epoch 28/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9477 - acc: 0.0021\n",
      "Epoch 29/100\n",
      "7282/7282 [==============================] - 1s 73us/step - loss: 17.9258 - acc: 0.0023\n",
      "Epoch 30/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9881 - acc: 0.0026\n",
      "Epoch 31/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9272 - acc: 0.0022\n",
      "Epoch 32/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9767 - acc: 0.0021\n",
      "Epoch 33/100\n",
      "7282/7282 [==============================] - 1s 74us/step - loss: 17.9546 - acc: 0.0018\n",
      "Epoch 34/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.9721 - acc: 0.0025\n",
      "Epoch 35/100\n",
      "7282/7282 [==============================] - 1s 78us/step - loss: 17.9551 - acc: 0.0027\n",
      "Epoch 36/100\n",
      "7282/7282 [==============================] - 1s 90us/step - loss: 17.9692 - acc: 0.0022\n",
      "Epoch 37/100\n",
      "7282/7282 [==============================] - 1s 84us/step - loss: 17.9812 - acc: 0.0018\n",
      "Epoch 38/100\n",
      "7282/7282 [==============================] - 1s 86us/step - loss: 17.9366 - acc: 0.0021\n",
      "Epoch 39/100\n",
      "7282/7282 [==============================] - 1s 91us/step - loss: 17.9649 - acc: 0.0023\n",
      "Epoch 40/100\n",
      "7282/7282 [==============================] - 1s 90us/step - loss: 17.9475 - acc: 0.0016\n",
      "Epoch 41/100\n",
      "7282/7282 [==============================] - 1s 89us/step - loss: 17.9134 - acc: 0.0021\n",
      "Epoch 42/100\n",
      "7282/7282 [==============================] - 1s 95us/step - loss: 17.9746 - acc: 0.0018\n",
      "Epoch 43/100\n",
      "7282/7282 [==============================] - 1s 98us/step - loss: 17.9823 - acc: 0.0016\n",
      "Epoch 44/100\n",
      "7282/7282 [==============================] - 1s 98us/step - loss: 17.9069 - acc: 0.0022\n",
      "Epoch 45/100\n",
      "7282/7282 [==============================] - 1s 98us/step - loss: 17.9824 - acc: 0.0022\n",
      "Epoch 46/100\n",
      "7282/7282 [==============================] - 1s 99us/step - loss: 17.9551 - acc: 0.0021\n",
      "Epoch 47/100\n",
      "7282/7282 [==============================] - 1s 109us/step - loss: 17.9317 - acc: 0.0019\n",
      "Epoch 48/100\n",
      "7282/7282 [==============================] - 1s 93us/step - loss: 17.9209 - acc: 0.0026\n",
      "Epoch 49/100\n",
      "7282/7282 [==============================] - 1s 87us/step - loss: 17.9290 - acc: 0.0019\n",
      "Epoch 50/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.9347 - acc: 0.0021\n",
      "Epoch 51/100\n",
      "7282/7282 [==============================] - 1s 79us/step - loss: 17.9252 - acc: 0.0021\n",
      "Epoch 52/100\n",
      "7282/7282 [==============================] - 1s 73us/step - loss: 17.9889 - acc: 0.0014\n",
      "Epoch 53/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.9219 - acc: 0.0018\n",
      "Epoch 54/100\n",
      "7282/7282 [==============================] - 1s 74us/step - loss: 17.9196 - acc: 0.0026\n",
      "Epoch 55/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.8948 - acc: 0.0018\n",
      "Epoch 56/100\n",
      "7282/7282 [==============================] - 1s 74us/step - loss: 17.9494 - acc: 0.0022\n",
      "Epoch 57/100\n",
      "7282/7282 [==============================] - 1s 74us/step - loss: 17.9391 - acc: 0.0021\n",
      "Epoch 58/100\n",
      "7282/7282 [==============================] - 1s 81us/step - loss: 17.9175 - acc: 0.0016\n",
      "Epoch 59/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.8912 - acc: 0.0023\n",
      "Epoch 60/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.9226 - acc: 0.0023\n",
      "Epoch 61/100\n",
      "7282/7282 [==============================] - 1s 73us/step - loss: 17.8593 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.9055 - acc: 0.0025\n",
      "Epoch 63/100\n",
      "7282/7282 [==============================] - 1s 74us/step - loss: 17.9182 - acc: 0.0018\n",
      "Epoch 64/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.9270 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "7282/7282 [==============================] - 1s 79us/step - loss: 17.9235 - acc: 0.0023\n",
      "Epoch 66/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.8826 - acc: 0.0019\n",
      "Epoch 67/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.9276 - acc: 0.0025\n",
      "Epoch 68/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.9073 - acc: 0.0014\n",
      "Epoch 69/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.9011 - acc: 0.0018\n",
      "Epoch 70/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.9327 - acc: 0.0025\n",
      "Epoch 71/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.8951 - acc: 0.0022\n",
      "Epoch 72/100\n",
      "7282/7282 [==============================] - 1s 74us/step - loss: 17.9779 - acc: 0.0022\n",
      "Epoch 73/100\n",
      "7282/7282 [==============================] - 1s 78us/step - loss: 17.8769 - acc: 0.0016\n",
      "Epoch 74/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.8647 - acc: 0.0023\n",
      "Epoch 75/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.9145 - acc: 0.0019\n",
      "Epoch 76/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.9855 - acc: 0.0025\n",
      "Epoch 77/100\n",
      "7282/7282 [==============================] - 1s 77us/step - loss: 17.9290 - acc: 0.0018\n",
      "Epoch 78/100\n",
      "7282/7282 [==============================] - 1s 75us/step - loss: 17.8867 - acc: 0.0019\n",
      "Epoch 79/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.9021 - acc: 0.0016\n",
      "Epoch 80/100\n",
      "7282/7282 [==============================] - 1s 76us/step - loss: 17.8709 - acc: 0.0016\n",
      "Epoch 81/100\n",
      "7282/7282 [==============================] - 1s 78us/step - loss: 17.8992 - acc: 0.0027\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9305 - acc: 0.0025\n",
      "Epoch 83/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.8927 - acc: 0.0022\n",
      "Epoch 84/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 17.9365 - acc: 0.0012\n",
      "Epoch 85/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 17.8789 - acc: 0.0025\n",
      "Epoch 86/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9394 - acc: 0.0021\n",
      "Epoch 87/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9349 - acc: 0.0015\n",
      "Epoch 88/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.8959 - acc: 0.0022\n",
      "Epoch 89/100\n",
      "7282/7282 [==============================] - 1s 81us/step - loss: 17.8663 - acc: 0.0014\n",
      "Epoch 90/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.8785 - acc: 0.0021\n",
      "Epoch 91/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.8832 - acc: 0.0022\n",
      "Epoch 92/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9644 - acc: 0.0019\n",
      "Epoch 93/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 17.9283 - acc: 0.0016\n",
      "Epoch 94/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.9250 - acc: 0.0012\n",
      "Epoch 95/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9181 - acc: 0.0021\n",
      "Epoch 96/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.9098 - acc: 0.0018\n",
      "Epoch 97/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.8993 - acc: 0.0016\n",
      "Epoch 98/100\n",
      "7282/7282 [==============================] - 1s 71us/step - loss: 17.8866 - acc: 0.0021\n",
      "Epoch 99/100\n",
      "7282/7282 [==============================] - 1s 72us/step - loss: 17.8806 - acc: 0.0026\n",
      "Epoch 100/100\n",
      "7282/7282 [==============================] - 1s 70us/step - loss: 17.9203 - acc: 0.0023\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "1990/7454 [=======>......................] - ETA: 0s - loss: 16.9815 - acc: 0.0020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8444 - acc: 0.0024\n",
      "Epoch 2/100\n",
      "7454/7454 [==============================] - 1s 69us/step - loss: 17.8547 - acc: 0.0024\n",
      "Epoch 3/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.8455 - acc: 0.0023\n",
      "Epoch 4/100\n",
      "7454/7454 [==============================] - 1s 69us/step - loss: 17.8756 - acc: 0.0016\n",
      "Epoch 5/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8536 - acc: 0.0020\n",
      "Epoch 6/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.8410 - acc: 0.0020\n",
      "Epoch 7/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.7965 - acc: 0.0027\n",
      "Epoch 8/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.7831 - acc: 0.0013\n",
      "Epoch 9/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8182 - acc: 0.0016\n",
      "Epoch 10/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8648 - acc: 0.0015\n",
      "Epoch 11/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8409 - acc: 0.0017\n",
      "Epoch 12/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8729 - acc: 0.0016\n",
      "Epoch 13/100\n",
      "7454/7454 [==============================] - 1s 70us/step - loss: 17.7943 - acc: 0.0021\n",
      "Epoch 14/100\n",
      "7454/7454 [==============================] - 1s 85us/step - loss: 17.7878 - acc: 0.0020\n",
      "Epoch 15/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.7868 - acc: 0.0027\n",
      "Epoch 16/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.8460 - acc: 0.0023\n",
      "Epoch 17/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.8558 - acc: 0.0019\n",
      "Epoch 18/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.8374 - acc: 0.0017\n",
      "Epoch 19/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.7740 - acc: 0.0019\n",
      "Epoch 20/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.8481 - acc: 0.0024\n",
      "Epoch 21/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.7879 - acc: 0.0020\n",
      "Epoch 22/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8422 - acc: 0.0023\n",
      "Epoch 23/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8540 - acc: 0.0023\n",
      "Epoch 24/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8009 - acc: 0.0013\n",
      "Epoch 25/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.8092 - acc: 0.0025\n",
      "Epoch 26/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.8143 - acc: 0.0021\n",
      "Epoch 27/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.7928 - acc: 0.0030\n",
      "Epoch 28/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8328 - acc: 0.0017\n",
      "Epoch 29/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.7953 - acc: 0.0013\n",
      "Epoch 30/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.7857 - acc: 0.0020\n",
      "Epoch 31/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.7939 - acc: 0.0024\n",
      "Epoch 32/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.7659 - acc: 0.0020\n",
      "Epoch 33/100\n",
      "7454/7454 [==============================] - 1s 74us/step - loss: 17.8526 - acc: 0.0020 0s - loss: 17.5767\n",
      "Epoch 34/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8221 - acc: 0.0027\n",
      "Epoch 35/100\n",
      "7454/7454 [==============================] - 1s 71us/step - loss: 17.7855 - acc: 0.0021\n",
      "Epoch 36/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8072 - acc: 0.0019\n",
      "Epoch 37/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8081 - acc: 0.0023\n",
      "Epoch 38/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8106 - acc: 0.0030\n",
      "Epoch 39/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8034 - acc: 0.0024\n",
      "Epoch 40/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.8181 - acc: 0.0028\n",
      "Epoch 41/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8573 - acc: 0.0021\n",
      "Epoch 42/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.7949 - acc: 0.0021\n",
      "Epoch 43/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.7706 - acc: 0.0016\n",
      "Epoch 44/100\n",
      "7454/7454 [==============================] - 1s 74us/step - loss: 17.7850 - acc: 0.0020\n",
      "Epoch 45/100\n",
      "7454/7454 [==============================] - 1s 74us/step - loss: 17.7560 - acc: 0.0028\n",
      "Epoch 46/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.7321 - acc: 0.0019\n",
      "Epoch 47/100\n",
      "7454/7454 [==============================] - 1s 81us/step - loss: 17.8817 - acc: 0.0021\n",
      "Epoch 48/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8011 - acc: 0.0020\n",
      "Epoch 49/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.8088 - acc: 0.0023\n",
      "Epoch 50/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.8288 - acc: 0.0023\n",
      "Epoch 51/100\n",
      "7454/7454 [==============================] - 1s 76us/step - loss: 17.7731 - acc: 0.0025\n",
      "Epoch 52/100\n",
      "7454/7454 [==============================] - 1s 74us/step - loss: 17.8480 - acc: 0.0017\n",
      "Epoch 53/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.7770 - acc: 0.0017\n",
      "Epoch 54/100\n",
      "7454/7454 [==============================] - 1s 74us/step - loss: 17.7707 - acc: 0.0020\n",
      "Epoch 55/100\n",
      "7454/7454 [==============================] - 1s 74us/step - loss: 17.8049 - acc: 0.0017\n",
      "Epoch 56/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.7619 - acc: 0.0027\n",
      "Epoch 57/100\n",
      "7454/7454 [==============================] - 1s 80us/step - loss: 17.7703 - acc: 0.0023\n",
      "Epoch 58/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.8245 - acc: 0.0021\n",
      "Epoch 59/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.7993 - acc: 0.0019\n",
      "Epoch 60/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.8041 - acc: 0.0019\n",
      "Epoch 61/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.7973 - acc: 0.0021\n",
      "Epoch 62/100\n",
      "7454/7454 [==============================] - 1s 74us/step - loss: 17.7638 - acc: 0.0019\n",
      "Epoch 63/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.7686 - acc: 0.0020\n",
      "Epoch 64/100\n",
      "7454/7454 [==============================] - 1s 74us/step - loss: 17.8265 - acc: 0.0016\n",
      "Epoch 65/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.7345 - acc: 0.0027\n",
      "Epoch 66/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.8017 - acc: 0.0020\n",
      "Epoch 67/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.7954 - acc: 0.0021\n",
      "Epoch 68/100\n",
      "7454/7454 [==============================] - 1s 76us/step - loss: 17.7594 - acc: 0.0023\n",
      "Epoch 69/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.7724 - acc: 0.0021\n",
      "Epoch 70/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.7742 - acc: 0.0019\n",
      "Epoch 71/100\n",
      "7454/7454 [==============================] - 1s 75us/step - loss: 17.8192 - acc: 0.0019\n",
      "Epoch 72/100\n",
      "7454/7454 [==============================] - 1s 76us/step - loss: 17.8101 - acc: 0.0021\n",
      "Epoch 73/100\n",
      "7454/7454 [==============================] - 1s 76us/step - loss: 17.8091 - acc: 0.0023\n",
      "Epoch 74/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.7789 - acc: 0.0020\n",
      "Epoch 75/100\n",
      "7454/7454 [==============================] - 1s 76us/step - loss: 17.7572 - acc: 0.0015\n",
      "Epoch 76/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.7237 - acc: 0.0020\n",
      "Epoch 77/100\n",
      "7454/7454 [==============================] - 1s 76us/step - loss: 17.7879 - acc: 0.0023\n",
      "Epoch 78/100\n",
      "7454/7454 [==============================] - 1s 76us/step - loss: 17.8009 - acc: 0.0023\n",
      "Epoch 79/100\n",
      "7454/7454 [==============================] - 1s 79us/step - loss: 17.7634 - acc: 0.0017\n",
      "Epoch 80/100\n",
      "7454/7454 [==============================] - 1s 80us/step - loss: 17.7790 - acc: 0.0016\n",
      "Epoch 81/100\n",
      "7454/7454 [==============================] - 1s 81us/step - loss: 17.7704 - acc: 0.0021\n",
      "Epoch 82/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.8089 - acc: 0.0023\n",
      "Epoch 83/100\n",
      "7454/7454 [==============================] - 1s 92us/step - loss: 17.7423 - acc: 0.0016\n",
      "Epoch 84/100\n",
      "7454/7454 [==============================] - 1s 76us/step - loss: 17.7376 - acc: 0.0021\n",
      "Epoch 85/100\n",
      "7454/7454 [==============================] - 1s 77us/step - loss: 17.8056 - acc: 0.0021\n",
      "Epoch 86/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.8004 - acc: 0.0020\n",
      "Epoch 87/100\n",
      "7454/7454 [==============================] - 1s 72us/step - loss: 17.7780 - acc: 0.0019\n",
      "Epoch 88/100\n",
      "7454/7454 [==============================] - 1s 73us/step - loss: 17.7959 - acc: 0.0021\n",
      "Epoch 89/100\n",
      "7454/7454 [==============================] - 1s 94us/step - loss: 17.7643 - acc: 0.0017\n",
      "Epoch 90/100\n",
      "7454/7454 [==============================] - 1s 81us/step - loss: 17.7741 - acc: 0.0023\n",
      "Epoch 91/100\n",
      "7454/7454 [==============================] - 1s 81us/step - loss: 17.7265 - acc: 0.0027\n",
      "Epoch 92/100\n",
      "7454/7454 [==============================] - 1s 80us/step - loss: 17.7153 - acc: 0.0015\n",
      "Epoch 93/100\n",
      "7454/7454 [==============================] - 1s 97us/step - loss: 17.7588 - acc: 0.0020\n",
      "Epoch 94/100\n",
      "7454/7454 [==============================] - 1s 88us/step - loss: 17.7769 - acc: 0.0017\n",
      "Epoch 95/100\n",
      "7454/7454 [==============================] - 1s 80us/step - loss: 17.7844 - acc: 0.0019\n",
      "Epoch 96/100\n",
      "7454/7454 [==============================] - 1s 81us/step - loss: 17.7521 - acc: 0.0013\n",
      "Epoch 97/100\n",
      "7454/7454 [==============================] - 1s 79us/step - loss: 17.7518 - acc: 0.0020\n",
      "Epoch 98/100\n",
      "7454/7454 [==============================] - 1s 85us/step - loss: 17.8649 - acc: 0.0016\n",
      "Epoch 99/100\n",
      "7454/7454 [==============================] - 1s 78us/step - loss: 17.8017 - acc: 0.0017\n",
      "Epoch 100/100\n",
      "7454/7454 [==============================] - 1s 81us/step - loss: 17.7184 - acc: 0.0024\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "1900/7626 [======>.......................] - ETA: 0s - loss: 17.5623 - acc: 0.0026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7626/7626 [==============================] - 1s 82us/step - loss: 17.6810 - acc: 0.0018\n",
      "Epoch 2/100\n",
      "7626/7626 [==============================] - 1s 97us/step - loss: 17.6475 - acc: 0.0025\n",
      "Epoch 3/100\n",
      "7626/7626 [==============================] - 1s 85us/step - loss: 17.6640 - acc: 0.0017\n",
      "Epoch 4/100\n",
      "7626/7626 [==============================] - 1s 81us/step - loss: 17.6414 - acc: 0.0020\n",
      "Epoch 5/100\n",
      "7626/7626 [==============================] - 1s 80us/step - loss: 17.6626 - acc: 0.0030\n",
      "Epoch 6/100\n",
      "7626/7626 [==============================] - 1s 80us/step - loss: 17.6524 - acc: 0.0024\n",
      "Epoch 7/100\n",
      "7626/7626 [==============================] - 1s 74us/step - loss: 17.6275 - acc: 0.0024\n",
      "Epoch 8/100\n",
      "7626/7626 [==============================] - 1s 72us/step - loss: 17.6780 - acc: 0.0014\n",
      "Epoch 9/100\n",
      "7626/7626 [==============================] - 1s 68us/step - loss: 17.6227 - acc: 0.0016\n",
      "Epoch 10/100\n",
      "7626/7626 [==============================] - 1s 78us/step - loss: 17.5712 - acc: 0.0024\n",
      "Epoch 11/100\n",
      "7626/7626 [==============================] - 1s 77us/step - loss: 17.6325 - acc: 0.0018\n",
      "Epoch 12/100\n",
      "7626/7626 [==============================] - 1s 70us/step - loss: 17.6769 - acc: 0.0018\n",
      "Epoch 13/100\n",
      "7626/7626 [==============================] - 1s 76us/step - loss: 17.6299 - acc: 0.0022\n",
      "Epoch 14/100\n",
      "7626/7626 [==============================] - 1s 72us/step - loss: 17.6125 - acc: 0.0022\n",
      "Epoch 15/100\n",
      "7626/7626 [==============================] - 1s 74us/step - loss: 17.6193 - acc: 0.0020\n",
      "Epoch 16/100\n",
      "7626/7626 [==============================] - 1s 80us/step - loss: 17.6078 - acc: 0.0018\n",
      "Epoch 17/100\n",
      "7626/7626 [==============================] - 1s 94us/step - loss: 17.6406 - acc: 0.0020\n",
      "Epoch 18/100\n",
      "7626/7626 [==============================] - 1s 75us/step - loss: 17.6503 - acc: 0.0021\n",
      "Epoch 19/100\n",
      "7626/7626 [==============================] - 1s 77us/step - loss: 17.6713 - acc: 0.0014\n",
      "Epoch 20/100\n",
      "7626/7626 [==============================] - 1s 78us/step - loss: 17.6605 - acc: 0.0029\n",
      "Epoch 21/100\n",
      "7626/7626 [==============================] - 1s 75us/step - loss: 17.6079 - acc: 0.0024\n",
      "Epoch 22/100\n",
      "7626/7626 [==============================] - 1s 75us/step - loss: 17.5847 - acc: 0.0028\n",
      "Epoch 23/100\n",
      "7626/7626 [==============================] - 1s 75us/step - loss: 17.6903 - acc: 0.0020\n",
      "Epoch 24/100\n",
      "7626/7626 [==============================] - 1s 76us/step - loss: 17.6725 - acc: 0.0025\n",
      "Epoch 25/100\n",
      "7626/7626 [==============================] - 1s 79us/step - loss: 17.6258 - acc: 0.0022\n",
      "Epoch 26/100\n",
      "7626/7626 [==============================] - 1s 91us/step - loss: 17.6309 - acc: 0.0022\n",
      "Epoch 27/100\n",
      "7626/7626 [==============================] - 1s 89us/step - loss: 17.6157 - acc: 0.0020\n",
      "Epoch 28/100\n",
      "7626/7626 [==============================] - 1s 77us/step - loss: 17.5975 - acc: 0.0018\n",
      "Epoch 29/100\n",
      "7626/7626 [==============================] - 1s 79us/step - loss: 17.6322 - acc: 0.0026\n",
      "Epoch 30/100\n",
      "7626/7626 [==============================] - 1s 77us/step - loss: 17.6422 - acc: 0.0020\n",
      "Epoch 31/100\n",
      "7626/7626 [==============================] - 1s 83us/step - loss: 17.6203 - acc: 0.0026\n",
      "Epoch 32/100\n",
      "7626/7626 [==============================] - 1s 79us/step - loss: 17.6436 - acc: 0.0020\n",
      "Epoch 33/100\n",
      "7626/7626 [==============================] - 1s 97us/step - loss: 17.6727 - acc: 0.0028\n",
      "Epoch 34/100\n",
      "7626/7626 [==============================] - 1s 73us/step - loss: 17.6433 - acc: 0.0022\n",
      "Epoch 35/100\n",
      "7626/7626 [==============================] - 1s 68us/step - loss: 17.6128 - acc: 0.0022\n",
      "Epoch 36/100\n",
      "7626/7626 [==============================] - 1s 83us/step - loss: 17.6729 - acc: 0.0025\n",
      "Epoch 37/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6773 - acc: 0.0025\n",
      "Epoch 38/100\n",
      "7626/7626 [==============================] - 1s 77us/step - loss: 17.6097 - acc: 0.0024\n",
      "Epoch 39/100\n",
      "7626/7626 [==============================] - 1s 75us/step - loss: 17.6079 - acc: 0.0017\n",
      "Epoch 40/100\n",
      "7626/7626 [==============================] - 0s 56us/step - loss: 17.6520 - acc: 0.0020\n",
      "Epoch 41/100\n",
      "7626/7626 [==============================] - 1s 73us/step - loss: 17.6202 - acc: 0.0017\n",
      "Epoch 42/100\n",
      "7626/7626 [==============================] - 1s 80us/step - loss: 17.6073 - acc: 0.0022\n",
      "Epoch 43/100\n",
      "7626/7626 [==============================] - 0s 60us/step - loss: 17.5966 - acc: 0.0020\n",
      "Epoch 44/100\n",
      "7626/7626 [==============================] - 1s 72us/step - loss: 17.5988 - acc: 0.0018\n",
      "Epoch 45/100\n",
      "7626/7626 [==============================] - 0s 60us/step - loss: 17.5883 - acc: 0.0018\n",
      "Epoch 46/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6082 - acc: 0.0026\n",
      "Epoch 47/100\n",
      "7626/7626 [==============================] - 1s 71us/step - loss: 17.6598 - acc: 0.0024\n",
      "Epoch 48/100\n",
      "7626/7626 [==============================] - 1s 73us/step - loss: 17.6288 - acc: 0.0031\n",
      "Epoch 49/100\n",
      "7626/7626 [==============================] - 1s 73us/step - loss: 17.6453 - acc: 0.0024\n",
      "Epoch 50/100\n",
      "7626/7626 [==============================] - 0s 62us/step - loss: 17.5959 - acc: 0.0022\n",
      "Epoch 51/100\n",
      "7626/7626 [==============================] - 0s 60us/step - loss: 17.6299 - acc: 0.0025\n",
      "Epoch 52/100\n",
      "7626/7626 [==============================] - 0s 56us/step - loss: 17.6041 - acc: 0.0017\n",
      "Epoch 53/100\n",
      "7626/7626 [==============================] - 0s 63us/step - loss: 17.5957 - acc: 0.0025\n",
      "Epoch 54/100\n",
      "7626/7626 [==============================] - 1s 66us/step - loss: 17.6233 - acc: 0.0020\n",
      "Epoch 55/100\n",
      "7626/7626 [==============================] - 0s 64us/step - loss: 17.5757 - acc: 0.0033\n",
      "Epoch 56/100\n",
      "7626/7626 [==============================] - 0s 62us/step - loss: 17.5927 - acc: 0.0028\n",
      "Epoch 57/100\n",
      "7626/7626 [==============================] - 0s 60us/step - loss: 17.6098 - acc: 0.0024\n",
      "Epoch 58/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6919 - acc: 0.0026\n",
      "Epoch 59/100\n",
      "7626/7626 [==============================] - 0s 55us/step - loss: 17.6208 - acc: 0.0021\n",
      "Epoch 60/100\n",
      "7626/7626 [==============================] - 0s 55us/step - loss: 17.5832 - acc: 0.0021\n",
      "Epoch 61/100\n",
      "7626/7626 [==============================] - 0s 58us/step - loss: 17.6358 - acc: 0.0029\n",
      "Epoch 62/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6620 - acc: 0.0018\n",
      "Epoch 63/100\n",
      "7626/7626 [==============================] - 0s 55us/step - loss: 17.6015 - acc: 0.0029\n",
      "Epoch 64/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.5578 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "7626/7626 [==============================] - 0s 55us/step - loss: 17.6962 - acc: 0.0014\n",
      "Epoch 66/100\n",
      "7626/7626 [==============================] - 0s 58us/step - loss: 17.6577 - acc: 0.0021\n",
      "Epoch 67/100\n",
      "7626/7626 [==============================] - 0s 63us/step - loss: 17.6195 - acc: 0.0026\n",
      "Epoch 68/100\n",
      "7626/7626 [==============================] - 0s 61us/step - loss: 17.6321 - acc: 0.0028\n",
      "Epoch 69/100\n",
      "7626/7626 [==============================] - 0s 60us/step - loss: 17.6112 - acc: 0.0026\n",
      "Epoch 70/100\n",
      "7626/7626 [==============================] - 0s 58us/step - loss: 17.6362 - acc: 0.0024\n",
      "Epoch 71/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6464 - acc: 0.0026\n",
      "Epoch 72/100\n",
      "7626/7626 [==============================] - 0s 63us/step - loss: 17.6106 - acc: 0.0016\n",
      "Epoch 73/100\n",
      "7626/7626 [==============================] - 1s 79us/step - loss: 17.6249 - acc: 0.0020\n",
      "Epoch 74/100\n",
      "7626/7626 [==============================] - 1s 103us/step - loss: 17.6485 - acc: 0.0025\n",
      "Epoch 75/100\n",
      "7626/7626 [==============================] - 1s 74us/step - loss: 17.5528 - acc: 0.0020\n",
      "Epoch 76/100\n",
      "7626/7626 [==============================] - 0s 63us/step - loss: 17.5988 - acc: 0.0016\n",
      "Epoch 77/100\n",
      "7626/7626 [==============================] - 1s 72us/step - loss: 17.5709 - acc: 0.0022\n",
      "Epoch 78/100\n",
      "7626/7626 [==============================] - 1s 73us/step - loss: 17.5773 - acc: 0.0018\n",
      "Epoch 79/100\n",
      "7626/7626 [==============================] - 1s 98us/step - loss: 17.6030 - acc: 0.0022\n",
      "Epoch 80/100\n",
      "7626/7626 [==============================] - 1s 102us/step - loss: 17.6522 - acc: 0.0017\n",
      "Epoch 81/100\n",
      "7626/7626 [==============================] - 1s 112us/step - loss: 17.6066 - acc: 0.0026\n",
      "Epoch 82/100\n",
      "7626/7626 [==============================] - 1s 70us/step - loss: 17.5958 - acc: 0.0024\n",
      "Epoch 83/100\n",
      "7626/7626 [==============================] - 1s 81us/step - loss: 17.6215 - acc: 0.0022\n",
      "Epoch 84/100\n",
      "7626/7626 [==============================] - 1s 87us/step - loss: 17.5925 - acc: 0.0017\n",
      "Epoch 85/100\n",
      "7626/7626 [==============================] - 1s 69us/step - loss: 17.5818 - acc: 0.0021\n",
      "Epoch 86/100\n",
      "7626/7626 [==============================] - 0s 65us/step - loss: 17.6329 - acc: 0.0031\n",
      "Epoch 87/100\n",
      "7626/7626 [==============================] - 0s 62us/step - loss: 17.5795 - acc: 0.0024\n",
      "Epoch 88/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6027 - acc: 0.0016\n",
      "Epoch 89/100\n",
      "7626/7626 [==============================] - 0s 56us/step - loss: 17.6101 - acc: 0.0018\n",
      "Epoch 90/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6211 - acc: 0.0022\n",
      "Epoch 91/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6281 - acc: 0.0031\n",
      "Epoch 92/100\n",
      "7626/7626 [==============================] - 0s 58us/step - loss: 17.5959 - acc: 0.0024\n",
      "Epoch 93/100\n",
      "7626/7626 [==============================] - 0s 54us/step - loss: 17.5883 - acc: 0.0024\n",
      "Epoch 94/100\n",
      "7626/7626 [==============================] - 1s 70us/step - loss: 17.6179 - acc: 0.0020\n",
      "Epoch 95/100\n",
      "7626/7626 [==============================] - 0s 61us/step - loss: 17.5670 - acc: 0.0020\n",
      "Epoch 96/100\n",
      "7626/7626 [==============================] - 0s 63us/step - loss: 17.6025 - acc: 0.0021\n",
      "Epoch 97/100\n",
      "7626/7626 [==============================] - 1s 67us/step - loss: 17.6011 - acc: 0.0016\n",
      "Epoch 98/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6083 - acc: 0.0020\n",
      "Epoch 99/100\n",
      "7626/7626 [==============================] - 0s 57us/step - loss: 17.6741 - acc: 0.0014\n",
      "Epoch 100/100\n",
      "7626/7626 [==============================] - 0s 58us/step - loss: 17.6634 - acc: 0.0022\n",
      "172/172 [==============================] - 0s 0us/step\n",
      "Epoch 1/100\n",
      "3120/7798 [===========>..................] - ETA: 0s - loss: 17.7084 - acc: 0.0013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6519 - acc: 0.0018\n",
      "Epoch 2/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6222 - acc: 0.0022\n",
      "Epoch 3/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6165 - acc: 0.0023\n",
      "Epoch 4/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6741 - acc: 0.0022\n",
      "Epoch 5/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6555 - acc: 0.0017\n",
      "Epoch 6/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6338 - acc: 0.0022\n",
      "Epoch 7/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6531 - acc: 0.0023\n",
      "Epoch 8/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6421 - acc: 0.0019\n",
      "Epoch 9/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6904 - acc: 0.0021\n",
      "Epoch 10/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6078 - acc: 0.0014\n",
      "Epoch 11/100\n",
      "7798/7798 [==============================] - 0s 60us/step - loss: 17.6482 - acc: 0.0028\n",
      "Epoch 12/100\n",
      "7798/7798 [==============================] - 1s 71us/step - loss: 17.7069 - acc: 0.0023\n",
      "Epoch 13/100\n",
      "7798/7798 [==============================] - 1s 70us/step - loss: 17.6344 - acc: 0.0024\n",
      "Epoch 14/100\n",
      "7798/7798 [==============================] - 1s 84us/step - loss: 17.6705 - acc: 0.0023\n",
      "Epoch 15/100\n",
      "7798/7798 [==============================] - 1s 71us/step - loss: 17.6573 - acc: 0.0018\n",
      "Epoch 16/100\n",
      "7798/7798 [==============================] - 0s 62us/step - loss: 17.6168 - acc: 0.0024\n",
      "Epoch 17/100\n",
      "7798/7798 [==============================] - 1s 71us/step - loss: 17.6385 - acc: 0.0019\n",
      "Epoch 18/100\n",
      "7798/7798 [==============================] - 0s 63us/step - loss: 17.6485 - acc: 0.0024\n",
      "Epoch 19/100\n",
      "7798/7798 [==============================] - 1s 67us/step - loss: 17.6147 - acc: 0.0021\n",
      "Epoch 20/100\n",
      "7798/7798 [==============================] - 0s 61us/step - loss: 17.6397 - acc: 0.0021\n",
      "Epoch 21/100\n",
      "7798/7798 [==============================] - 1s 103us/step - loss: 17.6382 - acc: 0.0024\n",
      "Epoch 22/100\n",
      "7798/7798 [==============================] - 1s 108us/step - loss: 17.6692 - acc: 0.00170s - loss: 17.6034 - acc: 0.00\n",
      "Epoch 23/100\n",
      "7798/7798 [==============================] - 1s 103us/step - loss: 17.6607 - acc: 0.0029\n",
      "Epoch 24/100\n",
      "7798/7798 [==============================] - 1s 144us/step - loss: 17.6699 - acc: 0.0023\n",
      "Epoch 25/100\n",
      "7798/7798 [==============================] - 1s 113us/step - loss: 17.6763 - acc: 0.0027\n",
      "Epoch 26/100\n",
      "7798/7798 [==============================] - 1s 146us/step - loss: 17.6681 - acc: 0.0019\n",
      "Epoch 27/100\n",
      "7798/7798 [==============================] - 1s 134us/step - loss: 17.7235 - acc: 0.0023\n",
      "Epoch 28/100\n",
      "7798/7798 [==============================] - 1s 71us/step - loss: 17.6567 - acc: 0.0024\n",
      "Epoch 29/100\n",
      "7798/7798 [==============================] - 0s 60us/step - loss: 17.6508 - acc: 0.0021\n",
      "Epoch 30/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6814 - acc: 0.0021\n",
      "Epoch 31/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6551 - acc: 0.0021\n",
      "Epoch 32/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6284 - acc: 0.0021\n",
      "Epoch 33/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6625 - acc: 0.0021\n",
      "Epoch 34/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6022 - acc: 0.0021\n",
      "Epoch 35/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6369 - acc: 0.0022\n",
      "Epoch 36/100\n",
      "7798/7798 [==============================] - 0s 60us/step - loss: 17.6171 - acc: 0.0022\n",
      "Epoch 37/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6032 - acc: 0.0026\n",
      "Epoch 38/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6525 - acc: 0.0022\n",
      "Epoch 39/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6311 - acc: 0.0024\n",
      "Epoch 40/100\n",
      "7798/7798 [==============================] - 0s 63us/step - loss: 17.6373 - acc: 0.0023\n",
      "Epoch 41/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6061 - acc: 0.0027\n",
      "Epoch 42/100\n",
      "7798/7798 [==============================] - 1s 82us/step - loss: 17.6376 - acc: 0.0022\n",
      "Epoch 43/100\n",
      "7798/7798 [==============================] - 1s 73us/step - loss: 17.5899 - acc: 0.0023\n",
      "Epoch 44/100\n",
      "7798/7798 [==============================] - 0s 59us/step - loss: 17.6776 - acc: 0.0023\n",
      "Epoch 45/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6129 - acc: 0.0021\n",
      "Epoch 46/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6208 - acc: 0.0029\n",
      "Epoch 47/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6124 - acc: 0.0027\n",
      "Epoch 48/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6666 - acc: 0.0022\n",
      "Epoch 49/100\n",
      "7798/7798 [==============================] - 0s 60us/step - loss: 17.6101 - acc: 0.0021\n",
      "Epoch 50/100\n",
      "7798/7798 [==============================] - 0s 55us/step - loss: 17.6021 - acc: 0.0022\n",
      "Epoch 51/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6035 - acc: 0.0024\n",
      "Epoch 52/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6242 - acc: 0.0026\n",
      "Epoch 53/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6379 - acc: 0.0021\n",
      "Epoch 54/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.5949 - acc: 0.0023\n",
      "Epoch 55/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6347 - acc: 0.0017\n",
      "Epoch 56/100\n",
      "7798/7798 [==============================] - 0s 64us/step - loss: 17.6343 - acc: 0.0026\n",
      "Epoch 57/100\n",
      "7798/7798 [==============================] - 1s 78us/step - loss: 17.5822 - acc: 0.0022\n",
      "Epoch 58/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6320 - acc: 0.0019\n",
      "Epoch 59/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6552 - acc: 0.0021\n",
      "Epoch 60/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6218 - acc: 0.0022\n",
      "Epoch 61/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6340 - acc: 0.0027\n",
      "Epoch 62/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6351 - acc: 0.0017\n",
      "Epoch 63/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6170 - acc: 0.0022\n",
      "Epoch 64/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.7158 - acc: 0.0026\n",
      "Epoch 65/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.5948 - acc: 0.0024\n",
      "Epoch 66/100\n",
      "7798/7798 [==============================] - 1s 87us/step - loss: 17.6486 - acc: 0.0023\n",
      "Epoch 67/100\n",
      "7798/7798 [==============================] - 1s 83us/step - loss: 17.6044 - acc: 0.0028\n",
      "Epoch 68/100\n",
      "7798/7798 [==============================] - 1s 89us/step - loss: 17.6305 - acc: 0.0021\n",
      "Epoch 69/100\n",
      "7798/7798 [==============================] - 1s 99us/step - loss: 17.6883 - acc: 0.0022\n",
      "Epoch 70/100\n",
      "7798/7798 [==============================] - 1s 86us/step - loss: 17.6008 - acc: 0.0021\n",
      "Epoch 71/100\n",
      "7798/7798 [==============================] - 0s 63us/step - loss: 17.5651 - acc: 0.0024\n",
      "Epoch 72/100\n",
      "7798/7798 [==============================] - 0s 59us/step - loss: 17.6167 - acc: 0.0023\n",
      "Epoch 73/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.5874 - acc: 0.0017\n",
      "Epoch 74/100\n",
      "7798/7798 [==============================] - 0s 62us/step - loss: 17.6374 - acc: 0.0018\n",
      "Epoch 75/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6017 - acc: 0.0022\n",
      "Epoch 76/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.5762 - acc: 0.0022\n",
      "Epoch 77/100\n",
      "7798/7798 [==============================] - 0s 56us/step - loss: 17.6103 - acc: 0.0024\n",
      "Epoch 78/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.5966 - acc: 0.0021\n",
      "Epoch 79/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6591 - acc: 0.0019\n",
      "Epoch 80/100\n",
      "7798/7798 [==============================] - 0s 59us/step - loss: 17.5957 - acc: 0.0019\n",
      "Epoch 81/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.5967 - acc: 0.0033\n",
      "Epoch 82/100\n",
      "7798/7798 [==============================] - 0s 57us/step - loss: 17.6342 - acc: 0.0019\n",
      "Epoch 83/100\n",
      "7798/7798 [==============================] - 0s 63us/step - loss: 17.6120 - acc: 0.0021\n",
      "Epoch 84/100\n",
      "7798/7798 [==============================] - 0s 64us/step - loss: 17.5897 - acc: 0.0022\n",
      "Epoch 85/100\n",
      "7798/7798 [==============================] - 0s 59us/step - loss: 17.6301 - acc: 0.0021\n",
      "Epoch 86/100\n",
      "7798/7798 [==============================] - 1s 67us/step - loss: 17.5673 - acc: 0.0019\n",
      "Epoch 87/100\n",
      "7798/7798 [==============================] - 1s 85us/step - loss: 17.6889 - acc: 0.0015\n",
      "Epoch 88/100\n",
      "7798/7798 [==============================] - 1s 69us/step - loss: 17.6150 - acc: 0.0021\n",
      "Epoch 89/100\n",
      "7798/7798 [==============================] - 0s 58us/step - loss: 17.6181 - acc: 0.0027\n",
      "Epoch 90/100\n",
      "7798/7798 [==============================] - 1s 69us/step - loss: 17.6390 - acc: 0.0028\n",
      "Epoch 91/100\n",
      "7798/7798 [==============================] - 1s 82us/step - loss: 17.6226 - acc: 0.0019\n",
      "Epoch 92/100\n",
      "7798/7798 [==============================] - 0s 62us/step - loss: 17.6126 - acc: 0.0024\n",
      "Epoch 93/100\n",
      "7798/7798 [==============================] - 1s 93us/step - loss: 17.6818 - acc: 0.0024\n",
      "Epoch 94/100\n",
      "7798/7798 [==============================] - 1s 95us/step - loss: 17.5664 - acc: 0.0029 0s - loss: 18.1627\n",
      "Epoch 95/100\n",
      "7798/7798 [==============================] - 1s 89us/step - loss: 17.6436 - acc: 0.0028\n",
      "Epoch 96/100\n",
      "7798/7798 [==============================] - 1s 67us/step - loss: 17.5880 - acc: 0.0024\n",
      "Epoch 97/100\n",
      "7798/7798 [==============================] - 0s 61us/step - loss: 17.6308 - acc: 0.0024\n",
      "Epoch 98/100\n",
      "7798/7798 [==============================] - 1s 85us/step - loss: 17.6237 - acc: 0.0019\n",
      "Epoch 99/100\n",
      "7798/7798 [==============================] - 1s 88us/step - loss: 17.6303 - acc: 0.0026\n",
      "Epoch 100/100\n",
      "7798/7798 [==============================] - 0s 59us/step - loss: 17.6552 - acc: 0.0022\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "1770/7970 [=====>........................] - ETA: 0s - loss: 18.2020 - acc: 0.0011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7970/7970 [==============================] - 1s 107us/step - loss: 17.6636 - acc: 0.0023\n",
      "Epoch 2/100\n",
      "7970/7970 [==============================] - 1s 94us/step - loss: 17.5517 - acc: 0.0020\n",
      "Epoch 3/100\n",
      "7970/7970 [==============================] - 0s 60us/step - loss: 17.6789 - acc: 0.0028\n",
      "Epoch 4/100\n",
      "7970/7970 [==============================] - 0s 55us/step - loss: 17.5915 - acc: 0.0020\n",
      "Epoch 5/100\n",
      "7970/7970 [==============================] - 0s 60us/step - loss: 17.5656 - acc: 0.0024\n",
      "Epoch 6/100\n",
      "7970/7970 [==============================] - 0s 58us/step - loss: 17.6204 - acc: 0.0020\n",
      "Epoch 7/100\n",
      "7970/7970 [==============================] - 0s 57us/step - loss: 17.6090 - acc: 0.0025\n",
      "Epoch 8/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.6057 - acc: 0.0018\n",
      "Epoch 9/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.6638 - acc: 0.0019\n",
      "Epoch 10/100\n",
      "7970/7970 [==============================] - 0s 58us/step - loss: 17.6373 - acc: 0.0023\n",
      "Epoch 11/100\n",
      "7970/7970 [==============================] - 0s 58us/step - loss: 17.5890 - acc: 0.0021\n",
      "Epoch 12/100\n",
      "7970/7970 [==============================] - 0s 57us/step - loss: 17.6658 - acc: 0.0025\n",
      "Epoch 13/100\n",
      "7970/7970 [==============================] - 0s 58us/step - loss: 17.5950 - acc: 0.0024\n",
      "Epoch 14/100\n",
      "7970/7970 [==============================] - 0s 58us/step - loss: 17.5827 - acc: 0.0019\n",
      "Epoch 15/100\n",
      "7970/7970 [==============================] - 1s 79us/step - loss: 17.6542 - acc: 0.0024\n",
      "Epoch 16/100\n",
      "7970/7970 [==============================] - 1s 82us/step - loss: 17.5502 - acc: 0.0023\n",
      "Epoch 17/100\n",
      "7970/7970 [==============================] - 1s 74us/step - loss: 17.6107 - acc: 0.0026\n",
      "Epoch 18/100\n",
      "7970/7970 [==============================] - 1s 72us/step - loss: 17.6153 - acc: 0.0024\n",
      "Epoch 19/100\n",
      "7970/7970 [==============================] - 0s 61us/step - loss: 17.5821 - acc: 0.0023\n",
      "Epoch 20/100\n",
      "7970/7970 [==============================] - 1s 66us/step - loss: 17.5864 - acc: 0.0025\n",
      "Epoch 21/100\n",
      "7970/7970 [==============================] - 1s 66us/step - loss: 17.6260 - acc: 0.0024\n",
      "Epoch 22/100\n",
      "7970/7970 [==============================] - 1s 79us/step - loss: 17.6010 - acc: 0.0016\n",
      "Epoch 23/100\n",
      "7970/7970 [==============================] - 1s 68us/step - loss: 17.6035 - acc: 0.0023\n",
      "Epoch 24/100\n",
      "7970/7970 [==============================] - 1s 67us/step - loss: 17.6328 - acc: 0.0025\n",
      "Epoch 25/100\n",
      "7970/7970 [==============================] - 1s 69us/step - loss: 17.5830 - acc: 0.0025\n",
      "Epoch 26/100\n",
      "7970/7970 [==============================] - 1s 74us/step - loss: 17.5606 - acc: 0.0020\n",
      "Epoch 27/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.5882 - acc: 0.0021\n",
      "Epoch 28/100\n",
      "7970/7970 [==============================] - 1s 86us/step - loss: 17.5621 - acc: 0.0024\n",
      "Epoch 29/100\n",
      "7970/7970 [==============================] - 1s 64us/step - loss: 17.5978 - acc: 0.0025\n",
      "Epoch 30/100\n",
      "7970/7970 [==============================] - 1s 95us/step - loss: 17.5420 - acc: 0.0025\n",
      "Epoch 31/100\n",
      "7970/7970 [==============================] - 1s 84us/step - loss: 17.5428 - acc: 0.0025\n",
      "Epoch 32/100\n",
      "7970/7970 [==============================] - 1s 65us/step - loss: 17.5935 - acc: 0.0021\n",
      "Epoch 33/100\n",
      "7970/7970 [==============================] - 0s 61us/step - loss: 17.5769 - acc: 0.0031\n",
      "Epoch 34/100\n",
      "7970/7970 [==============================] - 1s 86us/step - loss: 17.6295 - acc: 0.0021\n",
      "Epoch 35/100\n",
      "7970/7970 [==============================] - 1s 74us/step - loss: 17.5553 - acc: 0.0024\n",
      "Epoch 36/100\n",
      "7970/7970 [==============================] - 1s 75us/step - loss: 17.6178 - acc: 0.0021\n",
      "Epoch 37/100\n",
      "7970/7970 [==============================] - 1s 71us/step - loss: 17.5816 - acc: 0.0018\n",
      "Epoch 38/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.6125 - acc: 0.0018\n",
      "Epoch 39/100\n",
      "7970/7970 [==============================] - 0s 56us/step - loss: 17.6277 - acc: 0.0019\n",
      "Epoch 40/100\n",
      "7970/7970 [==============================] - 1s 77us/step - loss: 17.6101 - acc: 0.0026\n",
      "Epoch 41/100\n",
      "7970/7970 [==============================] - 1s 78us/step - loss: 17.5582 - acc: 0.0019\n",
      "Epoch 42/100\n",
      "7970/7970 [==============================] - 1s 64us/step - loss: 17.5580 - acc: 0.0023\n",
      "Epoch 43/100\n",
      "7970/7970 [==============================] - 0s 60us/step - loss: 17.6182 - acc: 0.0023\n",
      "Epoch 44/100\n",
      "7970/7970 [==============================] - 1s 69us/step - loss: 17.5968 - acc: 0.0025\n",
      "Epoch 45/100\n",
      "7970/7970 [==============================] - 1s 73us/step - loss: 17.5866 - acc: 0.0020\n",
      "Epoch 46/100\n",
      "7970/7970 [==============================] - 0s 60us/step - loss: 17.5716 - acc: 0.0020\n",
      "Epoch 47/100\n",
      "7970/7970 [==============================] - 1s 68us/step - loss: 17.5424 - acc: 0.0023\n",
      "Epoch 48/100\n",
      "7970/7970 [==============================] - 0s 63us/step - loss: 17.5243 - acc: 0.0018\n",
      "Epoch 49/100\n",
      "7970/7970 [==============================] - 0s 62us/step - loss: 17.5771 - acc: 0.0021\n",
      "Epoch 50/100\n",
      "7970/7970 [==============================] - 0s 60us/step - loss: 17.5487 - acc: 0.0029\n",
      "Epoch 51/100\n",
      "7970/7970 [==============================] - 1s 70us/step - loss: 17.5947 - acc: 0.0019\n",
      "Epoch 52/100\n",
      "7970/7970 [==============================] - 1s 67us/step - loss: 17.5505 - acc: 0.0023\n",
      "Epoch 53/100\n",
      "7970/7970 [==============================] - 1s 66us/step - loss: 17.5802 - acc: 0.0020\n",
      "Epoch 54/100\n",
      "7970/7970 [==============================] - 1s 64us/step - loss: 17.5583 - acc: 0.0028\n",
      "Epoch 55/100\n",
      "7970/7970 [==============================] - 0s 62us/step - loss: 17.5503 - acc: 0.0023\n",
      "Epoch 56/100\n",
      "7970/7970 [==============================] - 0s 58us/step - loss: 17.5779 - acc: 0.0018\n",
      "Epoch 57/100\n",
      "7970/7970 [==============================] - 1s 65us/step - loss: 17.5707 - acc: 0.0023\n",
      "Epoch 58/100\n",
      "7970/7970 [==============================] - 1s 72us/step - loss: 17.5820 - acc: 0.0023\n",
      "Epoch 59/100\n",
      "7970/7970 [==============================] - 1s 66us/step - loss: 17.5810 - acc: 0.0026\n",
      "Epoch 60/100\n",
      "7970/7970 [==============================] - 1s 146us/step - loss: 17.5272 - acc: 0.0019\n",
      "Epoch 61/100\n",
      "7970/7970 [==============================] - 1s 86us/step - loss: 17.5829 - acc: 0.0023\n",
      "Epoch 62/100\n",
      "7970/7970 [==============================] - 1s 125us/step - loss: 17.5554 - acc: 0.0019\n",
      "Epoch 63/100\n",
      "7970/7970 [==============================] - 1s 121us/step - loss: 17.5568 - acc: 0.0020\n",
      "Epoch 64/100\n",
      "7970/7970 [==============================] - 1s 84us/step - loss: 17.6017 - acc: 0.0029\n",
      "Epoch 65/100\n",
      "7970/7970 [==============================] - 1s 82us/step - loss: 17.5968 - acc: 0.0025\n",
      "Epoch 66/100\n",
      "7970/7970 [==============================] - 1s 71us/step - loss: 17.5507 - acc: 0.0021\n",
      "Epoch 67/100\n",
      "7970/7970 [==============================] - 1s 105us/step - loss: 17.5984 - acc: 0.0025\n",
      "Epoch 68/100\n",
      "7970/7970 [==============================] - 0s 62us/step - loss: 17.5602 - acc: 0.0020\n",
      "Epoch 69/100\n",
      "7970/7970 [==============================] - 0s 62us/step - loss: 17.5373 - acc: 0.0023\n",
      "Epoch 70/100\n",
      "7970/7970 [==============================] - 0s 61us/step - loss: 17.5289 - acc: 0.0020\n",
      "Epoch 71/100\n",
      "7970/7970 [==============================] - 1s 67us/step - loss: 17.5738 - acc: 0.0020\n",
      "Epoch 72/100\n",
      "7970/7970 [==============================] - 1s 65us/step - loss: 17.5614 - acc: 0.0013\n",
      "Epoch 73/100\n",
      "7970/7970 [==============================] - 0s 57us/step - loss: 17.5382 - acc: 0.0025\n",
      "Epoch 74/100\n",
      "7970/7970 [==============================] - 1s 66us/step - loss: 17.5794 - acc: 0.0026\n",
      "Epoch 75/100\n",
      "7970/7970 [==============================] - 1s 71us/step - loss: 17.5987 - acc: 0.0024\n",
      "Epoch 76/100\n",
      "7970/7970 [==============================] - 0s 61us/step - loss: 17.5625 - acc: 0.0019\n",
      "Epoch 77/100\n",
      "7970/7970 [==============================] - 0s 61us/step - loss: 17.5452 - acc: 0.0028\n",
      "Epoch 78/100\n",
      "7970/7970 [==============================] - 0s 57us/step - loss: 17.5816 - acc: 0.0025\n",
      "Epoch 79/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.5707 - acc: 0.0026\n",
      "Epoch 80/100\n",
      "7970/7970 [==============================] - 0s 60us/step - loss: 17.5771 - acc: 0.0020\n",
      "Epoch 81/100\n",
      "7970/7970 [==============================] - 0s 57us/step - loss: 17.5582 - acc: 0.0023\n",
      "Epoch 82/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.5876 - acc: 0.0025\n",
      "Epoch 83/100\n",
      "7970/7970 [==============================] - 1s 87us/step - loss: 17.5584 - acc: 0.0025\n",
      "Epoch 84/100\n",
      "7970/7970 [==============================] - 1s 105us/step - loss: 17.6680 - acc: 0.0025\n",
      "Epoch 85/100\n",
      "7970/7970 [==============================] - 1s 135us/step - loss: 17.5696 - acc: 0.0018\n",
      "Epoch 86/100\n",
      "7970/7970 [==============================] - 1s 131us/step - loss: 17.5819 - acc: 0.0021\n",
      "Epoch 87/100\n",
      "7970/7970 [==============================] - 1s 146us/step - loss: 17.5877 - acc: 0.0021\n",
      "Epoch 88/100\n",
      "7970/7970 [==============================] - 1s 117us/step - loss: 17.5995 - acc: 0.0026\n",
      "Epoch 89/100\n",
      "7970/7970 [==============================] - 1s 112us/step - loss: 17.5749 - acc: 0.0019\n",
      "Epoch 90/100\n",
      "7970/7970 [==============================] - 1s 121us/step - loss: 17.5416 - acc: 0.0025\n",
      "Epoch 91/100\n",
      "7970/7970 [==============================] - 1s 104us/step - loss: 17.5897 - acc: 0.0023\n",
      "Epoch 92/100\n",
      "7970/7970 [==============================] - 1s 97us/step - loss: 17.6212 - acc: 0.0024\n",
      "Epoch 93/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.5625 - acc: 0.0015\n",
      "Epoch 94/100\n",
      "7970/7970 [==============================] - 1s 66us/step - loss: 17.5489 - acc: 0.0026\n",
      "Epoch 95/100\n",
      "7970/7970 [==============================] - 0s 61us/step - loss: 17.5822 - acc: 0.0018\n",
      "Epoch 96/100\n",
      "7970/7970 [==============================] - 0s 61us/step - loss: 17.5493 - acc: 0.0025\n",
      "Epoch 97/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.6139 - acc: 0.0028\n",
      "Epoch 98/100\n",
      "7970/7970 [==============================] - 1s 65us/step - loss: 17.5653 - acc: 0.0026\n",
      "Epoch 99/100\n",
      "7970/7970 [==============================] - 0s 59us/step - loss: 17.5857 - acc: 0.0018\n",
      "Epoch 100/100\n",
      "7970/7970 [==============================] - 0s 61us/step - loss: 17.6222 - acc: 0.0028\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2900/8142 [=========>....................] - ETA: 0s - loss: 17.9946 - acc: 0.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8142/8142 [==============================] - 0s 58us/step - loss: 18.3502 - acc: 0.0022\n",
      "Epoch 2/100\n",
      "8142/8142 [==============================] - 1s 62us/step - loss: 18.2506 - acc: 0.0023\n",
      "Epoch 3/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 18.2892 - acc: 0.0020\n",
      "Epoch 4/100\n",
      "8142/8142 [==============================] - 1s 67us/step - loss: 18.2890 - acc: 0.0022\n",
      "Epoch 5/100\n",
      "8142/8142 [==============================] - 1s 62us/step - loss: 18.2861 - acc: 0.0023\n",
      "Epoch 6/100\n",
      "8142/8142 [==============================] - 1s 68us/step - loss: 18.2262 - acc: 0.0023\n",
      "Epoch 7/100\n",
      "8142/8142 [==============================] - 1s 67us/step - loss: 18.2297 - acc: 0.0023\n",
      "Epoch 8/100\n",
      "8142/8142 [==============================] - 1s 62us/step - loss: 18.2041 - acc: 0.0031\n",
      "Epoch 9/100\n",
      "8142/8142 [==============================] - 1s 66us/step - loss: 18.1479 - acc: 0.0027\n",
      "Epoch 10/100\n",
      "8142/8142 [==============================] - 1s 80us/step - loss: 18.1593 - acc: 0.0022\n",
      "Epoch 11/100\n",
      "8142/8142 [==============================] - 1s 68us/step - loss: 18.1460 - acc: 0.0018\n",
      "Epoch 12/100\n",
      "8142/8142 [==============================] - 1s 64us/step - loss: 18.1673 - acc: 0.0028\n",
      "Epoch 13/100\n",
      "8142/8142 [==============================] - 1s 66us/step - loss: 18.1617 - acc: 0.0022\n",
      "Epoch 14/100\n",
      "8142/8142 [==============================] - 0s 58us/step - loss: 18.1446 - acc: 0.0027\n",
      "Epoch 15/100\n",
      "8142/8142 [==============================] - 0s 61us/step - loss: 18.2001 - acc: 0.0031\n",
      "Epoch 16/100\n",
      "8142/8142 [==============================] - 0s 58us/step - loss: 18.1505 - acc: 0.0025\n",
      "Epoch 17/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.1413 - acc: 0.0025\n",
      "Epoch 18/100\n",
      "8142/8142 [==============================] - 1s 76us/step - loss: 18.1258 - acc: 0.0020\n",
      "Epoch 19/100\n",
      "8142/8142 [==============================] - 1s 62us/step - loss: 18.1432 - acc: 0.0023\n",
      "Epoch 20/100\n",
      "8142/8142 [==============================] - 1s 63us/step - loss: 18.1335 - acc: 0.0018\n",
      "Epoch 21/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 18.0679 - acc: 0.0021\n",
      "Epoch 22/100\n",
      "8142/8142 [==============================] - 1s 67us/step - loss: 18.0878 - acc: 0.0027\n",
      "Epoch 23/100\n",
      "8142/8142 [==============================] - 1s 64us/step - loss: 18.1146 - acc: 0.0033\n",
      "Epoch 24/100\n",
      "8142/8142 [==============================] - 1s 62us/step - loss: 18.1225 - acc: 0.0031\n",
      "Epoch 25/100\n",
      "8142/8142 [==============================] - 1s 67us/step - loss: 18.0961 - acc: 0.0025\n",
      "Epoch 26/100\n",
      "8142/8142 [==============================] - 1s 79us/step - loss: 18.1444 - acc: 0.0023\n",
      "Epoch 27/100\n",
      "8142/8142 [==============================] - 1s 80us/step - loss: 18.1039 - acc: 0.0023\n",
      "Epoch 28/100\n",
      "8142/8142 [==============================] - 1s 64us/step - loss: 18.1154 - acc: 0.0023\n",
      "Epoch 29/100\n",
      "8142/8142 [==============================] - 0s 59us/step - loss: 18.1423 - acc: 0.0023\n",
      "Epoch 30/100\n",
      "8142/8142 [==============================] - 0s 61us/step - loss: 18.1001 - acc: 0.0026\n",
      "Epoch 31/100\n",
      "8142/8142 [==============================] - 0s 59us/step - loss: 18.1535 - acc: 0.0023\n",
      "Epoch 32/100\n",
      "8142/8142 [==============================] - 1s 62us/step - loss: 18.0926 - acc: 0.0028\n",
      "Epoch 33/100\n",
      "8142/8142 [==============================] - 1s 69us/step - loss: 18.1099 - acc: 0.0025\n",
      "Epoch 34/100\n",
      "8142/8142 [==============================] - 1s 81us/step - loss: 18.0588 - acc: 0.0027\n",
      "Epoch 35/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 18.0218 - acc: 0.0027\n",
      "Epoch 36/100\n",
      "8142/8142 [==============================] - 1s 108us/step - loss: 18.0849 - acc: 0.0021\n",
      "Epoch 37/100\n",
      "8142/8142 [==============================] - 1s 99us/step - loss: 18.0671 - acc: 0.0026 0s - loss: 1\n",
      "Epoch 38/100\n",
      "8142/8142 [==============================] - 1s 111us/step - loss: 18.0771 - acc: 0.0027\n",
      "Epoch 39/100\n",
      "8142/8142 [==============================] - 1s 90us/step - loss: 18.0843 - acc: 0.0027\n",
      "Epoch 40/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0903 - acc: 0.0027\n",
      "Epoch 41/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0361 - acc: 0.0026\n",
      "Epoch 42/100\n",
      "8142/8142 [==============================] - 1s 74us/step - loss: 18.0356 - acc: 0.0022\n",
      "Epoch 43/100\n",
      "8142/8142 [==============================] - 1s 70us/step - loss: 18.0789 - acc: 0.0027\n",
      "Epoch 44/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0408 - acc: 0.0026\n",
      "Epoch 45/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.1160 - acc: 0.0015\n",
      "Epoch 46/100\n",
      "8142/8142 [==============================] - 1s 70us/step - loss: 18.0261 - acc: 0.0022\n",
      "Epoch 47/100\n",
      "8142/8142 [==============================] - 1s 74us/step - loss: 18.0530 - acc: 0.0022\n",
      "Epoch 48/100\n",
      "8142/8142 [==============================] - 1s 69us/step - loss: 18.0755 - acc: 0.0025\n",
      "Epoch 49/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 18.0327 - acc: 0.0027\n",
      "Epoch 50/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 18.0133 - acc: 0.0027\n",
      "Epoch 51/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0921 - acc: 0.0023\n",
      "Epoch 52/100\n",
      "8142/8142 [==============================] - 1s 75us/step - loss: 18.1465 - acc: 0.0025\n",
      "Epoch 53/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 18.0592 - acc: 0.0025\n",
      "Epoch 54/100\n",
      "8142/8142 [==============================] - 1s 75us/step - loss: 17.9998 - acc: 0.0022\n",
      "Epoch 55/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 18.0215 - acc: 0.0028\n",
      "Epoch 56/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 18.0272 - acc: 0.0027\n",
      "Epoch 57/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0345 - acc: 0.0022\n",
      "Epoch 58/100\n",
      "8142/8142 [==============================] - 1s 77us/step - loss: 18.0594 - acc: 0.0029\n",
      "Epoch 59/100\n",
      "8142/8142 [==============================] - 1s 74us/step - loss: 18.0222 - acc: 0.0028\n",
      "Epoch 60/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 18.0598 - acc: 0.0020\n",
      "Epoch 61/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 18.0101 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0674 - acc: 0.0021\n",
      "Epoch 63/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 17.9843 - acc: 0.0021\n",
      "Epoch 64/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 18.0203 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "8142/8142 [==============================] - 1s 70us/step - loss: 18.0144 - acc: 0.0023\n",
      "Epoch 66/100\n",
      "8142/8142 [==============================] - 1s 77us/step - loss: 17.9570 - acc: 0.0022\n",
      "Epoch 67/100\n",
      "8142/8142 [==============================] - 1s 76us/step - loss: 18.0714 - acc: 0.0038\n",
      "Epoch 68/100\n",
      "8142/8142 [==============================] - 1s 69us/step - loss: 18.0431 - acc: 0.0032\n",
      "Epoch 69/100\n",
      "8142/8142 [==============================] - 1s 74us/step - loss: 17.9638 - acc: 0.0032\n",
      "Epoch 70/100\n",
      "8142/8142 [==============================] - 1s 69us/step - loss: 18.0225 - acc: 0.0021\n",
      "Epoch 71/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 18.0119 - acc: 0.0026\n",
      "Epoch 72/100\n",
      "8142/8142 [==============================] - 1s 74us/step - loss: 17.9782 - acc: 0.0028\n",
      "Epoch 73/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 18.0023 - acc: 0.0023\n",
      "Epoch 74/100\n",
      "8142/8142 [==============================] - 1s 74us/step - loss: 18.0413 - acc: 0.0029\n",
      "Epoch 75/100\n",
      "8142/8142 [==============================] - 1s 68us/step - loss: 18.0245 - acc: 0.0026\n",
      "Epoch 76/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 17.9881 - acc: 0.0026\n",
      "Epoch 77/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 17.9985 - acc: 0.0026\n",
      "Epoch 78/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 17.9875 - acc: 0.0028\n",
      "Epoch 79/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0056 - acc: 0.0027\n",
      "Epoch 80/100\n",
      "8142/8142 [==============================] - 1s 78us/step - loss: 17.9570 - acc: 0.0031\n",
      "Epoch 81/100\n",
      "8142/8142 [==============================] - 1s 77us/step - loss: 17.9885 - acc: 0.0031\n",
      "Epoch 82/100\n",
      "8142/8142 [==============================] - 1s 69us/step - loss: 17.9893 - acc: 0.0021\n",
      "Epoch 83/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 17.9574 - acc: 0.0022\n",
      "Epoch 84/100\n",
      "8142/8142 [==============================] - 1s 74us/step - loss: 17.9956 - acc: 0.0025\n",
      "Epoch 85/100\n",
      "8142/8142 [==============================] - 1s 69us/step - loss: 18.0396 - acc: 0.0021\n",
      "Epoch 86/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 17.9963 - acc: 0.0033\n",
      "Epoch 87/100\n",
      "8142/8142 [==============================] - 1s 68us/step - loss: 17.9620 - acc: 0.0021\n",
      "Epoch 88/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 17.9713 - acc: 0.0021\n",
      "Epoch 89/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 18.0261 - acc: 0.0031\n",
      "Epoch 90/100\n",
      "8142/8142 [==============================] - 1s 69us/step - loss: 18.0315 - acc: 0.0027\n",
      "Epoch 91/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0089 - acc: 0.0033\n",
      "Epoch 92/100\n",
      "8142/8142 [==============================] - 1s 71us/step - loss: 17.9253 - acc: 0.0032\n",
      "Epoch 93/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 18.0048 - acc: 0.0022\n",
      "Epoch 94/100\n",
      "8142/8142 [==============================] - 1s 70us/step - loss: 17.9271 - acc: 0.0029\n",
      "Epoch 95/100\n",
      "8142/8142 [==============================] - 1s 74us/step - loss: 18.0364 - acc: 0.0022\n",
      "Epoch 96/100\n",
      "8142/8142 [==============================] - 1s 70us/step - loss: 18.0062 - acc: 0.0026\n",
      "Epoch 97/100\n",
      "8142/8142 [==============================] - 1s 68us/step - loss: 17.9555 - acc: 0.0027\n",
      "Epoch 98/100\n",
      "8142/8142 [==============================] - 1s 73us/step - loss: 17.9580 - acc: 0.0034\n",
      "Epoch 99/100\n",
      "8142/8142 [==============================] - 1s 68us/step - loss: 17.8894 - acc: 0.0029\n",
      "Epoch 100/100\n",
      "8142/8142 [==============================] - 1s 72us/step - loss: 17.9601 - acc: 0.0029\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2220/8314 [=======>......................] - ETA: 0s - loss: 18.1644 - acc: 0.0014  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8314/8314 [==============================] - 1s 72us/step - loss: 18.0700 - acc: 0.0020\n",
      "Epoch 2/100\n",
      "8314/8314 [==============================] - 1s 70us/step - loss: 18.0734 - acc: 0.0025\n",
      "Epoch 3/100\n",
      "8314/8314 [==============================] - 1s 71us/step - loss: 18.1474 - acc: 0.0024\n",
      "Epoch 4/100\n",
      "8314/8314 [==============================] - 1s 76us/step - loss: 18.0540 - acc: 0.0024\n",
      "Epoch 5/100\n",
      "8314/8314 [==============================] - 1s 72us/step - loss: 18.0221 - acc: 0.0025\n",
      "Epoch 6/100\n",
      "8314/8314 [==============================] - 1s 70us/step - loss: 18.1470 - acc: 0.0031\n",
      "Epoch 7/100\n",
      "8314/8314 [==============================] - 1s 70us/step - loss: 18.0652 - acc: 0.0028\n",
      "Epoch 8/100\n",
      "8314/8314 [==============================] - 1s 73us/step - loss: 18.0374 - acc: 0.0029\n",
      "Epoch 9/100\n",
      "8314/8314 [==============================] - 1s 73us/step - loss: 18.0760 - acc: 0.0029\n",
      "Epoch 10/100\n",
      "8314/8314 [==============================] - 1s 72us/step - loss: 18.0259 - acc: 0.0030\n",
      "Epoch 11/100\n",
      "8314/8314 [==============================] - 1s 68us/step - loss: 18.0522 - acc: 0.0030\n",
      "Epoch 12/100\n",
      "8314/8314 [==============================] - 1s 71us/step - loss: 18.0389 - acc: 0.0028\n",
      "Epoch 13/100\n",
      "8314/8314 [==============================] - 1s 75us/step - loss: 18.0473 - acc: 0.0026\n",
      "Epoch 14/100\n",
      "8314/8314 [==============================] - 1s 69us/step - loss: 18.0683 - acc: 0.0023\n",
      "Epoch 15/100\n",
      "8314/8314 [==============================] - 1s 72us/step - loss: 18.0183 - acc: 0.0026\n",
      "Epoch 16/100\n",
      "8314/8314 [==============================] - 1s 70us/step - loss: 18.0520 - acc: 0.0031\n",
      "Epoch 17/100\n",
      "8314/8314 [==============================] - 1s 76us/step - loss: 17.9840 - acc: 0.0026\n",
      "Epoch 18/100\n",
      "8314/8314 [==============================] - 1s 74us/step - loss: 18.0592 - acc: 0.0025\n",
      "Epoch 19/100\n",
      "8314/8314 [==============================] - 1s 70us/step - loss: 18.0308 - acc: 0.0024\n",
      "Epoch 20/100\n",
      "8314/8314 [==============================] - 1s 73us/step - loss: 18.0229 - acc: 0.0032\n",
      "Epoch 21/100\n",
      "8314/8314 [==============================] - 1s 69us/step - loss: 17.9929 - acc: 0.0028\n",
      "Epoch 22/100\n",
      "8314/8314 [==============================] - 1s 91us/step - loss: 18.0493 - acc: 0.0029\n",
      "Epoch 23/100\n",
      "8314/8314 [==============================] - 1s 85us/step - loss: 18.0164 - acc: 0.0030\n",
      "Epoch 24/100\n",
      "8314/8314 [==============================] - 1s 83us/step - loss: 18.0102 - acc: 0.0034\n",
      "Epoch 25/100\n",
      "8314/8314 [==============================] - 1s 83us/step - loss: 17.9327 - acc: 0.0029\n",
      "Epoch 26/100\n",
      "8314/8314 [==============================] - 1s 97us/step - loss: 18.0000 - acc: 0.0025\n",
      "Epoch 27/100\n",
      "8314/8314 [==============================] - 1s 71us/step - loss: 17.9565 - acc: 0.0024\n",
      "Epoch 28/100\n",
      "8314/8314 [==============================] - 1s 85us/step - loss: 18.0598 - acc: 0.0023\n",
      "Epoch 29/100\n",
      "8314/8314 [==============================] - 1s 93us/step - loss: 17.9593 - acc: 0.0029\n",
      "Epoch 30/100\n",
      "8314/8314 [==============================] - 1s 80us/step - loss: 18.0011 - acc: 0.0025\n",
      "Epoch 31/100\n",
      "8314/8314 [==============================] - 1s 64us/step - loss: 18.0554 - acc: 0.0038\n",
      "Epoch 32/100\n",
      "8314/8314 [==============================] - 1s 61us/step - loss: 17.9325 - acc: 0.0023\n",
      "Epoch 33/100\n",
      "8314/8314 [==============================] - 0s 59us/step - loss: 17.9902 - acc: 0.0031\n",
      "Epoch 34/100\n",
      "8314/8314 [==============================] - 1s 82us/step - loss: 17.9536 - acc: 0.0029\n",
      "Epoch 35/100\n",
      "8314/8314 [==============================] - 1s 89us/step - loss: 17.9983 - acc: 0.0030 0s - loss: 1\n",
      "Epoch 36/100\n",
      "8314/8314 [==============================] - 1s 64us/step - loss: 17.9912 - acc: 0.0029\n",
      "Epoch 37/100\n",
      "8314/8314 [==============================] - 1s 81us/step - loss: 18.0350 - acc: 0.0023\n",
      "Epoch 38/100\n",
      "8314/8314 [==============================] - 1s 87us/step - loss: 17.9622 - acc: 0.0025\n",
      "Epoch 39/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 17.9796 - acc: 0.0028\n",
      "Epoch 40/100\n",
      "8314/8314 [==============================] - 1s 62us/step - loss: 18.0444 - acc: 0.0032\n",
      "Epoch 41/100\n",
      "8314/8314 [==============================] - 1s 64us/step - loss: 17.9748 - acc: 0.0026\n",
      "Epoch 42/100\n",
      "8314/8314 [==============================] - 1s 63us/step - loss: 17.9831 - acc: 0.0031\n",
      "Epoch 43/100\n",
      "8314/8314 [==============================] - 0s 57us/step - loss: 17.9679 - acc: 0.0030\n",
      "Epoch 44/100\n",
      "8314/8314 [==============================] - 1s 88us/step - loss: 17.9691 - acc: 0.0028\n",
      "Epoch 45/100\n",
      "8314/8314 [==============================] - 1s 74us/step - loss: 17.9718 - acc: 0.0026\n",
      "Epoch 46/100\n",
      "8314/8314 [==============================] - 1s 74us/step - loss: 17.9493 - acc: 0.0030\n",
      "Epoch 47/100\n",
      "8314/8314 [==============================] - 1s 89us/step - loss: 17.9394 - acc: 0.0028\n",
      "Epoch 48/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 18.0013 - acc: 0.0028\n",
      "Epoch 49/100\n",
      "8314/8314 [==============================] - 0s 58us/step - loss: 17.9557 - acc: 0.0024\n",
      "Epoch 50/100\n",
      "8314/8314 [==============================] - 1s 63us/step - loss: 17.9247 - acc: 0.0023\n",
      "Epoch 51/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 17.9173 - acc: 0.0020\n",
      "Epoch 52/100\n",
      "8314/8314 [==============================] - 0s 59us/step - loss: 17.9485 - acc: 0.0026\n",
      "Epoch 53/100\n",
      "8314/8314 [==============================] - 1s 87us/step - loss: 17.9488 - acc: 0.0025\n",
      "Epoch 54/100\n",
      "8314/8314 [==============================] - 1s 88us/step - loss: 17.8955 - acc: 0.0028\n",
      "Epoch 55/100\n",
      "8314/8314 [==============================] - 1s 93us/step - loss: 17.9550 - acc: 0.0025\n",
      "Epoch 56/100\n",
      "8314/8314 [==============================] - 0s 59us/step - loss: 17.9579 - acc: 0.0025\n",
      "Epoch 57/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 17.9048 - acc: 0.0026\n",
      "Epoch 58/100\n",
      "8314/8314 [==============================] - 0s 56us/step - loss: 17.9105 - acc: 0.0028\n",
      "Epoch 59/100\n",
      "8314/8314 [==============================] - 1s 61us/step - loss: 17.9289 - acc: 0.0024\n",
      "Epoch 60/100\n",
      "8314/8314 [==============================] - 0s 56us/step - loss: 17.9662 - acc: 0.0028\n",
      "Epoch 61/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 17.9377 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "8314/8314 [==============================] - 0s 57us/step - loss: 17.9808 - acc: 0.0026\n",
      "Epoch 63/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 17.9717 - acc: 0.0024\n",
      "Epoch 64/100\n",
      "8314/8314 [==============================] - 0s 56us/step - loss: 17.8763 - acc: 0.0022\n",
      "Epoch 65/100\n",
      "8314/8314 [==============================] - 1s 61us/step - loss: 17.9030 - acc: 0.0029\n",
      "Epoch 66/100\n",
      "8314/8314 [==============================] - 0s 58us/step - loss: 17.9400 - acc: 0.0025\n",
      "Epoch 67/100\n",
      "8314/8314 [==============================] - 1s 72us/step - loss: 17.9412 - acc: 0.0023\n",
      "Epoch 68/100\n",
      "8314/8314 [==============================] - 1s 88us/step - loss: 17.8965 - acc: 0.0028\n",
      "Epoch 69/100\n",
      "8314/8314 [==============================] - 1s 79us/step - loss: 17.9101 - acc: 0.0030\n",
      "Epoch 70/100\n",
      "8314/8314 [==============================] - 1s 64us/step - loss: 17.9507 - acc: 0.0024\n",
      "Epoch 71/100\n",
      "8314/8314 [==============================] - 1s 80us/step - loss: 17.9116 - acc: 0.0023\n",
      "Epoch 72/100\n",
      "8314/8314 [==============================] - 1s 73us/step - loss: 17.9478 - acc: 0.0019\n",
      "Epoch 73/100\n",
      "8314/8314 [==============================] - 1s 82us/step - loss: 17.8968 - acc: 0.0024\n",
      "Epoch 74/100\n",
      "8314/8314 [==============================] - 1s 78us/step - loss: 17.9170 - acc: 0.0031\n",
      "Epoch 75/100\n",
      "8314/8314 [==============================] - 1s 74us/step - loss: 17.8663 - acc: 0.0020\n",
      "Epoch 76/100\n",
      "8314/8314 [==============================] - 1s 74us/step - loss: 17.9072 - acc: 0.0024\n",
      "Epoch 77/100\n",
      "8314/8314 [==============================] - 1s 62us/step - loss: 17.8943 - acc: 0.0031\n",
      "Epoch 78/100\n",
      "8314/8314 [==============================] - 1s 61us/step - loss: 17.8692 - acc: 0.0022\n",
      "Epoch 79/100\n",
      "8314/8314 [==============================] - 1s 81us/step - loss: 17.9182 - acc: 0.0023\n",
      "Epoch 80/100\n",
      "8314/8314 [==============================] - 1s 69us/step - loss: 17.9116 - acc: 0.0019\n",
      "Epoch 81/100\n",
      "8314/8314 [==============================] - 0s 57us/step - loss: 17.9272 - acc: 0.0028\n",
      "Epoch 82/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 17.9559 - acc: 0.0025\n",
      "Epoch 83/100\n",
      "8314/8314 [==============================] - 0s 57us/step - loss: 17.9017 - acc: 0.0024\n",
      "Epoch 84/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 17.9589 - acc: 0.0026\n",
      "Epoch 85/100\n",
      "8314/8314 [==============================] - 0s 57us/step - loss: 17.9142 - acc: 0.0026\n",
      "Epoch 86/100\n",
      "8314/8314 [==============================] - 0s 59us/step - loss: 17.9518 - acc: 0.0031\n",
      "Epoch 87/100\n",
      "8314/8314 [==============================] - 0s 57us/step - loss: 17.8795 - acc: 0.0026\n",
      "Epoch 88/100\n",
      "8314/8314 [==============================] - 0s 59us/step - loss: 17.9254 - acc: 0.0025\n",
      "Epoch 89/100\n",
      "8314/8314 [==============================] - 0s 57us/step - loss: 17.9067 - acc: 0.0026\n",
      "Epoch 90/100\n",
      "8314/8314 [==============================] - 0s 59us/step - loss: 17.8811 - acc: 0.0025\n",
      "Epoch 91/100\n",
      "8314/8314 [==============================] - 0s 57us/step - loss: 17.8718 - acc: 0.0030\n",
      "Epoch 92/100\n",
      "8314/8314 [==============================] - 1s 61us/step - loss: 17.8821 - acc: 0.0023\n",
      "Epoch 93/100\n",
      "8314/8314 [==============================] - 0s 58us/step - loss: 17.8472 - acc: 0.0028\n",
      "Epoch 94/100\n",
      "8314/8314 [==============================] - 1s 61us/step - loss: 17.8181 - acc: 0.0024\n",
      "Epoch 95/100\n",
      "8314/8314 [==============================] - 0s 58us/step - loss: 17.8471 - acc: 0.0022\n",
      "Epoch 96/100\n",
      "8314/8314 [==============================] - 0s 58us/step - loss: 17.8318 - acc: 0.0025\n",
      "Epoch 97/100\n",
      "8314/8314 [==============================] - 0s 59us/step - loss: 17.8443 - acc: 0.0030\n",
      "Epoch 98/100\n",
      "8314/8314 [==============================] - 1s 64us/step - loss: 17.8266 - acc: 0.0028\n",
      "Epoch 99/100\n",
      "8314/8314 [==============================] - 0s 60us/step - loss: 17.8350 - acc: 0.0024\n",
      "Epoch 100/100\n",
      "8314/8314 [==============================] - 0s 58us/step - loss: 17.9421 - acc: 0.0024\n",
      "172/172 [==============================] - 0s 29us/step\n",
      "Epoch 1/100\n",
      "2630/8486 [========>.....................] - ETA: 0s - loss: 16.9883 - acc: 0.0023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.8769 - acc: 0.0020\n",
      "Epoch 2/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.8249 - acc: 0.0018\n",
      "Epoch 3/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.8711 - acc: 0.0031\n",
      "Epoch 4/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.8517 - acc: 0.0027\n",
      "Epoch 5/100\n",
      "8486/8486 [==============================] - 0s 57us/step - loss: 17.8015 - acc: 0.0025\n",
      "Epoch 6/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.8242 - acc: 0.0022\n",
      "Epoch 7/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7890 - acc: 0.0021\n",
      "Epoch 8/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.8575 - acc: 0.0028\n",
      "Epoch 9/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.8197 - acc: 0.0029\n",
      "Epoch 10/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.8091 - acc: 0.0024\n",
      "Epoch 11/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7900 - acc: 0.0029\n",
      "Epoch 12/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7983 - acc: 0.0026\n",
      "Epoch 13/100\n",
      "8486/8486 [==============================] - 0s 57us/step - loss: 17.7431 - acc: 0.0025\n",
      "Epoch 14/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7922 - acc: 0.0022\n",
      "Epoch 15/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.8116 - acc: 0.0028\n",
      "Epoch 16/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.8061 - acc: 0.0024\n",
      "Epoch 17/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.8110 - acc: 0.0024\n",
      "Epoch 18/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7182 - acc: 0.0025\n",
      "Epoch 19/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7817 - acc: 0.0025\n",
      "Epoch 20/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7892 - acc: 0.0026\n",
      "Epoch 21/100\n",
      "8486/8486 [==============================] - 0s 57us/step - loss: 17.8331 - acc: 0.0029\n",
      "Epoch 22/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7910 - acc: 0.0029\n",
      "Epoch 23/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7690 - acc: 0.0029\n",
      "Epoch 24/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.8029 - acc: 0.0026\n",
      "Epoch 25/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.8501 - acc: 0.0032\n",
      "Epoch 26/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7981 - acc: 0.0022\n",
      "Epoch 27/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7460 - acc: 0.0027\n",
      "Epoch 28/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7926 - acc: 0.0019\n",
      "Epoch 29/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7646 - acc: 0.0029\n",
      "Epoch 30/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7507 - acc: 0.0022\n",
      "Epoch 31/100\n",
      "8486/8486 [==============================] - 1s 61us/step - loss: 17.8137 - acc: 0.0024\n",
      "Epoch 32/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7565 - acc: 0.0027\n",
      "Epoch 33/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7632 - acc: 0.0028\n",
      "Epoch 34/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7733 - acc: 0.0028\n",
      "Epoch 35/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7728 - acc: 0.0024\n",
      "Epoch 36/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7328 - acc: 0.0031\n",
      "Epoch 37/100\n",
      "8486/8486 [==============================] - 0s 57us/step - loss: 17.8160 - acc: 0.0025\n",
      "Epoch 38/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7353 - acc: 0.0028\n",
      "Epoch 39/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7827 - acc: 0.0028\n",
      "Epoch 40/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7653 - acc: 0.0027\n",
      "Epoch 41/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7734 - acc: 0.0022\n",
      "Epoch 42/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7196 - acc: 0.0024\n",
      "Epoch 43/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7730 - acc: 0.0028\n",
      "Epoch 44/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7691 - acc: 0.0028\n",
      "Epoch 45/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7481 - acc: 0.0033\n",
      "Epoch 46/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.8364 - acc: 0.0024\n",
      "Epoch 47/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.8001 - acc: 0.0032\n",
      "Epoch 48/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7141 - acc: 0.0027\n",
      "Epoch 49/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7110 - acc: 0.0031\n",
      "Epoch 50/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7320 - acc: 0.0031\n",
      "Epoch 51/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7123 - acc: 0.0029\n",
      "Epoch 52/100\n",
      "8486/8486 [==============================] - 1s 62us/step - loss: 17.7467 - acc: 0.0025\n",
      "Epoch 53/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7485 - acc: 0.0020\n",
      "Epoch 54/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7241 - acc: 0.0026\n",
      "Epoch 55/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7211 - acc: 0.0026\n",
      "Epoch 56/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.6846 - acc: 0.0026\n",
      "Epoch 57/100\n",
      "8486/8486 [==============================] - 0s 59us/step - loss: 17.7408 - acc: 0.0021\n",
      "Epoch 58/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7357 - acc: 0.0028\n",
      "Epoch 59/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7690 - acc: 0.0026\n",
      "Epoch 60/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7391 - acc: 0.0022\n",
      "Epoch 61/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7361 - acc: 0.0027\n",
      "Epoch 62/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7248 - acc: 0.0028\n",
      "Epoch 63/100\n",
      "8486/8486 [==============================] - 1s 84us/step - loss: 17.7207 - acc: 0.0027\n",
      "Epoch 64/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7276 - acc: 0.0025\n",
      "Epoch 65/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7120 - acc: 0.0025\n",
      "Epoch 66/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7523 - acc: 0.0029\n",
      "Epoch 67/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7526 - acc: 0.0027\n",
      "Epoch 68/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.6731 - acc: 0.0029\n",
      "Epoch 69/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7780 - acc: 0.0022\n",
      "Epoch 70/100\n",
      "8486/8486 [==============================] - 1s 61us/step - loss: 17.7387 - acc: 0.0027\n",
      "Epoch 71/100\n",
      "8486/8486 [==============================] - 0s 57us/step - loss: 17.6919 - acc: 0.0022\n",
      "Epoch 72/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.6924 - acc: 0.0028\n",
      "Epoch 73/100\n",
      "8486/8486 [==============================] - 0s 57us/step - loss: 17.7118 - acc: 0.0028\n",
      "Epoch 74/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7193 - acc: 0.0025\n",
      "Epoch 75/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7151 - acc: 0.0022\n",
      "Epoch 76/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.6632 - acc: 0.0032\n",
      "Epoch 77/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7211 - acc: 0.0025\n",
      "Epoch 78/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7771 - acc: 0.0020\n",
      "Epoch 79/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7103 - acc: 0.0025\n",
      "Epoch 80/100\n",
      "8486/8486 [==============================] - 1s 60us/step - loss: 17.7145 - acc: 0.0031\n",
      "Epoch 81/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.7456 - acc: 0.0025\n",
      "Epoch 82/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7223 - acc: 0.0026\n",
      "Epoch 83/100\n",
      "8486/8486 [==============================] - 0s 58us/step - loss: 17.6765 - acc: 0.0025\n",
      "Epoch 84/100\n",
      "8486/8486 [==============================] - 1s 78us/step - loss: 17.6412 - acc: 0.0024\n",
      "Epoch 85/100\n",
      "8486/8486 [==============================] - 1s 74us/step - loss: 17.7336 - acc: 0.0024\n",
      "Epoch 86/100\n",
      "8486/8486 [==============================] - 1s 73us/step - loss: 17.6671 - acc: 0.0029\n",
      "Epoch 87/100\n",
      "8486/8486 [==============================] - 1s 64us/step - loss: 17.7199 - acc: 0.0024\n",
      "Epoch 88/100\n",
      "8486/8486 [==============================] - 1s 84us/step - loss: 17.6443 - acc: 0.0027\n",
      "Epoch 89/100\n",
      "8486/8486 [==============================] - 1s 119us/step - loss: 17.6633 - acc: 0.0021\n",
      "Epoch 90/100\n",
      "8486/8486 [==============================] - 1s 134us/step - loss: 17.7831 - acc: 0.0024\n",
      "Epoch 91/100\n",
      "8486/8486 [==============================] - 1s 139us/step - loss: 17.6891 - acc: 0.0026\n",
      "Epoch 92/100\n",
      "8486/8486 [==============================] - 1s 113us/step - loss: 17.6813 - acc: 0.0028\n",
      "Epoch 93/100\n",
      "8486/8486 [==============================] - 1s 101us/step - loss: 17.7182 - acc: 0.0025\n",
      "Epoch 94/100\n",
      "8486/8486 [==============================] - 1s 131us/step - loss: 17.6730 - acc: 0.0027\n",
      "Epoch 95/100\n",
      "8486/8486 [==============================] - 1s 69us/step - loss: 17.7183 - acc: 0.0026\n",
      "Epoch 96/100\n",
      "8486/8486 [==============================] - 1s 75us/step - loss: 17.6402 - acc: 0.0024\n",
      "Epoch 97/100\n",
      "8486/8486 [==============================] - 1s 69us/step - loss: 17.6238 - acc: 0.0021\n",
      "Epoch 98/100\n",
      "8486/8486 [==============================] - 1s 68us/step - loss: 17.6673 - acc: 0.0020\n",
      "Epoch 99/100\n",
      "8486/8486 [==============================] - 1s 59us/step - loss: 17.7209 - acc: 0.0025\n",
      "Epoch 100/100\n",
      "8486/8486 [==============================] - 1s 72us/step - loss: 17.7135 - acc: 0.0028\n",
      "172/172 [==============================] - 0s 0us/step\n",
      "Epoch 1/100\n",
      "2460/8658 [=======>......................] - ETA: 0s - loss: 18.4619 - acc: 0.0024 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8658/8658 [==============================] - 1s 65us/step - loss: 17.7877 - acc: 0.0027\n",
      "Epoch 2/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7389 - acc: 0.0014\n",
      "Epoch 3/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.7803 - acc: 0.0028\n",
      "Epoch 4/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7261 - acc: 0.0030\n",
      "Epoch 5/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.7141 - acc: 0.0036\n",
      "Epoch 6/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7271 - acc: 0.0025\n",
      "Epoch 7/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.7414 - acc: 0.0028\n",
      "Epoch 8/100\n",
      "8658/8658 [==============================] - 1s 70us/step - loss: 17.7255 - acc: 0.0024\n",
      "Epoch 9/100\n",
      "8658/8658 [==============================] - 1s 61us/step - loss: 17.7308 - acc: 0.0028\n",
      "Epoch 10/100\n",
      "8658/8658 [==============================] - 1s 69us/step - loss: 17.6896 - acc: 0.0032\n",
      "Epoch 11/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7386 - acc: 0.0031\n",
      "Epoch 12/100\n",
      "8658/8658 [==============================] - 1s 68us/step - loss: 17.7155 - acc: 0.0027\n",
      "Epoch 13/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6893 - acc: 0.0027\n",
      "Epoch 14/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7240 - acc: 0.0028\n",
      "Epoch 15/100\n",
      "8658/8658 [==============================] - 1s 72us/step - loss: 17.6913 - acc: 0.0028\n",
      "Epoch 16/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7610 - acc: 0.0024\n",
      "Epoch 17/100\n",
      "8658/8658 [==============================] - 1s 66us/step - loss: 17.7389 - acc: 0.0028\n",
      "Epoch 18/100\n",
      "8658/8658 [==============================] - 0s 57us/step - loss: 17.7718 - acc: 0.0032\n",
      "Epoch 19/100\n",
      "8658/8658 [==============================] - 1s 72us/step - loss: 17.7157 - acc: 0.0027\n",
      "Epoch 20/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.7500 - acc: 0.0028\n",
      "Epoch 21/100\n",
      "8658/8658 [==============================] - 1s 81us/step - loss: 17.6540 - acc: 0.0020\n",
      "Epoch 22/100\n",
      "8658/8658 [==============================] - 1s 81us/step - loss: 17.6844 - acc: 0.0030\n",
      "Epoch 23/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.7113 - acc: 0.0030\n",
      "Epoch 24/100\n",
      "8658/8658 [==============================] - 1s 77us/step - loss: 17.6791 - acc: 0.0025\n",
      "Epoch 25/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.6807 - acc: 0.0023\n",
      "Epoch 26/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6854 - acc: 0.0024\n",
      "Epoch 27/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7526 - acc: 0.0028\n",
      "Epoch 28/100\n",
      "8658/8658 [==============================] - 0s 57us/step - loss: 17.7715 - acc: 0.0027\n",
      "Epoch 29/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6685 - acc: 0.0025\n",
      "Epoch 30/100\n",
      "8658/8658 [==============================] - 1s 61us/step - loss: 17.6672 - acc: 0.0031\n",
      "Epoch 31/100\n",
      "8658/8658 [==============================] - 1s 62us/step - loss: 17.6699 - acc: 0.0024\n",
      "Epoch 32/100\n",
      "8658/8658 [==============================] - 1s 65us/step - loss: 17.6630 - acc: 0.0035\n",
      "Epoch 33/100\n",
      "8658/8658 [==============================] - 1s 68us/step - loss: 17.7206 - acc: 0.0025\n",
      "Epoch 34/100\n",
      "8658/8658 [==============================] - 1s 63us/step - loss: 17.7028 - acc: 0.0027\n",
      "Epoch 35/100\n",
      "8658/8658 [==============================] - 1s 65us/step - loss: 17.7339 - acc: 0.0037\n",
      "Epoch 36/100\n",
      "8658/8658 [==============================] - 1s 66us/step - loss: 17.6973 - acc: 0.0027\n",
      "Epoch 37/100\n",
      "8658/8658 [==============================] - 0s 57us/step - loss: 17.6731 - acc: 0.0024\n",
      "Epoch 38/100\n",
      "8658/8658 [==============================] - 1s 62us/step - loss: 17.7322 - acc: 0.0029\n",
      "Epoch 39/100\n",
      "8658/8658 [==============================] - 1s 90us/step - loss: 17.7059 - acc: 0.0031\n",
      "Epoch 40/100\n",
      "8658/8658 [==============================] - 1s 71us/step - loss: 17.7094 - acc: 0.0030\n",
      "Epoch 41/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6340 - acc: 0.0027\n",
      "Epoch 42/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7092 - acc: 0.0029\n",
      "Epoch 43/100\n",
      "8658/8658 [==============================] - 0s 57us/step - loss: 17.7296 - acc: 0.0032\n",
      "Epoch 44/100\n",
      "8658/8658 [==============================] - 0s 57us/step - loss: 17.6663 - acc: 0.0021\n",
      "Epoch 45/100\n",
      "8658/8658 [==============================] - 1s 62us/step - loss: 17.6790 - acc: 0.0025\n",
      "Epoch 46/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6952 - acc: 0.0024\n",
      "Epoch 47/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6731 - acc: 0.0030\n",
      "Epoch 48/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6908 - acc: 0.0027\n",
      "Epoch 49/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6330 - acc: 0.0025\n",
      "Epoch 50/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.7108 - acc: 0.0021\n",
      "Epoch 51/100\n",
      "8658/8658 [==============================] - 1s 81us/step - loss: 17.6899 - acc: 0.0028\n",
      "Epoch 52/100\n",
      "8658/8658 [==============================] - 1s 89us/step - loss: 17.7291 - acc: 0.0029\n",
      "Epoch 53/100\n",
      "8658/8658 [==============================] - 1s 70us/step - loss: 17.7061 - acc: 0.0028\n",
      "Epoch 54/100\n",
      "8658/8658 [==============================] - 1s 63us/step - loss: 17.6860 - acc: 0.0028\n",
      "Epoch 55/100\n",
      "8658/8658 [==============================] - 1s 62us/step - loss: 17.7014 - acc: 0.0030\n",
      "Epoch 56/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.7281 - acc: 0.0027\n",
      "Epoch 57/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6823 - acc: 0.0028\n",
      "Epoch 58/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.7089 - acc: 0.0028\n",
      "Epoch 59/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.6772 - acc: 0.0024\n",
      "Epoch 60/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6904 - acc: 0.0028\n",
      "Epoch 61/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.6592 - acc: 0.0025\n",
      "Epoch 62/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7092 - acc: 0.0032\n",
      "Epoch 63/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6741 - acc: 0.0037\n",
      "Epoch 64/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6775 - acc: 0.0029\n",
      "Epoch 65/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6612 - acc: 0.0029\n",
      "Epoch 66/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6971 - acc: 0.0028\n",
      "Epoch 67/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6764 - acc: 0.0028\n",
      "Epoch 68/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6826 - acc: 0.0028\n",
      "Epoch 69/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.7132 - acc: 0.0031\n",
      "Epoch 70/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7257 - acc: 0.0030\n",
      "Epoch 71/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6154 - acc: 0.0031\n",
      "Epoch 72/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.6969 - acc: 0.0029\n",
      "Epoch 73/100\n",
      "8658/8658 [==============================] - 0s 58us/step - loss: 17.5990 - acc: 0.0022\n",
      "Epoch 74/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6416 - acc: 0.0024\n",
      "Epoch 75/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6959 - acc: 0.0030\n",
      "Epoch 76/100\n",
      "8658/8658 [==============================] - 0s 57us/step - loss: 17.6197 - acc: 0.0025\n",
      "Epoch 77/100\n",
      "8658/8658 [==============================] - 1s 78us/step - loss: 17.6871 - acc: 0.0035\n",
      "Epoch 78/100\n",
      "8658/8658 [==============================] - 1s 76us/step - loss: 17.6457 - acc: 0.0028\n",
      "Epoch 79/100\n",
      "8658/8658 [==============================] - 1s 63us/step - loss: 17.6481 - acc: 0.0028\n",
      "Epoch 80/100\n",
      "8658/8658 [==============================] - 1s 62us/step - loss: 17.6368 - acc: 0.0029\n",
      "Epoch 81/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6765 - acc: 0.0029\n",
      "Epoch 82/100\n",
      "8658/8658 [==============================] - 0s 57us/step - loss: 17.6937 - acc: 0.0033\n",
      "Epoch 83/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.6543 - acc: 0.0028\n",
      "Epoch 84/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.6765 - acc: 0.0031\n",
      "Epoch 85/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.6035 - acc: 0.0025\n",
      "Epoch 86/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.7337 - acc: 0.0024\n",
      "Epoch 87/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.7117 - acc: 0.0030\n",
      "Epoch 88/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6942 - acc: 0.0032\n",
      "Epoch 89/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6622 - acc: 0.0028\n",
      "Epoch 90/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6962 - acc: 0.0028\n",
      "Epoch 91/100\n",
      "8658/8658 [==============================] - 1s 80us/step - loss: 17.6083 - acc: 0.0031\n",
      "Epoch 92/100\n",
      "8658/8658 [==============================] - 1s 74us/step - loss: 17.6577 - acc: 0.0032\n",
      "Epoch 93/100\n",
      "8658/8658 [==============================] - 1s 60us/step - loss: 17.6423 - acc: 0.0035\n",
      "Epoch 94/100\n",
      "8658/8658 [==============================] - 0s 57us/step - loss: 17.6443 - acc: 0.0031\n",
      "Epoch 95/100\n",
      "8658/8658 [==============================] - 1s 58us/step - loss: 17.6263 - acc: 0.0024\n",
      "Epoch 96/100\n",
      "8658/8658 [==============================] - 1s 79us/step - loss: 17.6554 - acc: 0.0023\n",
      "Epoch 97/100\n",
      "8658/8658 [==============================] - 1s 69us/step - loss: 17.6513 - acc: 0.0032\n",
      "Epoch 98/100\n",
      "8658/8658 [==============================] - 1s 59us/step - loss: 17.6611 - acc: 0.0030\n",
      "Epoch 99/100\n",
      "8658/8658 [==============================] - 1s 61us/step - loss: 17.6361 - acc: 0.0028\n",
      "Epoch 100/100\n",
      "8658/8658 [==============================] - 1s 89us/step - loss: 17.6515 - acc: 0.0035\n",
      "172/172 [==============================] - 0s 35us/step\n",
      "Epoch 1/100\n",
      "2980/8830 [=========>....................] - ETA: 0s - loss: 17.7188 - acc: 0.0023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8830/8830 [==============================] - 1s 84us/step - loss: 17.7751 - acc: 0.0027\n",
      "Epoch 2/100\n",
      "8830/8830 [==============================] - 1s 71us/step - loss: 17.6559 - acc: 0.0029\n",
      "Epoch 3/100\n",
      "8830/8830 [==============================] - 1s 83us/step - loss: 17.7648 - acc: 0.0031\n",
      "Epoch 4/100\n",
      "8830/8830 [==============================] - 1s 72us/step - loss: 17.6860 - acc: 0.0035\n",
      "Epoch 5/100\n",
      "8830/8830 [==============================] - 1s 76us/step - loss: 17.6897 - acc: 0.0025\n",
      "Epoch 6/100\n",
      "8830/8830 [==============================] - 1s 80us/step - loss: 17.7318 - acc: 0.0027\n",
      "Epoch 7/100\n",
      "8830/8830 [==============================] - 1s 71us/step - loss: 17.6577 - acc: 0.0026\n",
      "Epoch 8/100\n",
      "8830/8830 [==============================] - 1s 65us/step - loss: 17.7477 - acc: 0.0032\n",
      "Epoch 9/100\n",
      "8830/8830 [==============================] - 1s 68us/step - loss: 17.7227 - acc: 0.0029\n",
      "Epoch 10/100\n",
      "8830/8830 [==============================] - 1s 74us/step - loss: 17.7117 - acc: 0.0031\n",
      "Epoch 11/100\n",
      "8830/8830 [==============================] - 1s 63us/step - loss: 17.7337 - acc: 0.0022\n",
      "Epoch 12/100\n",
      "8830/8830 [==============================] - 1s 59us/step - loss: 17.7262 - acc: 0.0033\n",
      "Epoch 13/100\n",
      "8830/8830 [==============================] - 1s 62us/step - loss: 17.7014 - acc: 0.0034\n",
      "Epoch 14/100\n",
      "8830/8830 [==============================] - 1s 64us/step - loss: 17.7180 - acc: 0.0029\n",
      "Epoch 15/100\n",
      "8830/8830 [==============================] - 1s 61us/step - loss: 17.6842 - acc: 0.0026\n",
      "Epoch 16/100\n",
      "8830/8830 [==============================] - 1s 72us/step - loss: 17.6945 - acc: 0.0029\n",
      "Epoch 17/100\n",
      "8830/8830 [==============================] - 1s 63us/step - loss: 17.7099 - acc: 0.0029\n",
      "Epoch 18/100\n",
      "8830/8830 [==============================] - 1s 59us/step - loss: 17.7001 - acc: 0.0024\n",
      "Epoch 19/100\n",
      "8830/8830 [==============================] - 1s 59us/step - loss: 17.7058 - acc: 0.0034\n",
      "Epoch 20/100\n",
      "8830/8830 [==============================] - 1s 59us/step - loss: 17.7112 - acc: 0.0031\n",
      "Epoch 21/100\n",
      "8830/8830 [==============================] - 1s 62us/step - loss: 17.6984 - acc: 0.0034\n",
      "Epoch 22/100\n",
      "8830/8830 [==============================] - 1s 78us/step - loss: 17.6859 - acc: 0.0028\n",
      "Epoch 23/100\n",
      "8830/8830 [==============================] - 1s 61us/step - loss: 17.6873 - acc: 0.0027\n",
      "Epoch 24/100\n",
      "8830/8830 [==============================] - 1s 59us/step - loss: 17.7088 - acc: 0.0026\n",
      "Epoch 25/100\n",
      "8830/8830 [==============================] - 1s 61us/step - loss: 17.6917 - acc: 0.0031\n",
      "Epoch 26/100\n",
      "8830/8830 [==============================] - 1s 61us/step - loss: 17.7037 - acc: 0.0027\n",
      "Epoch 27/100\n",
      "8830/8830 [==============================] - 1s 61us/step - loss: 17.6971 - acc: 0.0029\n",
      "Epoch 28/100\n",
      "8830/8830 [==============================] - 1s 60us/step - loss: 17.7144 - acc: 0.0028\n",
      "Epoch 29/100\n",
      "8830/8830 [==============================] - 1s 60us/step - loss: 17.6939 - acc: 0.0033\n",
      "Epoch 30/100\n",
      "8830/8830 [==============================] - 1s 81us/step - loss: 17.6764 - acc: 0.0033\n",
      "Epoch 31/100\n",
      "8830/8830 [==============================] - 1s 71us/step - loss: 17.7161 - acc: 0.0027\n",
      "Epoch 32/100\n",
      "8830/8830 [==============================] - 1s 116us/step - loss: 17.6871 - acc: 0.0029\n",
      "Epoch 33/100\n",
      "8830/8830 [==============================] - 1s 124us/step - loss: 17.6973 - acc: 0.0026\n",
      "Epoch 34/100\n",
      "8830/8830 [==============================] - 1s 122us/step - loss: 17.6809 - acc: 0.0027\n",
      "Epoch 35/100\n",
      "8830/8830 [==============================] - 1s 141us/step - loss: 17.6500 - acc: 0.0027\n",
      "Epoch 36/100\n",
      "8830/8830 [==============================] - 1s 148us/step - loss: 17.7440 - acc: 0.00320s - loss: 17.8423\n",
      "Epoch 37/100\n",
      "8830/8830 [==============================] - 1s 64us/step - loss: 17.6906 - acc: 0.0034\n",
      "Epoch 38/100\n",
      "8830/8830 [==============================] - 1s 80us/step - loss: 17.7470 - acc: 0.0029\n",
      "Epoch 39/100\n",
      "8830/8830 [==============================] - 1s 62us/step - loss: 17.6571 - acc: 0.0026\n",
      "Epoch 40/100\n",
      "8830/8830 [==============================] - 0s 56us/step - loss: 17.6733 - acc: 0.0024\n",
      "Epoch 41/100\n",
      "8830/8830 [==============================] - 1s 69us/step - loss: 17.7337 - acc: 0.0028\n",
      "Epoch 42/100\n",
      "8830/8830 [==============================] - 1s 76us/step - loss: 17.6512 - acc: 0.0029\n",
      "Epoch 43/100\n",
      "8830/8830 [==============================] - 1s 82us/step - loss: 17.7107 - acc: 0.0026\n",
      "Epoch 44/100\n",
      "8830/8830 [==============================] - 1s 70us/step - loss: 17.7655 - acc: 0.0034\n",
      "Epoch 45/100\n",
      "8830/8830 [==============================] - 1s 66us/step - loss: 17.6960 - acc: 0.0027\n",
      "Epoch 46/100\n",
      "8830/8830 [==============================] - 1s 72us/step - loss: 17.6407 - acc: 0.0026\n",
      "Epoch 47/100\n",
      "8830/8830 [==============================] - 1s 65us/step - loss: 17.7505 - acc: 0.0027\n",
      "Epoch 48/100\n",
      "8830/8830 [==============================] - 1s 81us/step - loss: 17.6836 - acc: 0.0027\n",
      "Epoch 49/100\n",
      "8830/8830 [==============================] - 1s 63us/step - loss: 17.7100 - acc: 0.0026\n",
      "Epoch 50/100\n",
      "8830/8830 [==============================] - 1s 85us/step - loss: 17.6315 - acc: 0.0028\n",
      "Epoch 51/100\n",
      "8830/8830 [==============================] - 1s 73us/step - loss: 17.7021 - acc: 0.0023\n",
      "Epoch 52/100\n",
      "8830/8830 [==============================] - 1s 79us/step - loss: 17.6604 - acc: 0.0031\n",
      "Epoch 53/100\n",
      "8830/8830 [==============================] - 1s 85us/step - loss: 17.7570 - acc: 0.0029\n",
      "Epoch 54/100\n",
      "8830/8830 [==============================] - 1s 84us/step - loss: 17.6767 - acc: 0.0027\n",
      "Epoch 55/100\n",
      "8830/8830 [==============================] - 1s 76us/step - loss: 17.6754 - acc: 0.0034\n",
      "Epoch 56/100\n",
      "8830/8830 [==============================] - 1s 73us/step - loss: 17.7355 - acc: 0.0033\n",
      "Epoch 57/100\n",
      "8830/8830 [==============================] - 1s 59us/step - loss: 17.6875 - acc: 0.0024\n",
      "Epoch 58/100\n",
      "8830/8830 [==============================] - 1s 57us/step - loss: 17.6855 - acc: 0.0025\n",
      "Epoch 59/100\n",
      "8830/8830 [==============================] - 1s 57us/step - loss: 17.7232 - acc: 0.0023\n",
      "Epoch 60/100\n",
      "8830/8830 [==============================] - 1s 57us/step - loss: 17.7370 - acc: 0.0026\n",
      "Epoch 61/100\n",
      "8830/8830 [==============================] - 0s 55us/step - loss: 17.6734 - acc: 0.0034\n",
      "Epoch 62/100\n",
      "8830/8830 [==============================] - 1s 58us/step - loss: 17.7033 - acc: 0.0035\n",
      "Epoch 63/100\n",
      "8830/8830 [==============================] - 0s 55us/step - loss: 17.6998 - acc: 0.0026\n",
      "Epoch 64/100\n",
      "8830/8830 [==============================] - 0s 57us/step - loss: 17.7281 - acc: 0.0029\n",
      "Epoch 65/100\n",
      "8830/8830 [==============================] - 0s 56us/step - loss: 17.7628 - acc: 0.0031\n",
      "Epoch 66/100\n",
      "8830/8830 [==============================] - 1s 69us/step - loss: 17.6824 - acc: 0.0028\n",
      "Epoch 67/100\n",
      "8830/8830 [==============================] - 1s 77us/step - loss: 17.6986 - acc: 0.0029\n",
      "Epoch 68/100\n",
      "8830/8830 [==============================] - 1s 69us/step - loss: 17.6360 - acc: 0.0023\n",
      "Epoch 69/100\n",
      "8830/8830 [==============================] - 1s 58us/step - loss: 17.6898 - acc: 0.0022\n",
      "Epoch 70/100\n",
      "8830/8830 [==============================] - 1s 74us/step - loss: 17.6950 - acc: 0.0020\n",
      "Epoch 71/100\n",
      "8830/8830 [==============================] - 1s 67us/step - loss: 17.7208 - acc: 0.0029\n",
      "Epoch 72/100\n",
      "8830/8830 [==============================] - 1s 59us/step - loss: 17.6699 - acc: 0.0029\n",
      "Epoch 73/100\n",
      "8830/8830 [==============================] - 0s 57us/step - loss: 17.7282 - acc: 0.0029\n",
      "Epoch 74/100\n",
      "8830/8830 [==============================] - 1s 57us/step - loss: 17.7251 - acc: 0.0025\n",
      "Epoch 75/100\n",
      "8830/8830 [==============================] - 1s 58us/step - loss: 17.6520 - acc: 0.0031\n",
      "Epoch 76/100\n",
      "8830/8830 [==============================] - 1s 58us/step - loss: 17.6826 - acc: 0.0033\n",
      "Epoch 77/100\n",
      "8830/8830 [==============================] - 1s 59us/step - loss: 17.6793 - acc: 0.0034\n",
      "Epoch 78/100\n",
      "8830/8830 [==============================] - 1s 61us/step - loss: 17.6554 - acc: 0.0026\n",
      "Epoch 79/100\n",
      "8830/8830 [==============================] - 1s 65us/step - loss: 17.7034 - acc: 0.0035\n",
      "Epoch 80/100\n",
      "8830/8830 [==============================] - 1s 60us/step - loss: 17.7155 - acc: 0.0027\n",
      "Epoch 81/100\n",
      "8830/8830 [==============================] - 1s 65us/step - loss: 17.6572 - acc: 0.0032\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8830/8830 [==============================] - 1s 66us/step - loss: 17.7437 - acc: 0.0027\n",
      "Epoch 83/100\n",
      "8830/8830 [==============================] - 1s 90us/step - loss: 17.7013 - acc: 0.0034\n",
      "Epoch 84/100\n",
      "8830/8830 [==============================] - 1s 67us/step - loss: 17.6798 - acc: 0.0040\n",
      "Epoch 85/100\n",
      "8830/8830 [==============================] - 1s 66us/step - loss: 17.6958 - acc: 0.0029\n",
      "Epoch 86/100\n",
      "8830/8830 [==============================] - 1s 68us/step - loss: 17.6418 - acc: 0.0032\n",
      "Epoch 87/100\n",
      "8830/8830 [==============================] - 1s 68us/step - loss: 17.6963 - acc: 0.0031\n",
      "Epoch 88/100\n",
      "8830/8830 [==============================] - 1s 69us/step - loss: 17.7187 - acc: 0.0028\n",
      "Epoch 89/100\n",
      "8830/8830 [==============================] - 1s 66us/step - loss: 17.6467 - acc: 0.0025\n",
      "Epoch 90/100\n",
      "8830/8830 [==============================] - 1s 66us/step - loss: 17.7146 - acc: 0.0032\n",
      "Epoch 91/100\n",
      "8830/8830 [==============================] - 1s 67us/step - loss: 17.6384 - acc: 0.0028\n",
      "Epoch 92/100\n",
      "8830/8830 [==============================] - 1s 67us/step - loss: 17.7222 - acc: 0.0029\n",
      "Epoch 93/100\n",
      "8830/8830 [==============================] - 1s 66us/step - loss: 17.6892 - acc: 0.0027\n",
      "Epoch 94/100\n",
      "8830/8830 [==============================] - 1s 66us/step - loss: 17.7047 - acc: 0.0025\n",
      "Epoch 95/100\n",
      "8830/8830 [==============================] - 1s 88us/step - loss: 17.6807 - acc: 0.0029: 0s - loss:\n",
      "Epoch 96/100\n",
      "8830/8830 [==============================] - 1s 71us/step - loss: 17.6875 - acc: 0.0032\n",
      "Epoch 97/100\n",
      "8830/8830 [==============================] - 1s 57us/step - loss: 17.6794 - acc: 0.0031\n",
      "Epoch 98/100\n",
      "8830/8830 [==============================] - 0s 57us/step - loss: 17.7317 - acc: 0.0029\n",
      "Epoch 99/100\n",
      "8830/8830 [==============================] - 1s 57us/step - loss: 17.6929 - acc: 0.0028\n",
      "Epoch 100/100\n",
      "8830/8830 [==============================] - 0s 56us/step - loss: 17.7302 - acc: 0.0031\n",
      "172/172 [==============================] - 0s 91us/step\n",
      "Epoch 1/100\n",
      "2960/9002 [========>.....................] - ETA: 0s - loss: 17.7596 - acc: 0.0030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9002/9002 [==============================] - 1s 56us/step - loss: 18.1146 - acc: 0.0030\n",
      "Epoch 2/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 18.1072 - acc: 0.0029\n",
      "Epoch 3/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 18.0476 - acc: 0.0031\n",
      "Epoch 4/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 18.0262 - acc: 0.0031\n",
      "Epoch 5/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 18.0869 - acc: 0.0031\n",
      "Epoch 6/100\n",
      "9002/9002 [==============================] - 1s 79us/step - loss: 18.0539 - acc: 0.0029\n",
      "Epoch 7/100\n",
      "9002/9002 [==============================] - 1s 65us/step - loss: 17.9867 - acc: 0.0023\n",
      "Epoch 8/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 18.0101 - acc: 0.0032\n",
      "Epoch 9/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 18.0226 - acc: 0.0029\n",
      "Epoch 10/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 18.0153 - acc: 0.0027\n",
      "Epoch 11/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 18.0373 - acc: 0.0027\n",
      "Epoch 12/100\n",
      "9002/9002 [==============================] - 1s 80us/step - loss: 18.0473 - acc: 0.0030\n",
      "Epoch 13/100\n",
      "9002/9002 [==============================] - 1s 77us/step - loss: 17.9750 - acc: 0.0032\n",
      "Epoch 14/100\n",
      "9002/9002 [==============================] - 1s 74us/step - loss: 18.0269 - acc: 0.0030\n",
      "Epoch 15/100\n",
      "9002/9002 [==============================] - 1s 67us/step - loss: 17.9745 - acc: 0.0021\n",
      "Epoch 16/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 18.0586 - acc: 0.0031\n",
      "Epoch 17/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 18.0541 - acc: 0.0027\n",
      "Epoch 18/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9545 - acc: 0.0029\n",
      "Epoch 19/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9382 - acc: 0.0030\n",
      "Epoch 20/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 18.0112 - acc: 0.0029\n",
      "Epoch 21/100\n",
      "9002/9002 [==============================] - 0s 55us/step - loss: 18.0114 - acc: 0.0036\n",
      "Epoch 22/100\n",
      "9002/9002 [==============================] - 1s 59us/step - loss: 17.9586 - acc: 0.0027\n",
      "Epoch 23/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9601 - acc: 0.0029\n",
      "Epoch 24/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9844 - acc: 0.0033\n",
      "Epoch 25/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9628 - acc: 0.0029\n",
      "Epoch 26/100\n",
      "9002/9002 [==============================] - 1s 73us/step - loss: 17.9642 - acc: 0.0024\n",
      "Epoch 27/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9317 - acc: 0.0031\n",
      "Epoch 28/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9151 - acc: 0.0026\n",
      "Epoch 29/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9948 - acc: 0.0036\n",
      "Epoch 30/100\n",
      "9002/9002 [==============================] - 1s 73us/step - loss: 17.9505 - acc: 0.0030\n",
      "Epoch 31/100\n",
      "9002/9002 [==============================] - 1s 60us/step - loss: 17.9708 - acc: 0.0030\n",
      "Epoch 32/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9881 - acc: 0.0032\n",
      "Epoch 33/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9718 - acc: 0.0027\n",
      "Epoch 34/100\n",
      "9002/9002 [==============================] - 1s 68us/step - loss: 17.9491 - acc: 0.0038\n",
      "Epoch 35/100\n",
      "9002/9002 [==============================] - 1s 67us/step - loss: 17.9721 - acc: 0.0032\n",
      "Epoch 36/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9502 - acc: 0.0032\n",
      "Epoch 37/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9930 - acc: 0.0031\n",
      "Epoch 38/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9704 - acc: 0.0023\n",
      "Epoch 39/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9640 - acc: 0.0030\n",
      "Epoch 40/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 18.0310 - acc: 0.0031\n",
      "Epoch 41/100\n",
      "9002/9002 [==============================] - 1s 72us/step - loss: 17.9244 - acc: 0.0031\n",
      "Epoch 42/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9458 - acc: 0.0027\n",
      "Epoch 43/100\n",
      "9002/9002 [==============================] - 1s 71us/step - loss: 17.9564 - acc: 0.0027\n",
      "Epoch 44/100\n",
      "9002/9002 [==============================] - 1s 61us/step - loss: 17.9289 - acc: 0.0032\n",
      "Epoch 45/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9716 - acc: 0.0030\n",
      "Epoch 46/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9423 - acc: 0.0032\n",
      "Epoch 47/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9445 - acc: 0.0029\n",
      "Epoch 48/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9622 - acc: 0.0033\n",
      "Epoch 49/100\n",
      "9002/9002 [==============================] - 1s 77us/step - loss: 17.9204 - acc: 0.0033\n",
      "Epoch 50/100\n",
      "9002/9002 [==============================] - 1s 60us/step - loss: 17.9459 - acc: 0.0031\n",
      "Epoch 51/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 18.0092 - acc: 0.0027\n",
      "Epoch 52/100\n",
      "9002/9002 [==============================] - 1s 59us/step - loss: 17.9843 - acc: 0.0023\n",
      "Epoch 53/100\n",
      "9002/9002 [==============================] - 1s 65us/step - loss: 17.8916 - acc: 0.0031\n",
      "Epoch 54/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9373 - acc: 0.0030\n",
      "Epoch 55/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9572 - acc: 0.0026\n",
      "Epoch 56/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9292 - acc: 0.0024\n",
      "Epoch 57/100\n",
      "9002/9002 [==============================] - 1s 62us/step - loss: 17.9008 - acc: 0.0038\n",
      "Epoch 58/100\n",
      "9002/9002 [==============================] - 1s 60us/step - loss: 17.9054 - acc: 0.0023\n",
      "Epoch 59/100\n",
      "9002/9002 [==============================] - 1s 77us/step - loss: 17.8855 - acc: 0.0031\n",
      "Epoch 60/100\n",
      "9002/9002 [==============================] - 1s 74us/step - loss: 17.8956 - acc: 0.0028\n",
      "Epoch 61/100\n",
      "9002/9002 [==============================] - 1s 63us/step - loss: 17.8896 - acc: 0.0038\n",
      "Epoch 62/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9662 - acc: 0.0029\n",
      "Epoch 63/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.8688 - acc: 0.0027\n",
      "Epoch 64/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9332 - acc: 0.0030\n",
      "Epoch 65/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9872 - acc: 0.0031\n",
      "Epoch 66/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9865 - acc: 0.0031\n",
      "Epoch 67/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.9318 - acc: 0.0023\n",
      "Epoch 68/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9633 - acc: 0.0028\n",
      "Epoch 69/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.8886 - acc: 0.0031\n",
      "Epoch 70/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9255 - acc: 0.0030\n",
      "Epoch 71/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9042 - acc: 0.0032\n",
      "Epoch 72/100\n",
      "9002/9002 [==============================] - 1s 56us/step - loss: 17.8895 - acc: 0.0032\n",
      "Epoch 73/100\n",
      "9002/9002 [==============================] - 1s 72us/step - loss: 17.9229 - acc: 0.0033\n",
      "Epoch 74/100\n",
      "9002/9002 [==============================] - 1s 62us/step - loss: 17.8933 - acc: 0.0033\n",
      "Epoch 75/100\n",
      "9002/9002 [==============================] - 1s 80us/step - loss: 17.9024 - acc: 0.0022\n",
      "Epoch 76/100\n",
      "9002/9002 [==============================] - 1s 70us/step - loss: 17.8857 - acc: 0.0024\n",
      "Epoch 77/100\n",
      "9002/9002 [==============================] - 1s 66us/step - loss: 17.9211 - acc: 0.0030\n",
      "Epoch 78/100\n",
      "9002/9002 [==============================] - 1s 70us/step - loss: 17.9517 - acc: 0.0032\n",
      "Epoch 79/100\n",
      "9002/9002 [==============================] - 1s 86us/step - loss: 17.9225 - acc: 0.0032\n",
      "Epoch 80/100\n",
      "9002/9002 [==============================] - 1s 68us/step - loss: 17.9030 - acc: 0.0030\n",
      "Epoch 81/100\n",
      "9002/9002 [==============================] - 1s 84us/step - loss: 17.9614 - acc: 0.0029\n",
      "Epoch 82/100\n",
      "9002/9002 [==============================] - 1s 119us/step - loss: 17.9219 - acc: 0.0037\n",
      "Epoch 83/100\n",
      "9002/9002 [==============================] - 1s 124us/step - loss: 17.9295 - acc: 0.0027\n",
      "Epoch 84/100\n",
      "9002/9002 [==============================] - 1s 112us/step - loss: 17.9295 - acc: 0.0029\n",
      "Epoch 85/100\n",
      "9002/9002 [==============================] - 1s 90us/step - loss: 17.8499 - acc: 0.0026\n",
      "Epoch 86/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9134 - acc: 0.0030\n",
      "Epoch 87/100\n",
      "9002/9002 [==============================] - 1s 68us/step - loss: 17.8578 - acc: 0.0031\n",
      "Epoch 88/100\n",
      "9002/9002 [==============================] - 1s 72us/step - loss: 17.9061 - acc: 0.0024\n",
      "Epoch 89/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.8720 - acc: 0.0034\n",
      "Epoch 90/100\n",
      "9002/9002 [==============================] - 1s 61us/step - loss: 17.8718 - acc: 0.0031\n",
      "Epoch 91/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9161 - acc: 0.0027\n",
      "Epoch 92/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9400 - acc: 0.0029\n",
      "Epoch 93/100\n",
      "9002/9002 [==============================] - 1s 59us/step - loss: 17.9318 - acc: 0.0027\n",
      "Epoch 94/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.9339 - acc: 0.0027\n",
      "Epoch 95/100\n",
      "9002/9002 [==============================] - 1s 57us/step - loss: 17.8918 - acc: 0.0032\n",
      "Epoch 96/100\n",
      "9002/9002 [==============================] - 1s 68us/step - loss: 17.8726 - acc: 0.0038\n",
      "Epoch 97/100\n",
      "9002/9002 [==============================] - 1s 66us/step - loss: 17.8949 - acc: 0.0032\n",
      "Epoch 98/100\n",
      "9002/9002 [==============================] - 1s 59us/step - loss: 17.9404 - acc: 0.0027\n",
      "Epoch 99/100\n",
      "9002/9002 [==============================] - 1s 60us/step - loss: 17.8468 - acc: 0.0026\n",
      "Epoch 100/100\n",
      "9002/9002 [==============================] - 1s 58us/step - loss: 17.9370 - acc: 0.0026\n",
      "172/172 [==============================] - 0s 38us/step\n",
      "Epoch 1/100\n",
      "2530/9174 [=======>......................] - ETA: 0s - loss: 17.4813 - acc: 0.0032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9174/9174 [==============================] - 1s 73us/step - loss: 17.7541 - acc: 0.0031\n",
      "Epoch 2/100\n",
      "9174/9174 [==============================] - 1s 59us/step - loss: 17.6831 - acc: 0.0025\n",
      "Epoch 3/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6465 - acc: 0.0022\n",
      "Epoch 4/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.7251 - acc: 0.0026\n",
      "Epoch 5/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6679 - acc: 0.0029\n",
      "Epoch 6/100\n",
      "9174/9174 [==============================] - 1s 59us/step - loss: 17.7223 - acc: 0.0032\n",
      "Epoch 7/100\n",
      "9174/9174 [==============================] - 1s 61us/step - loss: 17.7570 - acc: 0.0027\n",
      "Epoch 8/100\n",
      "9174/9174 [==============================] - 1s 60us/step - loss: 17.6966 - acc: 0.0026\n",
      "Epoch 9/100\n",
      "9174/9174 [==============================] - 1s 59us/step - loss: 17.7007 - acc: 0.0025\n",
      "Epoch 10/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6869 - acc: 0.0023\n",
      "Epoch 11/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6899 - acc: 0.0024\n",
      "Epoch 12/100\n",
      "9174/9174 [==============================] - 1s 73us/step - loss: 17.6981 - acc: 0.0034\n",
      "Epoch 13/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6953 - acc: 0.0032\n",
      "Epoch 14/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6788 - acc: 0.0028\n",
      "Epoch 15/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6857 - acc: 0.0027\n",
      "Epoch 16/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7067 - acc: 0.0031\n",
      "Epoch 17/100\n",
      "9174/9174 [==============================] - 1s 59us/step - loss: 17.7431 - acc: 0.0027\n",
      "Epoch 18/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6860 - acc: 0.0026\n",
      "Epoch 19/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6692 - acc: 0.0033\n",
      "Epoch 20/100\n",
      "9174/9174 [==============================] - 1s 69us/step - loss: 17.6857 - acc: 0.0029\n",
      "Epoch 21/100\n",
      "9174/9174 [==============================] - 1s 61us/step - loss: 17.7054 - acc: 0.0029\n",
      "Epoch 22/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6493 - acc: 0.0035\n",
      "Epoch 23/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6606 - acc: 0.0032\n",
      "Epoch 24/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.7331 - acc: 0.0028\n",
      "Epoch 25/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6939 - acc: 0.0021\n",
      "Epoch 26/100\n",
      "9174/9174 [==============================] - 1s 55us/step - loss: 17.6800 - acc: 0.0028\n",
      "Epoch 27/100\n",
      "9174/9174 [==============================] - 1s 75us/step - loss: 17.7252 - acc: 0.0034\n",
      "Epoch 28/100\n",
      "9174/9174 [==============================] - 1s 59us/step - loss: 17.7710 - acc: 0.0029\n",
      "Epoch 29/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.7028 - acc: 0.0024\n",
      "Epoch 30/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7505 - acc: 0.0031\n",
      "Epoch 31/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6869 - acc: 0.0029\n",
      "Epoch 32/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6494 - acc: 0.0025\n",
      "Epoch 33/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.7210 - acc: 0.0029\n",
      "Epoch 34/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7010 - acc: 0.0031\n",
      "Epoch 35/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6641 - acc: 0.0031\n",
      "Epoch 36/100\n",
      "9174/9174 [==============================] - 1s 62us/step - loss: 17.7247 - acc: 0.0031\n",
      "Epoch 37/100\n",
      "9174/9174 [==============================] - 1s 85us/step - loss: 17.6985 - acc: 0.0031\n",
      "Epoch 38/100\n",
      "9174/9174 [==============================] - 1s 65us/step - loss: 17.7021 - acc: 0.0024\n",
      "Epoch 39/100\n",
      "9174/9174 [==============================] - 1s 62us/step - loss: 17.7480 - acc: 0.0022\n",
      "Epoch 40/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6935 - acc: 0.0032\n",
      "Epoch 41/100\n",
      "9174/9174 [==============================] - 1s 59us/step - loss: 17.6956 - acc: 0.0021\n",
      "Epoch 42/100\n",
      "9174/9174 [==============================] - 1s 60us/step - loss: 17.6650 - acc: 0.0025\n",
      "Epoch 43/100\n",
      "9174/9174 [==============================] - 1s 60us/step - loss: 17.6948 - acc: 0.0029\n",
      "Epoch 44/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6714 - acc: 0.0031\n",
      "Epoch 45/100\n",
      "9174/9174 [==============================] - 1s 60us/step - loss: 17.6778 - acc: 0.0026\n",
      "Epoch 46/100\n",
      "9174/9174 [==============================] - 1s 62us/step - loss: 17.6606 - acc: 0.0037\n",
      "Epoch 47/100\n",
      "9174/9174 [==============================] - 1s 59us/step - loss: 17.7194 - acc: 0.0024\n",
      "Epoch 48/100\n",
      "9174/9174 [==============================] - 1s 59us/step - loss: 17.6647 - acc: 0.0034\n",
      "Epoch 49/100\n",
      "9174/9174 [==============================] - 1s 80us/step - loss: 17.6945 - acc: 0.0033\n",
      "Epoch 50/100\n",
      "9174/9174 [==============================] - 1s 90us/step - loss: 17.6698 - acc: 0.0025\n",
      "Epoch 51/100\n",
      "9174/9174 [==============================] - 1s 70us/step - loss: 17.7314 - acc: 0.0033\n",
      "Epoch 52/100\n",
      "9174/9174 [==============================] - 1s 65us/step - loss: 17.6978 - acc: 0.0020\n",
      "Epoch 53/100\n",
      "9174/9174 [==============================] - 1s 64us/step - loss: 17.6833 - acc: 0.0031\n",
      "Epoch 54/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6998 - acc: 0.0033\n",
      "Epoch 55/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.7007 - acc: 0.0027\n",
      "Epoch 56/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7071 - acc: 0.0026\n",
      "Epoch 57/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.7028 - acc: 0.0035\n",
      "Epoch 58/100\n",
      "9174/9174 [==============================] - 0s 54us/step - loss: 17.7222 - acc: 0.0028\n",
      "Epoch 59/100\n",
      "9174/9174 [==============================] - 1s 55us/step - loss: 17.7990 - acc: 0.0027\n",
      "Epoch 60/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6653 - acc: 0.0029\n",
      "Epoch 61/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6963 - acc: 0.0027\n",
      "Epoch 62/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7299 - acc: 0.0027\n",
      "Epoch 63/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6502 - acc: 0.0026\n",
      "Epoch 64/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.7302 - acc: 0.0031\n",
      "Epoch 65/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6941 - acc: 0.0022\n",
      "Epoch 66/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7189 - acc: 0.0025\n",
      "Epoch 67/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6833 - acc: 0.0032\n",
      "Epoch 68/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7187 - acc: 0.0027\n",
      "Epoch 69/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7154 - acc: 0.0029\n",
      "Epoch 70/100\n",
      "9174/9174 [==============================] - 1s 55us/step - loss: 17.6521 - acc: 0.0023\n",
      "Epoch 71/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.7203 - acc: 0.0031\n",
      "Epoch 72/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.7313 - acc: 0.0027\n",
      "Epoch 73/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6647 - acc: 0.0032\n",
      "Epoch 74/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6742 - acc: 0.0028\n",
      "Epoch 75/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6850 - acc: 0.0031\n",
      "Epoch 76/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.7266 - acc: 0.0027\n",
      "Epoch 77/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6762 - acc: 0.0029\n",
      "Epoch 78/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7271 - acc: 0.0028\n",
      "Epoch 79/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6824 - acc: 0.0034\n",
      "Epoch 80/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.7040 - acc: 0.0035\n",
      "Epoch 81/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6940 - acc: 0.0031\n",
      "Epoch 82/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6643 - acc: 0.0023\n",
      "Epoch 83/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6346 - acc: 0.0023\n",
      "Epoch 84/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7243 - acc: 0.0029\n",
      "Epoch 85/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.6808 - acc: 0.0037\n",
      "Epoch 86/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6409 - acc: 0.0029\n",
      "Epoch 87/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7548 - acc: 0.0028\n",
      "Epoch 88/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6659 - acc: 0.0032\n",
      "Epoch 89/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6772 - acc: 0.0026\n",
      "Epoch 90/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6760 - acc: 0.0034\n",
      "Epoch 91/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6727 - acc: 0.0022\n",
      "Epoch 92/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6872 - acc: 0.0028\n",
      "Epoch 93/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6433 - acc: 0.0032\n",
      "Epoch 94/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6852 - acc: 0.0028\n",
      "Epoch 95/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.7032 - acc: 0.0034\n",
      "Epoch 96/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6573 - acc: 0.0024\n",
      "Epoch 97/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6647 - acc: 0.0021\n",
      "Epoch 98/100\n",
      "9174/9174 [==============================] - 1s 58us/step - loss: 17.7013 - acc: 0.0035\n",
      "Epoch 99/100\n",
      "9174/9174 [==============================] - 1s 57us/step - loss: 17.6907 - acc: 0.0036\n",
      "Epoch 100/100\n",
      "9174/9174 [==============================] - 1s 56us/step - loss: 17.6889 - acc: 0.0027\n",
      "172/172 [==============================] - 0s 0us/step\n",
      "Epoch 1/100\n",
      "3200/9346 [=========>....................] - ETA: 0s - loss: 17.6848 - acc: 0.0031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5406 - acc: 0.0036\n",
      "Epoch 2/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5254 - acc: 0.0027\n",
      "Epoch 3/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5593 - acc: 0.0031\n",
      "Epoch 4/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.6334 - acc: 0.0032\n",
      "Epoch 5/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5296 - acc: 0.0030\n",
      "Epoch 6/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5649 - acc: 0.0037\n",
      "Epoch 7/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5235 - acc: 0.0022\n",
      "Epoch 8/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.5825 - acc: 0.0025\n",
      "Epoch 9/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5379 - acc: 0.0029\n",
      "Epoch 10/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5166 - acc: 0.0033\n",
      "Epoch 11/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5656 - acc: 0.0035\n",
      "Epoch 12/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5239 - acc: 0.0033\n",
      "Epoch 13/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5367 - acc: 0.0026\n",
      "Epoch 14/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5350 - acc: 0.0034\n",
      "Epoch 15/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5930 - acc: 0.0034\n",
      "Epoch 16/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5869 - acc: 0.0032\n",
      "Epoch 17/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.5275 - acc: 0.0031\n",
      "Epoch 18/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.6054 - acc: 0.0027\n",
      "Epoch 19/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.6090 - acc: 0.0028\n",
      "Epoch 20/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5846 - acc: 0.0033\n",
      "Epoch 21/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.5791 - acc: 0.0035\n",
      "Epoch 22/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5461 - acc: 0.0031\n",
      "Epoch 23/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5423 - acc: 0.0031\n",
      "Epoch 24/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5435 - acc: 0.0028\n",
      "Epoch 25/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5993 - acc: 0.0034\n",
      "Epoch 26/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5597 - acc: 0.0026\n",
      "Epoch 27/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.5305 - acc: 0.0030\n",
      "Epoch 28/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5759 - acc: 0.0027\n",
      "Epoch 29/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.5398 - acc: 0.0031\n",
      "Epoch 30/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5272 - acc: 0.0024\n",
      "Epoch 31/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.5820 - acc: 0.0025\n",
      "Epoch 32/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5611 - acc: 0.0028\n",
      "Epoch 33/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.6125 - acc: 0.0037\n",
      "Epoch 34/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5712 - acc: 0.0031\n",
      "Epoch 35/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.6235 - acc: 0.0022\n",
      "Epoch 36/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5044 - acc: 0.0034\n",
      "Epoch 37/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.6078 - acc: 0.0030\n",
      "Epoch 38/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.6103 - acc: 0.0029\n",
      "Epoch 39/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5746 - acc: 0.0031\n",
      "Epoch 40/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5452 - acc: 0.0027\n",
      "Epoch 41/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5634 - acc: 0.0028\n",
      "Epoch 42/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.5943 - acc: 0.0031\n",
      "Epoch 43/100\n",
      "9346/9346 [==============================] - 1s 71us/step - loss: 17.5415 - acc: 0.0027\n",
      "Epoch 44/100\n",
      "9346/9346 [==============================] - 1s 73us/step - loss: 17.5788 - acc: 0.0029\n",
      "Epoch 45/100\n",
      "9346/9346 [==============================] - 1s 80us/step - loss: 17.5866 - acc: 0.0036\n",
      "Epoch 46/100\n",
      "9346/9346 [==============================] - 1s 67us/step - loss: 17.5474 - acc: 0.0030\n",
      "Epoch 47/100\n",
      "9346/9346 [==============================] - 1s 79us/step - loss: 17.6075 - acc: 0.0024\n",
      "Epoch 48/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5654 - acc: 0.0032\n",
      "Epoch 49/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5348 - acc: 0.0032\n",
      "Epoch 50/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5045 - acc: 0.0026\n",
      "Epoch 51/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5728 - acc: 0.0031\n",
      "Epoch 52/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.6066 - acc: 0.0028\n",
      "Epoch 53/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5459 - acc: 0.0037\n",
      "Epoch 54/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5622 - acc: 0.0028\n",
      "Epoch 55/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5388 - acc: 0.0035\n",
      "Epoch 56/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5876 - acc: 0.0033\n",
      "Epoch 57/100\n",
      "9346/9346 [==============================] - 1s 59us/step - loss: 17.5450 - acc: 0.0030\n",
      "Epoch 58/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5782 - acc: 0.0033\n",
      "Epoch 59/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5446 - acc: 0.0026\n",
      "Epoch 60/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.6076 - acc: 0.0035\n",
      "Epoch 61/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5103 - acc: 0.0031\n",
      "Epoch 62/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.6068 - acc: 0.0029\n",
      "Epoch 63/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5343 - acc: 0.0031\n",
      "Epoch 64/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5920 - acc: 0.0030\n",
      "Epoch 65/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5327 - acc: 0.0024\n",
      "Epoch 66/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5725 - acc: 0.0026\n",
      "Epoch 67/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.6089 - acc: 0.0034\n",
      "Epoch 68/100\n",
      "9346/9346 [==============================] - 1s 57us/step - loss: 17.5647 - acc: 0.0028\n",
      "Epoch 69/100\n",
      "9346/9346 [==============================] - 1s 59us/step - loss: 17.5443 - acc: 0.0026\n",
      "Epoch 70/100\n",
      "9346/9346 [==============================] - 1s 55us/step - loss: 17.5712 - acc: 0.0028\n",
      "Epoch 71/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5065 - acc: 0.0027\n",
      "Epoch 72/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5663 - acc: 0.0024\n",
      "Epoch 73/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.5455 - acc: 0.0030\n",
      "Epoch 74/100\n",
      "9346/9346 [==============================] - 1s 58us/step - loss: 17.5684 - acc: 0.0030\n",
      "Epoch 75/100\n",
      "9346/9346 [==============================] - 1s 56us/step - loss: 17.6270 - acc: 0.0025\n",
      "Epoch 76/100\n",
      "2130/9346 [=====>........................] - ETA: 0s - loss: 17.2249 - acc: 0.0052  "
     ]
    }
   ],
   "source": [
    "# initialize CNN\n",
    "keras_reg = Sequential()\n",
    "# add input layer and first hidden layer\n",
    "keras_reg.add(Dense(output_dim=8, init='uniform', activation='relu', input_dim=14))\n",
    "# add second hidden layer\n",
    "keras_reg.add(Dense(output_dim=8, init='uniform', activation='relu'))\n",
    "# add the output layer\n",
    "keras_reg.add(Dense(output_dim=1, init='uniform'))\n",
    "# compile\n",
    "keras_reg.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "keras_param = {}\n",
    "rmse_list = []\n",
    "score_list = []\n",
    "tscv = TimeSeriesSplit(n_splits = 70)\n",
    "cv = tscv.split(X)\n",
    "\n",
    "# fix random seed\n",
    "seed=10\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#keras_est = KerasRegressor(build_fn=keras_reg, epochs=100, batch_size=10, verbose=0)\n",
    "#keras_cv = GridSearchCV(keras_estimator, keras_param, cv=cv, verbose=1)\n",
    "\n",
    "for train_index, test_index in cv:\n",
    "        \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # fit ANN to training set\n",
    "    keras_reg.fit(X_train,y_train, batch_size=10, nb_epoch=100)\n",
    "    #keras_est.fit(X_train,y_train, batch_size=10, nb_epoch=100)\n",
    "    y_pred = keras_reg.predict(X_test)\n",
    "    score = keras_reg.evaluate(X_test,y_test,batch_size=16)\n",
    "    score_list.append(score)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    rmse_list.append(rmse) \n",
    "\n",
    "#results = cross_val_score(keras_estimator, X, y, cv=keras_cv)\n",
    "#print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting Parameters : {'max_leaf_nodes': 100, 'n_estimators': 100}\n",
      "Gradient Boosting Score =  0.6577543467027146\n"
     ]
    }
   ],
   "source": [
    "random_state = 35\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=70)\n",
    "cv = tscv.split(X)\n",
    "\n",
    "gb = GradientBoostingRegressor()\n",
    "gb_param = {'n_estimators': [100, 500, 1000], 'max_leaf_nodes': [100, 300,500]}\n",
    "\n",
    "gb_cv = GridSearchCV(gb, gb_param, iid=False, cv=cv, return_train_score=False)\n",
    "gb_cv.fit(X,y)\n",
    "gb_result = gb_cv.cv_results_\n",
    "print(\"Best Gradient Boosting Parameters :\",gb_cv.best_params_)\n",
    "print(\"Gradient Boosting Score = \",gb_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE Score =  12.114865930211554\n",
      "Average Prediction Accuracy = -0.9077001031688738\n",
      "Execution time:  135.9574224948883\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=200)\n",
    "cv = tscv.split(X)\n",
    "\n",
    "rmse_list = []\n",
    "score_list = []\n",
    "gb = GradientBoostingRegressor(n_estimators=100,max_leaf_nodes=500)\n",
    "\n",
    "# set start time\n",
    "start = time.time()\n",
    "\n",
    "for train_index, test_index in cv:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    gb.fit(X_train,y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    score = gb.score(X_test,y_test)\n",
    "    score_list.append(score)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# set end time\n",
    "end = time.time()\n",
    "\n",
    "print(\"Average RMSE Score = \",np.mean(rmse_list))\n",
    "print(\"Average Prediction Accuracy =\",np.mean(score_list))\n",
    "print(\"Execution time: \",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr_param = {'n_estimators': [100, 500, 600], 'min_samples_split': [70, 100, 150]}\n",
    "tscv = TimeSeriesSplit(n_splits=200)\n",
    "cv = tscv.split(X)\n",
    "\n",
    "rfr_cv = GridSearchCV(rfr, rfr_param, iid=False, cv=cv, return_train_score=False)\n",
    "rfr_cv.fit(X,y)\n",
    "rfr_result = rfr_cv.cv_results_\n",
    "print(\"Best Random Forest Parameters :\",rfr_cv.best_params_)\n",
    "print(\"Random Forest Regressor Score = \",rfr_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=200)\n",
    "cv = tscv.split(X)\n",
    "\n",
    "rmse_list = []\n",
    "score_list = []\n",
    "rfr =RandomForestRegressor(n_estimators=500,max_leaf_nodes=100)\n",
    "\n",
    "# set start time\n",
    "start = time.time()\n",
    "\n",
    "for train_index, test_index in cv:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    rfr.fit(X_train,y_train)\n",
    "    y_pred = rfr.predict(X_test)\n",
    "    score = rfr.score(X_test,y_test)\n",
    "    score_list.append(score)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# set end time\n",
    "end = time.time()\n",
    "    \n",
    "print(\"Average RMSE Score = \",np.mean(rmse_list))\n",
    "print(\"Average Prediction Accuracy =\",np.mean(score_list))\n",
    "print(\"Execution time: \",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(min_data=1)\n",
    "#lgbm_param = {'num_leaves': [10, 100, 1000],'min_data_in_leaf': [100, 500, 1000],'max_depth': [5, 50, 100]}\n",
    "lgbm_param = {'min_data': [1],'min_data_in_bin':[1],'num_leaves': [30,50],'min_data_in_leaf': [60,70,100],'max_depth': [20,30]}\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "cv = tscv.split(X)\n",
    "lgbm_cv = GridSearchCV(lgbm, lgbm_param, cv=cv, verbose=1)\n",
    "lgbm_cv.fit(X,y)\n",
    "lgbm_cv.best_params_\n",
    "lgbm_result = lgbm_cv.cv_results_\n",
    "print(\"Best LGBM Parameters :\",lgbm_cv.best_params_)\n",
    "print(\"LGB Score = \",lgbm_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=200)\n",
    "cv = tscv.split(X)\n",
    "\n",
    "rmse_list = []\n",
    "score_list = []\n",
    "lgbm = LGBMRegressor(min_data=1,num_leaves=50,min_data_inleaf=70,max_depth=100)\n",
    "\n",
    "# set start time\n",
    "start = time.time()\n",
    "\n",
    "for train_index, test_index in cv:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    lgbm.fit(X_train,y_train)\n",
    "    y_pred = lgbm.predict(X_test)\n",
    "    score = lgbm.score(X_test,y_test)\n",
    "    score_list.append(score)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# set end time\n",
    "end = time.time()\n",
    "    \n",
    "print(\"Average RMSE Score = \",np.mean(rmse_list))\n",
    "print(\"Average Prediction Accuracy =\",np.mean(score_list))\n",
    "print(\"Execution time: \",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()\n",
    "#lgbm_param = {'num_leaves': [10, 100, 1000],'min_data_in_leaf': [100, 500, 1000],'max_depth': [5, 50, 100]}\n",
    "xgb_param = {'n_estimators': [100,200],'learning_rate': [0.08, 0.1],'max_depth': [30,100,200]}\n",
    "tscv = TimeSeriesSplit(n_splits=200)\n",
    "cv = tscv.split(X)\n",
    "xgb_cv = GridSearchCV(xgb, xgb_param, cv=cv, verbose=1)\n",
    "xgb_cv.fit(X,y)\n",
    "print(\"Best XGB Parameters :\",xgb_cv.best_params_)\n",
    "xgb_result = xgb_cv.cv_results_\n",
    "print(\"XGB Score = \",xgb_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=200)\n",
    "cv = tscv.split(X)\n",
    "\n",
    "rmse_list = []\n",
    "score_list = []\n",
    "xgb = XGBRegressor(n_estimators=100,min_data_inleaf=70,max_depth=30)\n",
    "\n",
    "# set start time\n",
    "start = time.time()\n",
    "\n",
    "for train_index, test_index in cv:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    xgb.fit(X_train,y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    score = xgb.score(X_test,y_test)\n",
    "    score_list.append(score)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# set end time\n",
    "end = time.time()\n",
    "    \n",
    "print(\"Average RMSE Score = \",np.mean(rmse_list))\n",
    "print(\"Average Prediction Accuracy =\",np.mean(score_list))\n",
    "print(\"Execution time: \",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "# XGB Feature importance\n",
    "plot_importance(xgb)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "seaborn.set()\n",
    "y.plot(figsize=(25,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# TODO: Apply PCA by fitting the good data with the same number of dimensions as features\n",
    "pca = PCA(n_components = 7)\n",
    "pca.fit(X)\n",
    "\n",
    "# Generate PCA results plot\n",
    "pca_results = vs.pca_results(X, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
